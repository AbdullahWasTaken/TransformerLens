Search.setIndex({"docnames": ["content/citation", "content/contributing", "content/gallery", "content/getting_started", "content/getting_started_mech_interp", "content/special_cases", "content/tutorials", "generated/code/modules", "generated/code/transformer_lens", "generated/code/transformer_lens.ActivationCache", "generated/code/transformer_lens.FactoredMatrix", "generated/code/transformer_lens.HookedEncoder", "generated/code/transformer_lens.HookedSAE", "generated/code/transformer_lens.HookedSAEConfig", "generated/code/transformer_lens.HookedSAETransformer", "generated/code/transformer_lens.HookedTransformer", "generated/code/transformer_lens.HookedTransformerConfig", "generated/code/transformer_lens.SVDInterpreter", "generated/code/transformer_lens.components", "generated/code/transformer_lens.evals", "generated/code/transformer_lens.head_detector", "generated/code/transformer_lens.hook_points", "generated/code/transformer_lens.loading_from_pretrained", "generated/code/transformer_lens.past_key_value_caching", "generated/code/transformer_lens.patching", "generated/code/transformer_lens.train", "generated/code/transformer_lens.utilities", "generated/code/transformer_lens.utilities.devices", "generated/code/transformer_lens.utils", "generated/demos/BERT", "generated/demos/Exploratory_Analysis_Demo", "generated/demos/Main_Demo", "generated/model_properties_table", "index"], "filenames": ["content/citation.md", "content/contributing.md", "content/gallery.md", "content/getting_started.md", "content/getting_started_mech_interp.md", "content/special_cases.md", "content/tutorials.md", "generated/code/modules.rst", "generated/code/transformer_lens.rst", "generated/code/transformer_lens.ActivationCache.rst", "generated/code/transformer_lens.FactoredMatrix.rst", "generated/code/transformer_lens.HookedEncoder.rst", "generated/code/transformer_lens.HookedSAE.rst", "generated/code/transformer_lens.HookedSAEConfig.rst", "generated/code/transformer_lens.HookedSAETransformer.rst", "generated/code/transformer_lens.HookedTransformer.rst", "generated/code/transformer_lens.HookedTransformerConfig.rst", "generated/code/transformer_lens.SVDInterpreter.rst", "generated/code/transformer_lens.components.rst", "generated/code/transformer_lens.evals.rst", "generated/code/transformer_lens.head_detector.rst", "generated/code/transformer_lens.hook_points.rst", "generated/code/transformer_lens.loading_from_pretrained.rst", "generated/code/transformer_lens.past_key_value_caching.rst", "generated/code/transformer_lens.patching.rst", "generated/code/transformer_lens.train.rst", "generated/code/transformer_lens.utilities.rst", "generated/code/transformer_lens.utilities.devices.rst", "generated/code/transformer_lens.utils.rst", "generated/demos/BERT.ipynb", "generated/demos/Exploratory_Analysis_Demo.ipynb", "generated/demos/Main_Demo.ipynb", "generated/model_properties_table.md", "index.md"], "titles": ["Citation", "Contributing", "Gallery", "Getting Started", "Getting Started in Mechanistic Interpretability", "Special Cases", "Tutorials", "Transformer Lens API", "transformer_lens", "transformer_lens.ActivationCache", "transformer_lens.FactoredMatrix", "transformer_lens.HookedEncoder", "transformer_lens.HookedSAE", "transformer_lens.HookedSAEConfig", "transformer_lens.HookedSAETransformer", "transformer_lens.HookedTransformer", "transformer_lens.HookedTransformerConfig", "transformer_lens.SVDInterpreter", "transformer_lens.components", "transformer_lens.evals", "transformer_lens.head_detector", "transformer_lens.hook_points", "transformer_lens.loading_from_pretrained", "transformer_lens.past_key_value_caching", "transformer_lens.patching", "transformer_lens.train", "transformer_lens.utilities", "transformer_lens.utilities.devices", "transformer_lens.utils", "BERT in TransformerLens", "Exploratory Analysis Demo", "Transformer Lens Main Demo Notebook", "Model Properties Table", "TransformerLens"], "terms": {"pleas": [0, 1, 3, 4, 29, 31], "cite": 0, "thi": [0, 1, 3, 4, 5, 6, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 33], "librari": [0, 2, 3, 4, 6, 9, 19, 28, 29, 30], "misc": 0, "nanda2022transformerlen": 0, "titl": [0, 1, 30, 31], "transformerlen": [0, 2, 3, 4, 6, 9, 12, 15, 18, 22, 28, 30, 31], "author": [0, 30], "neel": [0, 2, 4, 6, 15, 17, 29, 31], "nanda": [0, 2, 4, 15, 31], "joseph": [0, 12], "bloom": [0, 12, 18, 22, 32], "year": 0, "2022": [0, 28], "howpublish": 0, "url": [0, 3], "http": [0, 1, 3, 6, 9, 12, 15, 16, 18, 19, 20, 24, 28, 29, 30, 31], "github": [0, 1, 3, 6, 12, 15, 29], "com": [0, 3, 6, 9, 12, 15, 18, 29, 30, 31], "transformerlensorg": [0, 3, 6, 29], "For": [1, 9, 11, 12, 15, 18, 20, 28, 29, 30], "one": [1, 3, 4, 9, 11, 14, 15, 16, 18, 20, 21, 22, 23, 24, 28, 30, 31, 33], "click": [1, 31], "your": [1, 3, 6, 13, 15, 16, 20, 21, 30, 31], "develop": [1, 6, 29, 30, 31], "environ": [1, 3], "project": [1, 6, 9, 18, 25, 30], "includ": [1, 4, 6, 9, 11, 15, 16, 19, 20, 21, 30], "It": [1, 3, 6, 9, 11, 15, 16, 18, 19, 21, 24, 28, 30, 31, 33], "can": [1, 2, 3, 5, 6, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 30, 31, 33], "us": [1, 2, 3, 5, 6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 33], "local": [1, 15, 16, 18, 22, 28, 31], "v": [1, 9, 11, 15, 16, 18, 24, 29, 30, 31], "code": [1, 4, 9, 12, 15, 16, 18, 19, 20, 21, 22, 28, 29, 30, 31], "codespac": 1, "poetri": 1, "packag": 1, "manag": [1, 9, 14, 15, 21, 28], "instal": [1, 29, 30, 31], "follow": [1, 3, 9, 15, 28, 31, 33], "also": [1, 6, 9, 11, 12, 14, 15, 16, 17, 20, 21, 22, 27, 28, 30, 31], "virtual": 1, "config": [1, 15, 16, 18, 22, 24, 25], "virtualenv": 1, "true": [1, 9, 11, 14, 15, 16, 19, 20, 21, 22, 24, 27, 28, 29, 30, 31], "dev": 1, "doc": [1, 7, 9, 15, 29, 31], "jupyt": [1, 29], "If": [1, 3, 7, 9, 11, 14, 15, 16, 18, 20, 21, 22, 24, 27, 28, 29, 30, 31], "ad": [1, 6, 12, 14, 15, 16, 18, 21, 30, 31], "featur": [1, 3, 6, 11, 17, 18, 24, 28, 29, 30, 33], "add": [1, 12, 14, 15, 16, 18, 21, 23, 28, 30, 31, 33], "unit": 1, "you": [1, 3, 4, 6, 9, 11, 12, 14, 15, 16, 17, 19, 20, 21, 22, 28, 29, 30, 31, 33], "need": [1, 3, 9, 15, 16, 18, 21, 28, 29, 30, 31, 33], "model": [1, 2, 3, 5, 6, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 30], "ones": [1, 11, 14, 15, 20, 30], "ar": [1, 3, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 28, 29, 31, 33], "cach": [1, 9, 14, 15, 16, 18, 20, 21, 23, 24, 28, 30, 33], "action": [1, 2, 30], "so": [1, 6, 9, 10, 11, 13, 15, 16, 17, 19, 21, 22, 23, 24, 28, 30, 31], "quickli": [1, 6], "cd": [1, 30, 31], "These": [1, 30, 31], "gpt2": [1, 14, 15, 16, 17, 18, 19, 22, 30, 31, 32], "attn": [1, 9, 11, 13, 14, 15, 16, 18, 22, 24, 28, 30, 31, 32], "onli": [1, 2, 9, 10, 11, 14, 15, 16, 18, 20, 21, 22, 28, 29, 30, 31, 32], "1l": [1, 22, 30, 31, 32], "2l": [1, 15, 22, 31, 32], "3l": [1, 22, 31, 32], "4l": [1, 22, 31, 32], "tini": [1, 9, 15, 22, 28, 30, 31, 32], "stori": [1, 9, 15, 22, 24, 28, 30, 32], "1m": [1, 9, 15, 22, 28, 32], "note": [1, 3, 9, 10, 11, 12, 14, 15, 16, 18, 19, 21, 22, 28, 30, 31], "i": [1, 3, 4, 5, 6, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 33], "quit": 1, "slow": [1, 31], "we": [1, 2, 7, 9, 12, 13, 15, 16, 20, 23, 24, 28, 29, 30, 31, 33], "have": [1, 3, 9, 11, 15, 18, 20, 24, 28, 30, 31, 33], "cpu": [1, 9, 11, 13, 15, 16, 18, 22, 29, 30, 31], "smaller": [1, 31], "like": [1, 3, 4, 6, 11, 15, 18, 19, 20, 24, 28, 29, 30, 31, 33], "prefer": 1, "possibl": [1, 11, 15, 20, 24, 28, 30, 31, 33], "via": [1, 2, 3, 4, 11, 15, 24, 30], "make": [1, 3, 6, 10, 11, 12, 15, 20, 21, 29, 30, 31, 33], "accept": [1, 3, 11, 15, 21, 30], "notebook": [1, 3, 6, 12, 29, 30, 33], "all": [1, 4, 9, 11, 14, 15, 18, 19, 20, 21, 24, 28, 30], "suit": 1, "mention": [1, 31], "pycln": 1, "isort": 1, "black": [1, 31], "pull": 1, "request": 1, "check": [1, 3, 6, 15, 17, 18, 19, 20, 21, 28, 30, 31], "file": [1, 28], "line": [1, 30, 31], "length": [1, 9, 11, 15, 16, 18, 28, 30, 31], "set": [1, 2, 9, 11, 13, 14, 15, 16, 18, 19, 20, 21, 24, 25, 28, 30, 31], "100": [1, 19, 30, 31], "pyproject": 1, "toml": 1, "instead": [1, 5, 9, 14, 15, 16, 18, 21, 30, 31], "default": [1, 5, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 28, 29, 30, 31], "88": [1, 31], "sure": [1, 3, 15, 28, 30, 31], "thorough": 1, "ani": [1, 3, 9, 11, 13, 14, 15, 16, 18, 21, 28, 29, 30, 31, 33], "should": [1, 6, 9, 11, 14, 15, 18, 20, 21, 25, 28, 30, 31], "do": [1, 3, 4, 6, 9, 11, 15, 18, 19, 21, 24, 28, 29, 30, 31, 33], "directli": [1, 11, 16, 28, 30, 31], "automat": [1, 6, 15, 16, 28, 29, 30, 31], "gener": [1, 6, 15, 18, 19, 23, 24, 28, 30], "api": [1, 21, 30], "when": [1, 3, 6, 9, 10, 11, 14, 15, 16, 18, 19, 21, 22, 23, 24, 28, 29, 30, 31], "merg": [1, 15], "main": [1, 3, 5, 6, 9, 21, 30], "thei": [1, 4, 15, 16, 18, 19, 24, 28, 30, 31, 33], "pytest": 1, "doctest": 1, "want": [1, 6, 9, 12, 14, 15, 17, 19, 20, 21, 23, 28, 30, 31], "view": [1, 2], "chang": [1, 2, 3, 14, 15, 16, 21, 22, 24, 28, 30, 31], "hot": [1, 30, 31], "reload": [1, 30, 31], "give": [1, 9, 15, 16, 19, 22, 24, 28, 30, 31], "real": [1, 6, 28, 29, 30, 31, 33], "time": [1, 6, 7, 9, 15, 20, 21, 28, 29, 30, 31], "edit": [1, 6, 12, 15, 24, 29, 30, 31, 33], "googl": [1, 6, 22, 29, 30, 31], "python": [1, 2, 13, 16, 19, 22, 28, 31, 32], "write": [1, 2, 3, 15, 28, 30, 31, 33], "some": [1, 3, 9, 15, 17, 18, 19, 21, 24, 28, 29, 30], "from": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 28, 29, 30, 31, 33], "restructuredtext": 1, "rest": [1, 9, 15, 16, 19, 22, 28, 31], "In": [1, 2, 5, 9, 11, 14, 15, 18, 19, 21, 29, 30, 31], "case": [1, 2, 9, 15, 16, 19, 20, 21, 22, 24, 28, 29, 30, 32], "A": [1, 2, 4, 9, 10, 11, 14, 15, 18, 19, 21, 23, 24, 28, 30, 31], "descript": 1, "what": [1, 3, 6, 9, 15, 20, 24, 31, 33], "doe": [1, 9, 11, 15, 16, 20, 21, 24, 28, 30, 31], "much": [1, 9, 15, 19, 20, 24, 28, 30, 31], "detail": [1, 9, 15, 16, 18, 22, 24, 28, 30, 31], "necessari": [1, 31], "fulli": [1, 24, 30], "understand": [1, 9, 15, 20, 29, 31], "warn": [1, 9, 14, 15, 20, 21, 28, 29], "user": [1, 2, 16, 28, 31], "e": [1, 9, 11, 12, 15, 18, 20, 21, 22, 28, 29, 30, 31, 32], "g": [1, 9, 11, 12, 15, 18, 20, 21, 28, 31], "common": [1, 6, 9, 15, 18, 28, 30, 31], "pitfal": 1, "exampl": [1, 2, 9, 11, 14, 15, 17, 18, 19, 21, 28, 29, 30], "here": [1, 2, 3, 15, 16, 18, 19, 20, 28, 30, 31], "print": [1, 9, 19, 25, 28, 29, 30, 31], "1": [1, 3, 4, 9, 11, 14, 15, 16, 18, 20, 21, 22, 23, 28, 29, 30, 31, 32], "2": [1, 3, 4, 9, 11, 15, 16, 18, 19, 20, 22, 28, 29, 30, 31, 32, 33], "3": [1, 5, 9, 10, 11, 15, 18, 19, 22, 24, 28, 29, 30, 31, 32, 33], "arg": [1, 18, 21], "param_without_type_signatur": 1, "each": [1, 9, 10, 11, 15, 16, 18, 20, 21, 22, 23, 24, 28, 30, 31], "indent": 1, "onc": [1, 3, 15, 28, 30, 31], "more": [1, 6, 9, 10, 15, 16, 18, 20, 24, 28, 30, 31, 33], "param_2": 1, "anoth": [1, 29, 30, 31], "paramet": [1, 6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 27, 28, 30], "return": [1, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 22, 24, 25, 27, 28, 30, 31], "without": [1, 3, 9, 15, 18, 28, 29, 30, 31], "type": [1, 5, 6, 9, 11, 12, 15, 16, 17, 18, 20, 21, 22, 24, 25, 27, 28, 30, 31], "signatur": [1, 11, 15, 31], "rais": [1, 15, 20, 22, 28, 31], "inform": [1, 15, 16, 18, 21, 22, 29, 30, 31], "about": [1, 6, 9, 12, 15, 19, 21, 24, 28, 30, 31, 33], "error": [1, 9, 12, 13, 15, 20, 22, 31], "mai": [1, 9, 11, 15, 16, 18, 28, 30, 31], "part": [1, 9, 15, 18, 24, 30, 31, 33], "codebas": [1, 31], "cross": [1, 9, 15, 28, 30, 31], "referenc": 1, "omit": [1, 20, 31], "full": [1, 4, 9, 11, 15, 16, 18, 28, 31], "path": [1, 4, 14, 28], "same": [1, 3, 9, 10, 12, 14, 15, 16, 18, 20, 21, 23, 24, 28, 30, 31], "mod": 1, "transformer_len": [1, 3, 7, 29, 30, 31], "modul": [1, 7, 11, 15, 16, 17, 18, 19, 21, 22, 23, 24, 28, 31], "const": 1, "loading_from_pretrain": [1, 7, 8, 15, 31], "official_model_nam": [1, 15, 22], "hookedtransform": [1, 3, 5, 6, 7, 8, 9, 11, 14, 16, 17, 18, 19, 20, 22, 24, 25, 27, 28, 29, 30, 31], "meth": [1, 9], "from_pretrain": [1, 3, 5, 9, 11, 14, 15, 17, 19, 22, 28, 29, 30, 31], "attr": 1, "cfg": [1, 11, 12, 15, 17, 18, 19, 22, 23, 27, 28, 30, 31], "latex": 1, "re": [1, 3, 4, 6, 9, 15, 16, 20, 30, 31], "place": [1, 6, 11, 15, 28, 30, 31], "string": [1, 11, 15, 16, 19, 20, 21, 22, 28, 30, 31], "backward": [1, 14, 21, 29, 30, 31], "slash": 1, "must": [1, 9, 11, 15, 16, 18, 20, 21, 28, 30, 31], "repeat": [1, 15, 19, 23, 28, 30, 31], "inlin": 1, "displai": [1, 30, 31], "mode": [1, 9, 15, 16, 18, 28, 30, 31], "b": [1, 10, 11, 15, 18, 19, 22, 24, 28, 31, 32], "2ab": 1, "nowrap": 1, "begin": [1, 3, 15, 19, 20, 28, 30, 31], "eqnarrai": 1, "y": [1, 9, 15, 20, 29, 30, 31], "ax": [1, 15, 24, 31], "bx": 1, "c": [1, 22, 28, 31, 32], "f": [1, 29, 30, 31], "x": [1, 9, 15, 18, 20, 21, 22, 28, 29, 30, 31], "2xy": 1, "end": [1, 6, 14, 15, 21, 24, 28, 30, 31], "ital": 1, "text": [1, 6, 9, 14, 15, 16, 18, 19, 21, 22, 23, 28, 30], "bold": 1, "list": [1, 3, 4, 9, 11, 14, 15, 16, 19, 20, 21, 23, 24, 28, 30, 31], "item": [1, 9, 28, 29, 30, 31], "number": [1, 9, 15, 16, 17, 18, 19, 22, 24, 25, 27, 28, 30, 31], "quot": 1, "level": [1, 21, 30, 31, 33], "extern": [1, 30], "link": [1, 15, 19], "domain": 1, "invalid": 1, "research": [2, 3, 4, 6, 29, 30, 31, 33], "done": [2, 4, 5, 9, 15, 16, 18, 21, 30, 31], "involv": [2, 30, 31], "progress": [2, 15, 31], "measur": [2, 19, 20, 24, 28, 30], "grokk": [2, 6], "mechanist": [2, 3, 6, 24, 30, 31], "interpret": [2, 3, 6, 9, 15, 17, 20, 24, 28, 29, 30], "iclr": 2, "spotlight": 2, "2023": 2, "lawrenc": 2, "chan": 2, "tom": [2, 30], "lieberum": 2, "jess": 2, "smith": 2, "jacob": 2, "steinhardt": 2, "find": [2, 6, 9, 10, 15, 24, 30, 31], "neuron": [2, 6, 9, 15, 30, 31], "haystack": 2, "studi": [2, 4, 24, 30, 31], "spars": 2, "probe": 2, "gurne": 2, "matthew": 2, "pauli": 2, "katherin": 2, "harvei": 2, "dmitrii": 2, "troitskii": 2, "dimitri": 2, "bertsima": 2, "toward": [2, 18, 24, 30], "autom": 2, "circuit": [2, 11, 15, 18, 19, 20, 24, 28, 30, 31], "discoveri": 2, "arthur": [2, 31], "conmi": [2, 31], "augustin": 2, "n": [2, 18, 25, 28, 30, 31], "mavor": 2, "parker": 2, "aengu": 2, "lynch": 2, "stefan": 2, "heimersheim": 2, "adri\u00e0": 2, "garriga": 2, "alonso": 2, "actual": [2, 15, 20, 21, 31], "othello": [2, 6, 22, 32], "gpt": [2, 3, 4, 6, 9, 11, 15, 16, 18, 19, 22, 28, 29, 30, 31, 32, 33], "ha": [2, 3, 4, 9, 10, 11, 15, 18, 19, 22, 23, 24, 28, 29, 30, 31], "linear": [2, 6, 11, 15, 18, 22, 30, 31], "emerg": [2, 6], "world": [2, 6, 31, 33], "represent": [2, 6], "docstr": 2, "4": [2, 3, 16, 18, 19, 28, 29, 30, 31, 32], "layer": [2, 5, 9, 11, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 28, 31], "attent": [2, 6, 9, 11, 12, 15, 16, 18, 20, 24, 28, 29, 31], "transform": [2, 3, 4, 6, 9, 11, 15, 16, 18, 22, 23, 24, 28, 29, 30], "jett": 2, "janiak": 2, "toi": [2, 15], "univers": 2, "icml": 2, "bilal": 2, "chughtai": 2, "n2g": 2, "scalabl": 2, "approach": [2, 9, 30, 31], "quantifi": [2, 20], "larg": [2, 6, 16, 18, 22, 28, 31, 32, 33], "languag": [2, 11, 15, 18, 19, 25, 28, 29, 30, 31], "workshop": 2, "rtml": 2, "alex": [2, 31], "foot": [2, 15, 31], "esben": 2, "kran": 2, "ioanni": 2, "konsta": 2, "fazl": 2, "barez": 2, "elicit": 2, "latent": 2, "predict": [2, 6, 9, 11, 15, 18, 19, 20, 28, 29, 30, 31], "tune": [2, 11, 22, 28, 31, 32], "len": [2, 9, 22], "nora": 2, "belros": 2, "zach": 2, "furman": 2, "logan": 2, "danni": 2, "halawi": 2, "igor": 2, "ostrovski": 2, "lev": 2, "mckinnei": 2, "stella": 2, "biderman": 2, "contribut": [2, 9, 15, 30], "being": [2, 9, 11, 15, 16, 20, 21, 24, 28, 30, 31], "induct": [2, 4, 19, 20, 22], "head": [2, 4, 6, 9, 11, 15, 16, 17, 18, 19, 20, 22, 24, 28], "phase": 2, "replic": [2, 4, 15, 17, 19, 30, 31], "partial": [2, 30, 31], "context": [2, 9, 14, 15, 21, 24, 28, 30, 31], "learn": [2, 3, 6, 16, 25, 28, 30, 31, 33], "connor": 2, "kissan": 2, "decis": [2, 3], "script": [2, 6], "train": [2, 6, 7, 8, 9, 11, 12, 13, 15, 16, 19, 22, 28, 29, 30, 33], "which": [2, 3, 5, 6, 9, 11, 15, 16, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31], "intermedi": [2, 9, 15, 21, 31], "activ": [2, 3, 4, 6, 9, 11, 12, 13, 14, 15, 16, 17, 21, 24, 28, 33], "perform": [2, 5, 6, 18, 19, 21, 28, 30, 31], "attribut": [2, 4, 6, 9, 14, 18, 24, 28, 31], "ablat": [2, 30, 31], "up": [2, 3, 4, 9, 15, 16, 21, 24, 25, 28, 30, 31], "initi": [2, 7, 13, 14, 15, 16, 18, 21, 27, 28, 30, 31], "work": [2, 3, 4, 6, 9, 11, 14, 15, 18, 21, 22, 28, 29, 30, 31, 33], "found": [2, 3, 5, 15, 16, 30, 31], "demo": [3, 17, 22, 29, 32], "how": [3, 6, 9, 15, 20, 24, 25, 29, 30, 31, 33], "basic": [3, 6, 15, 19, 28, 30], "To": [3, 4, 9, 15, 16, 18, 21, 22, 30, 31], "see": [3, 6, 9, 11, 12, 14, 15, 16, 18, 20, 22, 24, 28, 29, 30, 31, 33], "exploratori": [3, 6, 20, 28, 31, 33], "analysi": [3, 6, 9, 12, 15, 20, 28, 31, 33], "practic": [3, 4, 6, 14, 30, 31], "look": [3, 4, 6, 7, 9, 15, 18, 20, 24, 30, 31], "out": [3, 6, 9, 15, 17, 24, 28, 30, 31], "my": [3, 6, 15, 16, 28, 30, 31, 33], "analys": [3, 6, 9, 15, 31], "indirect": [3, 4, 6, 19], "object": [3, 4, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 21, 22, 23, 25, 28], "identif": [3, 4, 6, 19], "record": [3, 6, 31], "myself": [3, 6, 31], "veri": [3, 4, 6, 9, 16, 17, 19, 28, 30, 31, 33], "young": [3, 4, 31], "small": [3, 4, 5, 6, 9, 14, 15, 19, 22, 28, 30, 31, 32, 33], "field": [3, 4, 15, 28, 31, 33], "lot": [3, 4, 6, 9, 10, 23, 24, 28, 30, 31, 33], "open": [3, 4, 15, 19, 33], "problem": [3, 4, 31, 33], "would": [3, 4, 11, 18, 29, 30, 31, 33], "help": [3, 4, 16, 24, 30, 31], "try": [3, 4, 9, 15, 20, 29, 30, 31], "concret": [3, 4, 30, 31], "figur": [3, 24, 30, 31], "where": [3, 5, 9, 10, 11, 12, 15, 16, 18, 20, 21, 22, 24, 25, 28, 30, 31], "skill": [3, 31], "kei": [3, 4, 9, 11, 15, 16, 18, 19, 20, 23, 24, 28, 30, 31], "resourc": [3, 4], "new": [3, 6, 9, 12, 15, 21, 22, 23, 28, 30, 31], "tutori": [3, 4, 30, 31], "scratch": [3, 4, 30], "an": [3, 4, 6, 9, 10, 11, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 33], "accompani": [3, 4, 6, 31], "templat": [3, 19], "yourself": [3, 15, 30, 31], "One": [3, 15, 30, 31, 33], "signific": [3, 21, 29, 30, 31], "design": [3, 9, 12, 30, 31, 33], "made": [3, 19, 30, 31], "wa": [3, 5, 9, 11, 13, 15, 16, 19, 24, 30, 31], "singl": [3, 9, 11, 15, 18, 23, 24, 28, 30, 31], "implement": [3, 11, 12, 15, 18, 24, 28, 29, 30, 31], "could": [3, 30, 31], "support": [3, 6, 11, 12, 15, 16, 20, 21, 28, 29, 30, 31], "rang": [3, 4, 15, 17, 20, 24, 28, 30, 31], "subtli": [3, 18], "differ": [3, 5, 9, 11, 14, 15, 16, 18, 19, 20, 21, 24, 28, 29, 30, 31], "style": [3, 9, 11, 15, 16, 18, 20, 30, 31, 33], "upsid": 3, "just": [3, 4, 9, 12, 14, 15, 16, 19, 24, 28, 30, 31], "arbitrari": [3, 15, 30, 31], "name": [3, 9, 13, 15, 16, 19, 20, 21, 22, 24, 25, 28], "But": [3, 9, 15, 24, 28, 30, 31], "downsid": 3, "py": [3, 11], "compon": [3, 7, 8, 9, 11, 15, 28, 29, 30, 31], "difficult": [3, 9], "recommend": [3, 7, 9, 13, 15, 16, 17, 21, 30, 31], "clean": [3, 24, 28, 30, 31], "minim": [3, 31], "intern": [3, 9, 15, 24, 30, 31, 33], "architectur": [3, 11, 12, 29, 30], "significantli": [3, 11, 15, 19, 24, 30, 31], "clearer": 3, "better": [3, 15, 16, 19, 20, 22, 29, 30, 31], "document": [3, 15, 28, 31], "pip": [3, 29, 30, 31], "git": [3, 29], "import": [3, 9, 14, 15, 17, 19, 23, 24, 28, 29, 33], "known": [3, 33], "easytransform": [3, 31, 33], "break": [3, 9, 30, 31], "been": [3, 9, 15, 28, 29, 31], "sinc": [3, 9, 15, 18, 21, 30, 31], "renam": 3, "old": [3, 22, 31], "version": [3, 6, 15, 19, 21, 29, 30, 31], "legaci": [3, 20], "run": [3, 5, 9, 14, 15, 18, 21, 22, 23, 24, 25, 29, 30, 33], "v1": 3, "avail": [3, 6, 9, 13, 15, 16, 20, 22], "requir": [3, 11, 15, 24, 28], "luckili": 3, "provid": [3, 9, 11, 12, 14, 15, 18, 21, 27, 28], "wai": [3, 5, 9, 15, 21, 28, 29, 30, 31], "those": [3, 5, 14, 15, 21, 28, 30], "configur": [3, 13, 16, 25, 27], "environment": 3, "variabl": [3, 11], "simpli": [3, 30], "token": [3, 6, 9, 11, 15, 16, 17, 18, 19, 20, 22, 24, 28, 29, 30], "hf_token": 3, "agreement": 3, "issu": [3, 15, 30, 31], "attempt": [3, 15], "ue": 3, "befor": [3, 9, 11, 14, 15, 16, 18, 21, 28, 30, 31], "relat": [3, 15, 18, 30, 31], "consol": 3, "output": [3, 6, 9, 11, 12, 15, 16, 18, 20, 21, 24, 28, 30, 31], "point": [3, 9, 11, 14, 15, 16, 17, 21, 28, 30, 33], "As": [3, 15, 28, 30, 31], "23": [3, 30, 31], "24": [3, 15, 28, 30, 31, 32], "current": [3, 9, 11, 14, 15, 16, 18, 20, 29, 30, 31], "co": [3, 28], "mistralai": [3, 22], "mixtral": [3, 5, 22, 32], "8x7b": [3, 22], "v0": [3, 22, 32], "mistral": [3, 16, 18, 19, 22, 32], "7b": [3, 6, 22, 31, 32], "instruct": [3, 22, 31, 32], "mean": [4, 9, 15, 16, 17, 18, 20, 21, 28, 29, 30, 31], "": [4, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 27, 28, 31, 33], "both": [4, 9, 15, 18, 20, 21, 23, 30, 31], "low": [4, 10, 15, 18, 28, 31], "hang": [4, 31], "fruit": [4, 31], "bar": [4, 15], "entri": [4, 18, 23, 24, 31], "The": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 33], "standard": [4, 5, 12, 15, 16, 30, 31], "answer": [4, 9, 24, 28, 30, 31], "why": [4, 9, 18, 28, 30, 31], "yet": [4, 11, 15, 30, 31, 33], "aren": [4, 22, 31], "t": [4, 9, 10, 11, 12, 15, 16, 17, 18, 19, 22, 28, 29, 30, 31, 33], "enough": [4, 9, 30, 31], "peopl": [4, 31], "guid": [4, 31], "arena": 4, "callum": [4, 31], "mcdougal": [4, 31], "comprehens": [4, 31], "introduct": 4, "mech": [4, 30], "interp": [4, 30], "written": [4, 6, 30], "snippet": 4, "copi": [4, 11, 12, 30], "come": [4, 15, 16, 24, 30, 31], "exercis": [4, 30], "solut": [4, 30, 31], "notabl": [4, 15, 21, 30, 31], "video": [4, 6, 30, 31], "me": [4, 22, 31, 33], "good": [4, 6, 9, 19, 28, 30, 31, 33], "cover": [4, 15, 31], "foundat": [4, 31], "concept": [4, 30, 31], "wild": [4, 9, 30, 31], "techniqu": [4, 6, 15, 24, 30, 31], "direct": [4, 9, 15, 17, 21, 24, 31], "logit": [4, 5, 6, 9, 11, 15, 18, 19, 24, 28, 31], "patch": [4, 6, 7, 8], "paper": [4, 6, 9, 15, 16, 18, 19, 24, 31], "read": [4, 6, 9, 15, 29, 31], "200": [4, 31], "explain": [4, 6, 30, 31], "jargon": 4, "unfamiliar": [4, 30], "term": [4, 9, 12, 13, 15, 30], "go": [4, 6, 24, 31], "across": [4, 9, 11, 15, 17, 22, 24, 27, 30, 31], "youtub": 4, "channel": 4, "content": [4, 19, 30, 31], "walkthrough": [4, 30, 31], "due": [5, 15, 31], "top": [5, 15, 28, 30, 31], "k": [5, 9, 10, 11, 15, 17, 18, 24, 28, 30, 31], "gate": [5, 15, 18], "hidden": [5, 16, 31], "amplifi": 5, "greatli": [5, 31, 33], "select": [5, 9, 28, 30, 31], "lead": [5, 6, 11, 21, 28, 31], "higher": [5, 15, 30], "than": [5, 9, 15, 16, 18, 19, 20, 21, 24, 28, 30, 31], "normal": [5, 9, 15, 16, 18, 28, 30, 31, 33], "varianc": [5, 30], "final": [5, 9, 11, 15, 16, 18, 28, 30, 31], "test": [5, 6, 15, 19, 20, 28, 29, 30, 31], "half": [5, 10, 11, 15, 18, 19, 31], "precis": [5, 20, 24, 30, 31], "deviat": [5, 16, 31], "absolut": [5, 11, 15, 16, 18, 20, 28, 30, 31], "compar": [5, 19, 31, 33], "around": [5, 9, 11, 14, 15, 21, 24, 27, 30, 31], "2e": 5, "There": [5, 9, 11, 20, 22, 28, 30, 31, 33], "two": [5, 10, 11, 18, 20, 22, 24, 28, 30, 31], "mitig": 5, "disabl": [5, 15, 20, 21, 30], "preprocess": [5, 11, 30], "option": [5, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28], "from_pretrained_no_process": [5, 15], "increas": [5, 24, 30, 31], "data": [5, 6, 15, 19, 28, 30, 31], "colab": [6, 29, 30, 31, 33], "blob": 6, "ipynb": 6, "causal": [6, 11, 16, 24, 30, 31], "intervent": [6, 24, 30, 31], "identifi": [6, 15, 24, 30, 31], "matter": [6, 15, 24, 30, 31], "produc": [6, 15, 24, 30], "incomplet": 6, "gradient": [6, 9, 21, 25, 31], "take": [6, 9, 15, 18, 21, 24, 28, 30, 31, 33], "approxim": [6, 30, 31], "individu": [6, 9, 15, 18, 30], "bad": [6, 15], "residu": [6, 9, 11, 15, 16, 18, 24, 31], "stream": [6, 9, 11, 15, 16, 18, 24, 28, 31], "probabl": [6, 15, 19, 20, 24, 28, 30, 31], "best": [6, 15, 30, 31], "after": [6, 9, 14, 15, 16, 18, 21, 25, 29, 30, 31, 33], "demonstr": [6, 17, 30, 31], "focus": [6, 30, 31], "less": [6, 15, 18, 30], "rigor": [6, 30, 31], "get": [6, 9, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 24, 27, 29, 30, 31, 33], "grasp": 6, "steal": 6, "liber": [6, 21], "phenomenon": 6, "memoris": 6, "minimis": 6, "loss": [6, 9, 13, 15, 19, 21, 24, 25, 28, 30, 31], "longer": 6, "generalis": [6, 30, 31], "sharp": [6, 31], "decreas": [6, 18, 28, 30], "well": [6, 15, 17, 21, 24, 28, 30, 31], "show": [6, 15, 17, 20, 29, 30, 31, 33], "task": [6, 11, 15, 16, 19, 24, 25, 29, 30], "modular": [6, 12, 28], "addit": [6, 11, 15, 30], "verifi": [6, 30, 31], "grok": 6, "light": 6, "explan": [6, 24, 30], "ll": [6, 15, 20, 30, 31], "pair": [6, 10, 15, 18, 20, 28, 30, 31], "seri": [6, 9, 31], "base": [6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32], "detector": [6, 20], "detect": [6, 20, 30, 31], "sever": [6, 9, 15, 28, 30, 31], "creat": [6, 9, 15, 18, 21, 30, 31], "own": [6, 30, 31], "custom": [6, 15, 16, 18, 19, 21, 28, 30, 31], "algorithm": [6, 10, 16, 31, 33], "interact": [6, 30, 31], "neuroscop": [6, 31], "hacki": [6, 28], "bug": [6, 9, 16, 28, 31], "web": [6, 31], "visualis": [6, 30], "even": [6, 10, 15, 16, 18, 19, 22, 30, 31, 33], "profession": 6, "front": 6, "visual": [6, 11, 29, 31], "dynam": [6, 16, 31], "updat": [6, 15, 23, 24, 27, 29, 30, 31], "llama": [6, 16, 22, 32], "convert": [6, 11, 15, 22, 28, 30, 31], "meta": [6, 15, 22, 28, 30, 31, 32], "now": [6, 15, 16, 30, 31], "until": [6, 9, 14, 15, 21, 29, 30, 31], "multi": [6, 9, 28, 31], "gpu": [6, 9, 10, 11, 15, 30, 31], "great": [6, 31, 33], "access": [6, 9, 14, 16, 21, 28, 30], "know": [6, 9, 11, 30, 31], "No": [6, 29, 31], "posit": [6, 9, 11, 14, 15, 16, 18, 19, 20, 21, 22, 24, 28, 30, 31], "experi": [6, 12, 13, 16, 30, 31, 33], "embed": [6, 9, 11, 15, 16, 18, 30, 31], "previou": [6, 9, 15, 18, 20, 30, 31], "port": 6, "weight": [6, 11, 13, 14, 15, 16, 18, 25, 28, 30, 31, 33], "excel": [6, 9, 30, 31, 33], "sequenc": [6, 11, 15, 16, 18, 19, 20, 21, 24, 28, 30, 31], "investig": [6, 9, 15, 20, 30, 31], "worth": [6, 9, 30, 31], "interest": [6, 11, 15, 30, 31], "topic": 6, "svd": [6, 10, 15, 17, 31], "conjectur": 6, "post": [6, 9, 17, 18, 30, 31], "singular": [6, 10, 15, 17, 31], "valu": [6, 9, 10, 11, 14, 15, 16, 18, 20, 22, 23, 24, 28, 30, 31, 33], "decomposit": [6, 9, 10, 15, 30, 31], "matric": [6, 10, 11, 15, 17, 18, 30, 31], "surprisingli": 6, "reproduc": [6, 13, 16, 20], "further": [6, 9, 15, 28, 30, 31], "tracr": 6, "cool": 6, "deepmind": 6, "tool": [6, 31, 33], "compil": 6, "program": [6, 31, 33], "rasp": 6, "jax": 6, "form": [6, 9, 10, 15, 24, 30, 31], "pytorch": [6, 13, 15, 16, 19, 21, 31], "brows": 7, "first": [7, 9, 15, 16, 19, 22, 24, 28, 30, 31], "activationcach": [7, 8, 11, 14, 15, 20, 24, 28, 30, 31], "submodul": 7, "factoredmatrix": [7, 8, 11, 18, 28, 31], "hookedencod": [7, 8, 27, 29], "hookedsa": [7, 8, 13, 14], "hookedsaeconfig": [7, 8, 12, 14], "hookedsaetransform": [7, 8, 12], "hookedtransformerconfig": [7, 8, 15, 18, 22, 23, 27], "svdinterpret": [7, 8], "eval": [7, 8, 31], "head_detector": [7, 8], "hook_point": [7, 8, 15, 31], "past_key_value_cach": [7, 8], "util": [7, 8, 9, 10, 15, 20, 21, 22, 25, 30, 31], "subpackag": 7, "core": [9, 15, 30, 31, 33], "wrapper": [9, 11, 14, 15, 24, 27, 31], "store": [9, 13, 15, 16, 18, 21, 23, 24, 25, 30, 31], "forward": [9, 11, 12, 14, 15, 16, 18, 21, 23, 31], "pass": [9, 12, 14, 15, 16, 18, 20, 21, 22, 23, 28, 31], "varieti": [9, 31], "helper": [9, 14, 15, 18, 19, 21, 24, 28, 31], "function": [9, 11, 13, 14, 15, 16, 18, 20, 21, 22, 24, 25, 27, 28, 31, 33], "them": [9, 14, 15, 18, 21, 24, 28, 30, 31], "start": [9, 15, 18, 24, 28, 30, 31], "class": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 28], "skim": 9, "method": [9, 11, 14, 15, 16, 21, 22, 23, 28, 30, 31], "refer": [9, 15, 18, 21, 30, 31], "back": [9, 16, 18, 31], "depend": [9, 15, 31], "cache_dict": 9, "dict": [9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 28], "str": [9, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31], "tensor": [9, 10, 11, 12, 14, 15, 17, 18, 20, 21, 23, 24, 28, 30, 31], "has_batch_dim": 9, "bool": [9, 11, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 28], "run_with_cach": [9, 11, 14, 15, 21, 30, 31], "particular": [9, 17, 20, 30, 31], "behaviour": [9, 15, 30, 31], "modal": 9, "step": [9, 15, 16, 22, 25, 28, 30, 31], "most": [9, 15, 21, 28, 30, 31, 33], "respons": [9, 16, 30], "prompt": [9, 15, 18, 19, 24, 28, 29, 30, 31], "did": [9, 28, 30, 31], "chicken": 9, "road": [9, 28], "might": [9, 11, 30], "specif": [9, 11, 14, 15, 18, 20, 24, 30, 31], "sublay": 9, "mlp": [9, 11, 15, 16, 18, 24, 28, 29, 30, 31], "kind": [9, 30, 31], "commonli": 9, "fall": 9, "under": [9, 15, 18], "categori": [9, 30], "dla": 9, "load": [9, 11, 14, 15, 16, 19, 22, 28, 29, 30, 33], "pretrain": [9, 11, 14, 15, 16, 19, 22, 28, 29, 30, 31], "_logit": 9, "residual_stream": 9, "label": [9, 15, 16, 18, 22, 30, 31], "decompose_resid": [9, 30], "return_label": [9, 30], "0": [9, 11, 13, 14, 15, 16, 17, 18, 20, 22, 25, 28, 30, 31, 32], "emb": [9, 18, 28, 31], "pos_emb": [9, 16, 31], "0_attn_out": 9, "proceed": 9, "space": [9, 11, 15, 28, 30, 31], "match": [9, 15, 20, 30], "logit_attr": 9, "shape": [9, 11, 12, 15, 18, 24, 28, 30, 31], "torch": [9, 11, 13, 15, 16, 18, 21, 22, 24, 27, 28, 29, 30, 31], "size": [9, 13, 15, 16, 18, 19, 25, 28, 30, 31], "10": [9, 15, 17, 28, 30, 31, 32], "7": [9, 19, 29, 30, 31, 32], "most_important_component_idx": 9, "argmax": [9, 29, 30], "3_attn_out": 9, "dig": [9, 30, 31, 33], "granular": 9, "get_full_resid_decomposit": 9, "larger": [9, 19, 30, 31], "stack": [9, 11, 15, 24, 28, 30, 31], "remain": [9, 15, 21, 31], "equal": [9, 16], "struggl": 9, "construct": [9, 11], "joke": 9, "last": [9, 15, 28, 29, 31], "trivial": 9, "few": [9, 11, 30, 31], "call": [9, 11, 15, 16, 18, 21, 22, 28, 30, 31], "accumulated_resid": [9, 30], "other": [9, 11, 12, 15, 18, 20, 21, 22, 24, 30], "biggest": 9, "footgun": [9, 21], "sourc": [9, 13, 15, 16, 18, 19, 24, 33], "keep": [9, 14, 15, 21, 29, 30, 31, 33], "track": [9, 14, 30], "index": [9, 11, 15, 16, 17, 18, 22, 24, 27, 28, 30, 31], "dimens": [9, 13, 14, 15, 16, 18, 21, 24, 28, 30, 31], "vector": [9, 10, 15, 17, 18, 24, 30, 31], "q": [9, 11, 15, 18, 24], "z": [9, 15, 18, 20, 24, 30, 31], "batch": [9, 11, 14, 15, 18, 19, 21, 23, 24, 25, 28, 30, 31], "po": [9, 11, 14, 15, 18, 24, 28, 30, 31], "head_index": [9, 15, 17, 18, 24, 30, 31], "d_head": [9, 11, 12, 15, 16, 18, 22, 23, 28, 30, 31, 32], "pattern": [9, 11, 15, 18, 20, 24, 31], "result": [9, 11, 15, 16, 18, 20, 22, 24, 28, 30, 31, 33], "softmax": [9, 15, 18, 28, 31], "attn_scor": [9, 18], "pre": [9, 15, 16, 18, 20, 28, 29], "query_po": [9, 18, 30], "key_po": [9, 18, 30], "d_model": [9, 11, 15, 16, 18, 22, 28, 30, 31, 32], "mid": [9, 30], "solu_ln": [9, 16], "between": [9, 15, 18, 20, 24, 28, 30, 31, 33], "layernorm": [9, 11, 15, 16, 18, 28, 29, 30], "d_mlp": [9, 11, 15, 16, 18, 22, 28, 31, 32], "resid_pr": [9, 16, 18, 24, 30, 31], "resid_mid": [9, 24], "resid_post": [9, 16, 30], "attn_out": [9, 15, 16, 24, 30], "mlp_out": [9, 15, 16, 18, 24, 30], "ln": [9, 15, 16, 18, 30, 31], "lnpre": [9, 16], "scale": [9, 15, 16, 18, 28, 30, 31], "sometim": [9, 19, 30], "miss": [9, 30], "becaus": [9, 10, 11, 15, 16, 18, 19, 28, 30, 31, 33], "appli": [9, 14, 15, 16, 18, 21, 24, 28, 29, 30, 31], "remove_batch_dim": [9, 14, 21, 28, 31], "batch_siz": [9, 11, 14, 18, 19, 21, 23, 25, 30, 31], "robust": [9, 30], "annot": [9, 31], "layers_cov": 9, "queri": [9, 11, 15, 16, 18, 20, 24, 31], "batch_and_pos_dim": 9, "ve": [9, 15, 18, 19, 21, 30, 33], "remov": [9, 10, 14, 15, 18, 21, 28, 30, 31, 33], "slice": [9, 21, 28, 30], "dictionari": [9, 11, 13, 14, 15, 16, 20, 21, 22, 28, 31], "whether": [9, 11, 13, 14, 15, 16, 18, 19, 21, 22, 24, 25, 28, 30, 31], "int": [9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31], "none": [9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 30, 31], "incl_mid": [9, 30], "fals": [9, 11, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31], "apply_ln": [9, 30], "pos_slic": [9, 21, 30], "union": [9, 11, 12, 14, 15, 17, 18, 20, 21, 22, 23, 24, 27, 28, 30], "tupl": [9, 10, 11, 14, 15, 18, 20, 21, 24, 28, 31], "ndarrai": [9, 15, 21, 28], "mlp_input": [9, 15], "float": [9, 10, 11, 12, 14, 15, 16, 18, 20, 22, 23, 24, 25, 28, 30, 31], "accumul": [9, 15, 30], "sub": [9, 31], "www": 9, "lesswrong": 9, "ackrb8wdpdan6v6ru": 9, "thought": [9, 30, 31], "believ": [9, 19, 30], "vocabulari": [9, 16, 30, 31], "rememb": 9, "norm": [9, 10, 15, 16, 18, 22, 25, 30, 31], "decod": [9, 29], "therefor": [9, 15, 28], "multipli": [9, 15, 18, 20, 30, 31], "unembed": [9, 11, 15, 30, 31], "matrix": [9, 10, 11, 15, 16, 17, 18, 20, 28, 30], "w_u": [9, 11, 15, 30, 31], "broken": [9, 21, 28, 30, 31], "down": [9, 15, 18, 30, 31], "einop": [9, 30, 31], "einsum": [9, 30, 31], "panda": [9, 24], "pd": [9, 24], "devic": [9, 11, 13, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 29, 30, 31], "answer_token": [9, 30], "to_single_token": [9, 15, 30, 31], "2975": 9, "accum_resid": 9, "last_token_accum": 9, "9": [9, 28, 30, 31, 32], "64": [9, 22, 28, 31, 32], "50257": [9, 22, 31, 32], "layers_unembed": 9, "d_vocab": [9, 11, 14, 15, 16, 17, 22, 24, 28, 31, 32], "rank": [9, 10, 15, 18, 28, 30, 31], "correct": [9, 24, 27, 28, 30, 31], "sorted_indic": 9, "argsort": 9, "dim": [9, 15, 28, 29, 30, 31], "descend": [9, 31], "rank_answ": 9, "nonzero": [9, 29], "as_tupl": 9, "0_pre": 9, "4442": 9, "1_pre": [9, 30], "382": 9, "2_pre": 9, "982": 9, "3_pre": 9, "1160": 9, "4_pre": 9, "408": 9, "5_pre": 9, "145": 9, "6_pre": 9, "78": 9, "7_pre": 9, "387": 9, "final_post": 9, "6": [9, 15, 22, 28, 29, 30, 31, 32], "dtype": [9, 11, 13, 15, 16, 18, 22, 27, 30, 31], "int64": [9, 28], "exclud": [9, 20], "n_layer": [9, 11, 15, 16, 22, 24, 27, 30, 31, 32], "immedi": [9, 18, 28, 30, 31], "indic": [9, 11, 18, 21, 24, 28, 30, 31], "taken": [9, 15, 31], "input": [9, 11, 12, 13, 15, 16, 18, 21, 22, 23, 24, 28, 30, 31], "l": [9, 11, 15, 30, 31], "noth": [9, 11, 15, 21, 28, 30, 31], "essenti": [9, 15, 30, 31, 33], "rather": [9, 15, 16, 18, 24, 28, 30, 31], "graph": [9, 30, 31], "apply_ln_to_stack": [9, 15, 28, 30], "residual_stack": [9, 30], "num_compon": 9, "batch_slic": 9, "batch_and_pos_dims_out": 9, "eg": [9, 12, 13, 14, 15, 19, 24, 28, 30, 31], "treat": [9, 15, 16, 30, 31], "factor": [9, 10, 15, 16, 30], "simul": [9, 15, 30, 31], "global": [9, 18, 21, 28, 30, 31], "entir": [9, 15, 24, 30], "element": [9, 15, 18, 20, 24, 28, 31], "unchang": [9, 11, 15, 28, 30, 31], "whose": [9, 11, 15, 19, 28, 30], "trail": [9, 10, 28], "assum": [9, 11, 15, 16, 18, 21, 24, 25, 28, 30], "hook_scal": [9, 28, 30, 31], "unemb": [9, 15, 16, 18, 30, 31], "map": [9, 11, 15, 18, 20, 21, 30, 31], "ie": [9, 11, 15, 16, 18, 22, 24, 28, 30, 31], "ln2": [9, 18, 28, 31], "ln1": [9, 16, 18, 28, 31], "ln_final": [9, 15, 30, 31], "over": [9, 15, 24, 28, 30, 31], "alreadi": [9, 15, 28, 30, 31], "apply_slice_to_batch_dim": 9, "compute_head_result": 9, "comput": [9, 10, 15, 18, 20, 21, 23, 24, 28, 30, 31, 33], "amount": [9, 16, 30], "sum": [9, 10, 15, 16, 18, 20, 28, 30, 31], "plu": 9, "b_o": [9, 11, 15, 31], "intend": [9, 16, 28, 29], "enabl": [9, 15, 30, 31, 33], "use_attn_result": [9, 15, 16], "forget": 9, "liter": [9, 11, 15, 17, 20, 21, 24], "incl_emb": 9, "decompos": 9, "incl": 9, "expand_neuron": 9, "bias": [9, 11, 15, 16, 25, 30], "expand": [9, 15, 18], "everi": [9, 11, 15, 18, 21, 24, 25, 28, 30, 31], "get_neuron_result": 9, "neuron_slic": 9, "num_neuron": 9, "subset": [9, 16, 19, 30, 31], "specifi": [9, 11, 15, 16, 18, 19, 20, 21, 27, 28, 31], "expens": [9, 10], "cheap": 9, "hook_emb": [9, 28, 31], "hook_pos_emb": [9, 31], "block": [9, 13, 14, 15, 16, 18, 24, 28, 29, 30, 31], "hook_resid_pr": [9, 31], "incorrect_token": [9, 30], "typic": [9, 11, 15, 18, 20, 30, 31], "calcul": [9, 10, 11, 15, 16, 18, 20, 28, 30, 31], "revers": [9, 10, 24, 28, 30, 31, 33], "dot": [9, 15, 18, 28], "product": [9, 10, 11, 18, 31], "incorrect": [9, 15, 24, 30, 31], "arxiv": [9, 15, 16, 18, 19], "org": [9, 15, 16, 18, 19, 31, 33], "ab": [9, 10, 15, 18, 20, 30, 31], "2211": [9, 19], "00593": [9, 19], "john": [9, 30, 31], "mari": [9, 30, 31], "went": [9, 30, 31], "shop": [9, 30, 31], "gave": [9, 19, 30, 31], "bag": [9, 30], "were": [9, 15, 16, 19, 28, 30, 31, 33], "choos": [9, 30, 31], "impact": 9, "final_ln": 9, "residual_stack_item": 9, "dure": [9, 14, 18, 21, 23, 31, 33], "stack_activ": 9, "activation_nam": [9, 24, 30], "sublayer_typ": 9, "flexibl": 9, "given": [9, 10, 11, 14, 15, 17, 20, 21, 22, 24, 27, 28, 30, 31], "strictli": [9, 31], "get_act_nam": [9, 28, 30, 31], "infer": [9, 12, 15, 18, 24, 30, 31], "incl_remaind": 9, "stack_head_result": [9, 30], "axi": [9, 18, 24, 28, 30, 31], "n_head": [9, 11, 12, 15, 16, 18, 22, 23, 24, 28, 30, 31, 32], "notat": [9, 30], "l0h0": 9, "stack_neuron_result": 9, "l0n0": 9, "super": [9, 15, 28, 31], "memori": [9, 10, 11, 15, 16, 30, 31], "short": [9, 28, 30, 31, 33], "move_model": 9, "move": [9, 11, 15, 24, 29, 30, 31], "mostli": [9, 30, 31], "finish": [9, 15, 28, 30, 31], "save": [9, 15, 16, 20, 25, 28, 30, 31], "howev": [9, 15, 18, 19, 30, 31], "oper": [9, 30, 31], "slower": 9, "unless": [9, 15, 16, 19, 31], "deprec": 9, "toggle_autodiff": 9, "toggl": [9, 15], "autodiff": [9, 31], "set_grad_en": [9, 29, 30, 31], "state": [9, 14, 15, 21, 30, 31, 33], "pretti": [9, 15, 28, 30, 31], "danger": 9, "turn": [9, 15, 28, 30, 31], "off": [9, 15, 19, 28, 30, 31], "abil": [9, 24, 30], "complet": [9, 18, 30, 31], "easi": [9, 15, 28, 30, 31, 33], "bunch": [9, 11, 14, 15, 21, 30, 31], "don": [9, 11, 15, 16, 17, 19, 28, 30, 31, 33], "realis": [9, 30], "consum": [9, 10], "downstream": 9, "delet": [9, 28, 30], "stick": [9, 30], "often": [9, 15, 16, 22, 28, 30, 31], "troubl": 9, "its": [9, 15, 18, 21, 29, 30, 31, 33], "mess": [9, 15, 28, 31], "inference_mod": 9, "decor": 9, "achiev": [9, 31], "similar": [9, 11, 14, 15, 18, 20, 30, 31], "effect": [9, 15, 24, 30, 31], "requires_grad": 9, "repres": [10, 11, 16, 18, 20, 24, 28, 30, 31], "effici": [10, 18, 28, 31], "eigenvalu": 10, "ldim": [10, 31], "mdim": [10, 31], "rdim": [10, 31], "properti": [10, 11, 15, 18, 28, 30, 31], "leading_dim": [10, 28], "ba": 10, "sens": [10, 21, 30, 31], "u": [10, 15, 24, 28, 30, 31], "vh": [10, 15], "collapse_l": 10, "collaps": [10, 30, 31], "left": [10, 15, 18, 28, 30, 31, 33], "side": [10, 15], "orthogon": [10, 15], "self": [10, 11, 15, 18, 28, 31], "collapse_r": 10, "analog": [10, 30, 31], "apart": [10, 28, 30, 31], "zero": [10, 15, 18, 20, 28, 30, 31], "bav": 10, "kv": 10, "abav": 10, "kav": 10, "av": 10, "eigenvector": [10, 31], "get_corn": [10, 28, 30], "make_even": 10, "sqrt": [10, 15, 16, 28], "diag": 10, "equival": [10, 15, 18, 30, 31], "factoris": [10, 15, 18, 31], "row": [10, 15, 24], "col": 10, "ndim": 10, "frobeniu": [10, 31], "squar": [10, 18, 28, 31], "m": [10, 18, 28, 30, 31], "st": 10, "transpos": [10, 28], "obviou": [10, 15, 30], "thing": [10, 15, 16, 18, 24, 30, 31, 33], "unsqueez": [10, 28], "hook": [11, 12, 13, 14, 15, 16, 18, 21, 30], "encod": [11, 18, 28, 31], "contain": [11, 15, 18, 19, 20, 21, 22, 23, 28, 30, 31], "bert": [11, 18, 22, 31, 32], "separ": [11, 15, 16, 21, 28, 30, 31], "move_to_devic": [11, 15], "kwarg": [11, 14, 15, 22, 28, 30, 31], "hookedrootmodul": [11, 12, 14, 15, 21, 31], "hookpoint": [11, 14, 15, 21, 30, 31], "inherit": [11, 31], "limit": [11, 15, 29, 30], "mvp": 11, "mask": [11, 15, 18, 28, 29, 30], "mlm": 11, "next": [11, 15, 28, 29, 30, 31], "sentenc": [11, 15, 18, 20, 30, 31], "nsp": 11, "dropout": 11, "inconsist": [11, 17], "fine": [11, 31], "fold": [11, 15, 18, 22, 29, 30], "ov": [11, 15, 17, 18, 30, 31], "o": [11, 29, 31], "qk": [11, 15, 18, 30], "w_e": [11, 15, 31], "conveni": [11, 15, 16, 21, 28, 31], "w_e_po": [11, 15], "n_ctx": [11, 15, 16, 18, 22, 31, 32], "concaten": [11, 15, 28, 30, 31], "w_po": [11, 15, 31], "overcomplet": [11, 15], "basi": [11, 15], "w_k": [11, 15, 16, 18, 31], "w_o": [11, 15, 18, 30, 31], "w_q": [11, 15, 18, 31], "w_v": [11, 15, 18, 31], "w_in": [11, 15, 17, 18, 31], "w_out": [11, 15, 17, 18, 31], "all_head_label": [11, 15], "format": [11, 15, 21, 30, 31], "h": [11, 15, 30, 31], "b_k": [11, 15, 18, 31], "b_q": [11, 15, 31], "b_u": [11, 15, 30, 31], "bia": [11, 15, 16, 18, 30, 31], "b_v": [11, 15, 18, 31], "b_in": [11, 15, 18, 31], "b_out": [11, 15, 18, 31], "buffer": [11, 15], "modifi": [11, 15], "cuda": [11, 13, 15, 16, 19, 22], "associ": [11, 15, 21], "optim": [11, 15, 25, 30], "live": [11, 15, 30, 31], "while": [11, 15, 18, 21, 30, 31], "return_typ": [11, 15, 21, 30, 31], "token_type_id": [11, 18], "one_zero_attention_mask": 11, "binari": [11, 18], "id": [11, 15, 18], "belong": [11, 18], "cl": [11, 18, 31], "sep": [11, 18], "sequence_length": [11, 18, 20, 28], "attend": [11, 16, 18, 28, 30, 31], "ignor": [11, 15, 16, 18, 21, 28, 31], "primarili": 11, "pad": [11, 15, 18, 28, 30, 31], "instanc": [11, 12, 18, 20, 21, 30], "shorter": [11, 15, 31], "right": [11, 15, 18, 24, 28, 30, 31], "classmethod": [11, 13, 15, 16, 23, 28], "model_nam": [11, 15, 16, 22, 31], "checkpoint_index": [11, 15, 16, 22, 31], "checkpoint_valu": [11, 15, 16, 22, 31], "hf_model": [11, 15], "float32": [11, 13, 15, 16, 18, 22, 30], "from_pretrained_kwarg": [11, 15], "huggingfac": [11, 15, 16, 19, 22, 28, 31, 33], "bertformaskedlm": 11, "unlik": [11, 15, 24, 31], "mp": [11, 15], "model_arg": [11, 14, 15, 21], "return_cache_object": [11, 14, 15], "otherwis": [11, 14, 15, 19, 20, 28], "device_or_dtyp": [11, 15, 27], "print_detail": [11, 15, 27, 28], "cast": [11, 15], "non_block": [11, 15], "memory_format": [11, 15], "channels_last": [11, 15], "Its": [11, 15], "complex": [11, 15, 16, 30, 31], "integr": [11, 15, 22], "tri": [11, 15, 30, 31, 33], "asynchron": [11, 15], "respect": [11, 15, 21, 28, 31], "host": [11, 15, 22], "pin": [11, 15], "below": [11, 15, 30], "desir": [11, 15], "4d": [11, 15], "keyword": [11, 14, 15, 21, 31], "argument": [11, 14, 15, 16, 21, 22, 28, 31], "xdoctest": [11, 15], "ignore_w": [11, 15], "non": [11, 15, 16, 18, 19, 28, 30, 31], "determinist": [11, 15, 28, 30], "nn": [11, 15, 21, 31], "1913": [11, 15], "3420": [11, 15], "5113": [11, 15], "2325": [11, 15], "doubl": [11, 15], "in_featur": [11, 15], "out_featur": [11, 15], "float64": [11, 15], "env": [11, 15], "torch_doctest_cuda1": [11, 15], "gpu1": [11, 15], "1914": [11, 15], "5112": [11, 15], "2324": [11, 15], "float16": [11, 15], "cdoubl": [11, 15], "3741": [11, 15], "j": [11, 15, 16, 18, 22, 30, 31, 32], "2382": [11, 15], "5593": [11, 15], "4443": [11, 15], "complex128": [11, 15], "6122": [11, 15], "1150": [11, 15], "sae": [12, 13, 14], "saelen": 12, "jbloomau": 12, "fairli": [12, 15, 30, 31], "doesn": [12, 15, 19, 28, 30, 31], "strong": 12, "assumpt": 12, "attach": [12, 14, 15, 31], "add_sa": [12, 14], "d_in": [12, 13, 28], "hook_z": [12, 13, 14, 30, 31], "reconstruct": 12, "d_sae": 13, "hook_nam": [13, 21], "use_error_term": 13, "seed": [13, 15, 16, 25, 31], "random": [13, 15, 16, 19, 25, 30, 31], "numpi": [13, 15, 16, 28, 30], "els": [13, 15, 16, 18, 22, 28, 29, 30, 31], "from_dict": [13, 16], "config_dict": [13, 16], "instanti": [13, 15, 16, 31], "set_seed_everywher": [13, 16], "to_dict": [13, 16], "model_kwarg": [14, 21], "__init__": [14, 15, 18, 21, 28, 31], "init": 14, "permanantli": 14, "reset_sa": 14, "overwrit": 14, "exist": [14, 20, 30, 31], "act_nam": [14, 30, 31], "prev_sa": 14, "reset": [14, 21], "mainli": [14, 16], "restor": [14, 28], "previous": [14, 30], "temporarili": [14, 30, 31], "run_with_sa": 14, "replac": [14, 15, 16, 24, 30, 31, 33], "run_with_cache_with_sa": 14, "reset_saes_end": 14, "By": [14, 15, 19, 21, 22, 24, 28, 30, 31], "origin": [14, 16, 17, 18, 30, 31], "run_with_hooks_with_sa": 14, "fwd_hook": [14, 21, 30, 31], "callabl": [14, 18, 21, 24], "bwd_hook": [14, 21], "reset_hooks_end": [14, 21, 30], "clear_context": [14, 21], "run_with_hook": [14, 21, 30, 31], "clear": [14, 21, 31], "temporari": [14, 21, 28, 31], "exit": [14, 21, 28], "sae_cfg": 14, "spliced_logit": 14, "get_deep_attr": 14, "obj": [14, 28], "nest": [14, 28], "subclass": [14, 18, 21], "set_deep_attr": 14, "swap": [14, 28, 30], "vice": 14, "versa": 14, "extract": [15, 31], "harder": [15, 24, 30], "aim": [15, 30, 33], "simplifi": [15, 30, 31], "within": [15, 18, 20, 21, 24, 28, 30, 31], "inspect": [15, 30], "alter": 15, "facilit": 15, "deeper": 15, "pretrainedtokenizerbas": 15, "default_padding_sid": 15, "50": [15, 25, 31], "initialis": [15, 16], "although": [15, 18, 21], "randomli": [15, 16, 31], "test_prompt": [15, 28, 30, 31], "w_gate": [15, 18], "tokenizer_nam": [15, 16], "cannot": [15, 28, 29, 31], "explicitli": [15, 16, 18, 19, 22, 24, 31], "n_devic": [15, 16, 22, 27], "greater": [15, 20], "split": [15, 18, 22, 28, 30, 31], "multipl": [15, 20, 27, 28, 31], "accumulated_bia": 15, "include_mlp_bias": 15, "layers_accumulated_ov": 15, "all_composition_scor": [15, 28], "composit": [15, 30, 31], "score": [15, 18, 20, 24, 30], "l1": 15, "h1": 15, "l2": 15, "h2": [15, 30], "upper": [15, 18], "triangular": [15, 20, 28, 31], "third": [15, 31], "pub": [15, 28], "2021": 15, "framework": [15, 18, 30, 31], "html": [15, 28, 30], "20abov": 15, "20diagram": 15, "20show": 15, "20q": 15, "2d": [15, 28], "2c": 15, "20k": [15, 28], "20and": 15, "20v": 15, "2dcomposit": 15, "three": [15, 24, 28, 30], "metric": [15, 20, 24, 30, 31], "center_unemb": [15, 30], "state_dict": 15, "center": [15, 16, 18, 30, 31], "subtract": [15, 20, 30], "themselv": 15, "translat": [15, 30, 31], "invari": 15, "log": [15, 25, 28, 30, 31], "prob": [15, 28, 30, 31], "slightli": [15, 28, 30], "misl": 15, "someth": [15, 19, 30], "center_writing_weight": [15, 30, 31], "fold_layer_norm": [15, 22], "check_hooks_to_add": [15, 21], "hook_point_nam": [15, 21], "dir": [15, 21], "fwd": [15, 21], "is_perman": [15, 21], "prepend": [15, 16, 19, 21, 22, 28, 31], "overrid": [15, 16, 21, 22, 28], "fold_bias": 15, "center_weight": 15, "rm": [15, 18], "consist": [15, 30, 31], "neighbour": 15, "further_com": [15, 16], "md": [15, 16], "fold_value_bias": 15, "alwai": [15, 16, 24, 30, 31], "constant": [15, 16, 18, 30, 31], "togeth": [15, 28, 30, 31], "easier": [15, 19, 30, 31, 33], "formal": 15, "b_o_new": 15, "b_o_origin": 15, "sum_head": 15, "b_v_head": 15, "w_o_head": 15, "loss_per_token": 15, "prepend_bo": [15, 16, 19, 22, 28, 30], "use_default_valu": 15, "padding_sid": [15, 28, 30], "start_at_lay": 15, "shortformer_pos_emb": [15, 18], "attention_mask": [15, 18, 23, 28], "stop_at_lay": 15, "past_kv_cach": [15, 18], "hookedtransformerkeyvaluecach": [15, 18, 23], "either": [15, 20, 21, 22, 24, 30, 31], "flag": [15, 16, 19, 21, 24, 28, 30, 31], "entropi": [15, 28, 30, 31], "per": [15, 24, 28, 30, 31], "averag": [15, 19, 30, 31], "scalar": [15, 18, 21, 31], "default_prepend_bo": [15, 16, 19, 22, 28, 31], "bo": [15, 16, 20, 22, 28, 30, 31], "impli": 15, "usag": [15, 30], "accordingli": [15, 16, 18, 22, 30, 31], "lose": [15, 16, 22], "empir": [15, 16, 22, 24, 31], "seem": [15, 16, 19, 22, 30, 31], "inclus": 15, "skip": [15, 30, 31], "neg": [15, 28, 30, 31], "shortform": [15, 16, 18, 22], "positional_embedding_typ": [15, 16, 18], "stop": 15, "exclus": [15, 28], "etc": [15, 24, 30, 31, 33], "frozen": [15, 23], "pai": [15, 18, 30], "through": [15, 30, 31], "correctli": 15, "okai": 15, "twice": [15, 19, 30, 31], "accident": [15, 21], "second": [15, 19, 30, 31], "fold_ln": [15, 22, 30, 31], "refactor_factored_attn_matric": [15, 30], "automodelforcausallm": 15, "process": [15, 16, 22, 28, 30, 31], "autoregress": [15, 25], "neo": [15, 18, 22, 31, 32], "gptj": [15, 22], "opt": [15, 22, 31, 32], "solu": [15, 16, 22, 28, 31, 32], "checkpoint": [15, 16, 22, 25], "neelnanda": [15, 22], "stanford": [15, 16, 18, 22, 31, 32], "crfm": [15, 22, 31], "load_and_process_state_dict": 15, "alia": [15, 22, 28, 31], "subsequ": [15, 22, 30, 31], "regular": [15, 18], "batchnorm": [15, 30, 31], "mathemat": [15, 18, 30, 31], "w_": 15, "b_": 15, "w": 15, "layernormpr": [15, 18], "eff": 15, "ext": 15, "wise": [15, 20], "computation": [15, 31], "handl": [15, 21], "wish": 15, "defin": [15, 18, 21, 28, 30, 31], "x_1": [15, 31], "x_0": [15, 31], "x_2": [15, 31], "frac": [15, 31], "x_3": 15, "cdot": 15, "x_4": 15, "idea": [15, 18, 24, 30, 31, 33], "preced": [15, 28, 30, 31], "never": [15, 31], "w_write": 15, "keepdim": 15, "affect": [15, 24, 30], "fed": [15, 20], "exactli": [15, 22, 30, 31], "1000": [15, 19, 28, 31], "recreat": 15, "onto": [15, 22, 30], "mix": [15, 28, 30, 31], "linearli": 15, "technic": [15, 30, 31], "deriv": [15, 31], "broadcast_b_v": 15, "broadcast": 15, "And": [15, 24, 30, 31], "destination_posit": [15, 31], "source_posit": [15, 31], "along": [15, 18, 28, 30, 31], "source_": 15, "destin": [15, 16, 24, 31], "behavior": [15, 16, 22, 30], "cache_dir": [15, 28], "torch_dtyp": 15, "compat": [15, 22, 29], "especi": [15, 30, 31], "bfloat16": 15, "boolean": [15, 21, 24, 28, 30, 31], "max_new_token": [15, 31], "stop_at_eo": 15, "eos_token_id": [15, 28], "do_sampl": 15, "top_k": [15, 28, 30, 31], "top_p": [15, 28], "temperatur": [15, 28, 31], "freq_penalti": [15, 28], "use_past_kv_cach": 15, "verbos": 15, "pos_plus_new_token": 15, "sampl": [15, 19, 28], "eos_token": 15, "reach": [15, 31], "avoid": [15, 23, 28, 30, 31], "fiddl": 15, "rag": 15, "eot": 15, "throw": 15, "awai": [15, 30], "enter": [15, 30, 31, 33], "messi": [15, 31], "maximum": [15, 16, 18, 25, 31], "stable_lm": 15, "distribut": [15, 27, 28, 30, 31], "greedi": [15, 28], "search": [15, 20, 30, 31], "max": [15, 30], "mass": 15, "cumul": [15, 28], "temp": [15, 28], "inf": 15, "uniform": [15, 28], "frequenc": [15, 28, 30], "penalti": [15, 28], "penalis": 15, "speed": [15, 30], "applic": [15, 28], "whatev": [15, 30], "tqdm": [15, 31], "get_token_posit": [15, 30, 31], "single_token": [15, 31], "present": 15, "gotcha": [15, 17, 30], "Be": 15, "care": [15, 18, 21, 30, 31], "weird": [15, 16, 30, 31], "carefulli": [15, 30], "correspond": [15, 18, 20, 24, 28, 30, 31], "dummi": [15, 21, 31], "init_weight": [15, 16], "empti": [15, 21], "bulk": 15, "ensur": [15, 30], "determin": [15, 18, 24, 27, 28, 30, 31], "NOT": [15, 21, 28, 31], "scheme": 15, "far": [15, 28, 30, 31], "tell": [15, 19, 30, 31], "date": 15, "gotten": 15, "round": [15, 19, 30, 31], "18182": 15, "fan_in": [15, 28], "tha": 15, "kaim": [15, 28], "despit": [15, 31], "fact": [15, 30, 31, 33], "xavier": [15, 28], "fan_out": 15, "transformerencod": 15, "exact": 15, "72253": 15, "mup": [15, 16], "haven": 15, "2203": 15, "03466": 15, "input_to_emb": 15, "relev": [15, 16, 18, 24, 28, 30, 31], "special": [15, 31], "redwood": [15, 30, 31], "load_sample_training_dataset": 15, "dataset": [15, 19, 25, 28, 31], "10k": [15, 19, 28], "get_dataset": [15, 28], "appropri": [15, 31], "info": [15, 16, 24, 28, 31], "download": [15, 28, 31], "locat": [15, 24, 30], "pt": [15, 29], "openwebtext": [15, 19, 28], "karma": [15, 19], "reddit": [15, 19], "hard": [15, 30, 31], "pile": [15, 19, 22, 28, 31, 32], "imperfectli": 15, "suppli": 15, "valid": [15, 19, 30], "loss_fn": [15, 31], "per_token": [15, 28, 31], "lm_cross_entropy_loss": [15, 28], "move_model_modules_to_devic": 15, "process_weights_": 15, "allow": [15, 20, 24, 28, 30, 31], "cleaner": 15, "experiment": [15, 29], "argu": [15, 31], "somewhat": [15, 30, 31], "w_qk": [15, 18, 31], "w_ov": [15, 18, 31], "mani": [15, 18, 23, 24, 25, 30, 31], "hopefulli": [15, 33], "column": [15, 24, 28], "rotat": [15, 16, 18, 31], "nth": 15, "formula": 15, "r": 15, "think": [15, 19, 28, 30, 31], "setup": [15, 21, 24], "refactor": 15, "diagon": [15, 30, 31], "asymmetri": 15, "fiddli": 15, "deal": [15, 18, 28, 30], "preserv": [15, 30, 31], "too": [15, 24, 30], "bilinear": [15, 31], "dimension": [15, 16], "coordin": 15, "sample_datapoint": 15, "implicitli": [15, 24, 31], "hasn": 15, "manual": [15, 28, 31], "choic": [15, 30], "truncat": [15, 19, 28, 31], "set_token": [15, 16], "pretrainedtoken": 15, "set_use_attn_in": 15, "use_attn_in": [15, 16], "set_use_attn_result": 15, "expos": [15, 33], "easili": [15, 28, 30, 31], "burn": 15, "set_use_hook_mlp_in": 15, "use_hook_mlp_in": [15, 16], "set_use_split_qkv_input": 15, "use_split_qkv_input": [15, 16], "to_single_str_token": 15, "int_token": 15, "uncertain": 15, "to_token": [15, 28, 30, 31], "to_str_token": [15, 17, 30, 31], "weirdli": [15, 30, 31], "gotcha2": 15, "letter": [15, 31], "capit": [15, 30, 31], "shoot": [15, 31], "gotcha3": 15, "exce": 15, "str_token": [15, 30], "to_str": [15, 30, 31], "arrai": [15, 17, 28], "long": [15, 31], "window": [15, 16, 28], "tokens_to_residual_direct": [15, 30], "mislead": [15, 30], "integ": [15, 28, 30, 31], "residual_direct": 15, "namedtupl": 15, "dataclass": [16, 21], "act_fn": [16, 18, 32], "ep": 16, "1e": [16, 22], "05": [16, 22], "use_attn_scal": 16, "use_local_attn": 16, "original_architectur": 16, "from_checkpoint": 16, "checkpoint_label_typ": [16, 31], "window_s": [16, 18], "attn_typ": [16, 18], "init_mod": 16, "normalization_typ": 16, "attention_dir": 16, "attn_onli": [16, 32], "initializer_rang": 16, "scale_attn_by_inverse_layer_idx": 16, "final_rm": 16, "d_vocab_out": [16, 18], "parallel_attn_mlp": 16, "rotary_dim": [16, 18], "n_param": [16, 32], "use_hook_token": 16, "gated_mlp": 16, "tokenizer_prepends_bo": 16, "n_key_value_head": [16, 18], "post_embedding_ln": 16, "rotary_bas": 16, "10000": [16, 18, 31], "trust_remote_cod": 16, "rotary_adjacent_pair": 16, "load_in_4bit": 16, "num_expert": 16, "experts_per_token": 16, "AND": 16, "feedforward": 16, "network": [16, 30, 31], "vocab": 16, "lowercas": 16, "relu": [16, 28, 32], "gelu": [16, 18, 22, 31, 32], "silu": [16, 32], "gelu_new": [16, 28], "gelu_fast": [16, 28], "epsilon": 16, "5": [16, 18, 19, 20, 22, 24, 28, 29, 30, 31, 32], "THEN": 16, "intens": 16, "famili": [16, 31], "certain": [16, 24], "distanc": [16, 18, 30], "weight_init_mod": 16, "xavier_uniform": 16, "xavier_norm": 16, "kaiming_uniform": 16, "kaiming_norm": 16, "pipelin": 16, "parallel": [16, 28, 30], "aka": 16, "unidirect": 16, "bidirect": [16, 29, 31], "8": [16, 18, 19, 20, 29, 30, 31, 32], "gain": [16, 28], "layer_id": [16, 18], "numer": [16, 17, 18, 31], "stabil": [16, 18, 31], "fp16": 16, "rotari": [16, 18], "describ": [16, 28, 30], "blog": [16, 18], "eleuth": [16, 18, 28, 31], "ai": [16, 18, 22, 28, 31], "res_stream": 16, "sinusoid": 16, "rmsnorm": [16, 18], "dumb": 16, "curs": 16, "law": 16, "pdf": [16, 18, 19], "2001": 16, "08361": 16, "meaning": [16, 24], "Will": [16, 24], "let": [16, 28, 30, 31, 33], "interven": [16, 21, 24, 30], "add_bos_token": [16, 28], "control": [16, 24, 30, 31], "bit": [16, 30, 31], "quantiz": 16, "bitsandbyt": 16, "group": [16, 18], "expert": 16, "moe": [16, 18], "get_singular_vector": 17, "vector_typ": 17, "layer_index": [17, 30], "num_vector": 17, "plot": [17, 31], "pysvelt": [17, 29, 31], "instabl": 17, "d": [17, 19, 20, 22, 30, 32], "medium": [17, 22, 32], "svd_interpret": 17, "22": [17, 19, 28, 30, 31], "all_token": 17, "np": [17, 28, 30], "def": [17, 30, 31], "plot_matrix": 17, "filter": [17, 21, 22, 28, 31], "topk": [17, 30], "topktabl": 17, "obj_typ": 17, "abstractattent": 18, "abc": [18, 31], "pure": 18, "glossari": 18, "order": [18, 24, 28, 30], "sorri": 18, "underli": [18, 24, 30, 31], "destination_residu": 18, "destination_po": 18, "source_po": [18, 31], "abstract": [18, 30, 31], "groupedqueryattent": 18, "enforc": 18, "child": 18, "better_abc": 18, "abstract_attribut": 18, "stackoverflow": 18, "question": [18, 30, 31], "23831510": 18, "256": [18, 31, 32], "Not": 18, "moment": 18, "reason": [18, 30, 31], "alibi": 18, "apply_causal_mask": 18, "pos_plus_past_kv_pos_offset": 18, "past_kv_pos_offset": [18, 28], "offset_po": [18, 28], "apply_rotari": 18, "calculate_attention_scor": 18, "calculate_qkv_matric": 18, "query_input": 18, "key_input": 18, "value_input": 18, "calculate_sin_cos_rotari": 18, "sine": 18, "cosin": 18, "wave": 18, "inexplic": 18, "adjac": [18, 30], "neox": [18, 22, 31, 32], "clue": [18, 30], "resolv": 18, "calculate_z_scor": 18, "static": [18, 19], "create_alibi_bia": 18, "head_idx": 18, "2108": 18, "12409": 18, "broad": [18, 30], "behind": [18, 30], "proport": [18, 28], "encourag": [18, 28], "distant": 18, "0000": [18, 30], "0625": 18, "1250": 18, "1875": 18, "0039": 18, "0078": 18, "0117": 18, "create_alibi_multipli": 18, "geometr": 18, "ratio": [18, 28, 30, 31], "With": [18, 31], "16": [18, 28, 30, 31, 32], "5000": 18, "2500": [18, 30], "0312": 18, "0156": 18, "7071": 18, "3536": 18, "1768": 18, "0884": 18, "0442": 18, "0221": 18, "0110": 18, "0055": 18, "create_alibi_slop": 18, "slope": 18, "triangl": 18, "lower": [18, 19, 20, 28, 30, 31], "bottom": [18, 31], "corner": 18, "kv_head_index": 18, "past_kv_cache_entri": 18, "hookedtransformerkeyvaluecacheentri": [18, 23], "additive_attention_mask": 18, "irrelev": [18, 30, 31], "past": [18, 23, 30], "rotate_every_two": 18, "x0": 18, "x1": 18, "param": [18, 25, 28, 31], "convent": [18, 28, 30, 31], "mistal": 18, "bertblock": 18, "transformerblock": 18, "except": [18, 29, 30, 31], "overridden": [18, 21, 28], "recip": [18, 21], "afterward": [18, 21], "former": [18, 21], "regist": [18, 21], "latter": [18, 21, 31], "silent": [18, 21], "bertemb": 18, "input_id": [18, 29], "bertmlmhead": 18, "purpos": [18, 19, 30, 31], "resid": 18, "gatedmlp": 18, "equat": 18, "pre_linear": 18, "2305": 18, "13245": 18, "hood": 18, "_w_k": 18, "_w_v": 18, "getter": 18, "similarli": 18, "kept": 18, "repeat_interleav": 18, "unexpand": 18, "expan": 18, "n_query_head": 18, "gpa": 18, "normalis": [18, 30], "posemb": 18, "root": [18, 29, 31], "rmsnormpr": 18, "tokentypeemb": 18, "1810": 18, "04805": 18, "block_index": 18, "positional_embeddings_typ": 18, "_description_": 18, "_type_": [18, 21], "evalu": [19, 21, 30, 31], "rough": [19, 31], "anyth": [19, 30], "properli": [19, 30], "cheapli": 19, "roughli": [19, 30, 31], "baselin": 19, "ioidataset": 19, "noun": 19, "num_sampl": 19, "symmetr": 19, "ioi_ev": 19, "476": 19, "met": 19, "alic": 19, "bob": 19, "charli": 19, "ball": [19, 30], "book": 19, "397": 19, "get_default_nam": 19, "get_default_noun": 19, "get_default_templ": 19, "get_sampl": 19, "evaluate_on_dataset": 19, "data_load": 19, "induction_loss": [19, 31], "subseq_len": 19, "384": [19, 31], "io": [19, 20, 29, 30, 31], "accuraci": [19, 20, 28], "make_code_data_load": 19, "codeparrot": [19, 28], "dump": 19, "presum": [19, 30], "natur": [19, 30, 31], "make_owt_data_load": 19, "corpu": [19, 28], "make_pile_data_load": 19, "eleutherai": [19, 22], "english": [19, 31, 33], "academ": 19, "internet": [19, 31], "make_wiki_data_load": 19, "wikitext": 19, "wikipedia": [19, 28, 31], "articl": [19, 28, 30, 31], "realli": [19, 20, 28, 30, 31], "expect": [19, 20, 30, 31], "anyon": 19, "bother": 19, "quarantin": 19, "nowadai": 19, "leakag": 19, "though": [19, 28, 30, 31], "sanity_check": 19, "feed": [19, 28, 31], "paragraph": [19, 31], "zoom": [19, 24, 30], "quick": [19, 20, 31], "saniti": [19, 30], "ok": [19, 30, 31], "gone": [19, 30, 31], "wrong": [19, 21, 30], "compute_head_attention_similarity_scor": 20, "attention_pattern": [20, 31], "detection_pattern": 20, "exclude_bo": 20, "exclude_current_token": 20, "error_measur": 20, "mul": 20, "comparison": 20, "exclude_bcurrent_token": 20, "detect_head": 20, "seq": [20, 28], "previous_token_head": 20, "duplicate_token_head": 20, "induction_head": 20, "headnam": 20, "itself": [20, 28, 30], "divid": [20, 28, 30], "straightforward": [20, 30], "big": [20, 22, 28, 30, 31], "fraction": 20, "alloc": 20, "prohibit": 20, "cours": [20, 30], "raw": [20, 30], "interv": 20, "perfect": [20, 30], "mismatch": 20, "examin": 20, "switch": 20, "advantag": 20, "closer": 20, "head_nam": 20, "ntensor": 20, "ioi": [20, 30, 31], "spacifi": 20, "analyz": 20, "paid": [20, 30, 31], "get_duplicate_token_head_detection_pattern": 20, "duplic": [20, 30, 31], "dynalist": 20, "n2zwtnoyhru1s4vnfsaq519j": 20, "2ukvedzonghl5uhugvhroxeo": 20, "get_induction_head_detection_pattern": 20, "_tfvup5csv5orithmqwj0gsi": 20, "get_previous_token_head_detection_pattern": 20, "0o5vohe9xezn8ertywkh7ioc": 20, "get_supported_head": 20, "inspir": [21, 31, 33], "garcon": [21, 31, 33], "act": [21, 24, 28, 30, 31], "ident": [21, 28, 30, 31], "wrap": [21, 31], "add_hook": [21, 30], "bwd": 21, "fn": 21, "add_perma_hook": [21, 31], "remove_hook": 21, "including_perman": 21, "build": [21, 31, 33], "interfac": [21, 31, 33], "nice": [21, 30], "variou": [21, 30, 31], "persist": 21, "debug": [21, 22, 25], "fix": [21, 30, 31], "still": [21, 30], "solv": [21, 30, 31, 33], "intent": 21, "reset_hook": [21, 31], "goe": [21, 30, 31], "add_caching_hook": 21, "names_filt": [21, 30], "incl_bwd": 21, "namesfilt": 21, "lambda": [21, 30, 31], "cache_al": 21, "cache_som": 21, "check_and_add_hook": 21, "get_caching_hook": 21, "whenev": 21, "my_hook": 21, "hooked_loss": 21, "remove_all_hook_fn": 21, "everyth": [21, 24, 28, 31], "degrad": 21, "lenshandl": 21, "removablehandl": 21, "context_level": 21, "hold": 21, "perman": 21, "hug": 22, "face": 22, "hub": [22, 28], "768": [22, 30, 31, 32], "layer_norm_ep": 22, "init_rang": 22, "02": 22, "1024": [22, 28, 31, 32], "3072": [22, 31, 32], "12": [22, 30, 31, 32], "model_alias": 22, "01": 22, "yi": [22, 32], "34b": [22, 32], "chat": [22, 31, 32], "6b": [22, 31, 32], "arthurconmi": 22, "redwood_attn_2l": [22, 32], "baidicoot": 22, "codellama": [22, 32], "hf": 22, "codellamallama": [22, 32], "3b": [22, 31, 32], "125m": [22, 31, 32], "20b": [22, 31, 32], "pythia": [22, 32], "4b": [22, 32], "dedup": [22, 32], "12b": [22, 32], "13b": [22, 31, 32], "14m": [22, 32], "160m": [22, 32], "seed1": [22, 32], "seed2": [22, 32], "seed3": [22, 32], "1b": [22, 32], "800m": 22, "8b": [22, 31, 32], "31m": [22, 32], "410m": [22, 32], "350m": 22, "9b": [22, 32], "70m": [22, 32], "19m": [22, 32], "2l512w": 22, "lr": [22, 25], "attn_only_1l512w_c4_cod": 22, "c4": [22, 28, 31], "attn_only_2l512w_c4_cod": 22, "attn_only_3l512w_c4_cod": 22, "attn_only_4l512w_c4_cod": 22, "gelu_1l512w_c4_cod": 22, "gelu_2l512w_c4_cod": 22, "gelu_3l512w_c4_cod": 22, "gelu_4l512w_c4_cod": 22, "solu_10l1280w_c4_cod": 22, "10l": [22, 31, 32], "solu_10l_v22_old": 22, "solu_12l1536w_c4_cod": 22, "12l": [22, 31, 32], "solu_12l_v23_old": 22, "solu_1l512w_c4_cod": 22, "solu_1l512w_wiki_finetun": 22, "wiki": [22, 28, 30, 31, 32], "finetun": 22, "solu_1l_v9_old": 22, "solu_2l512w_c4_cod": 22, "solu_2l_v10_old": 22, "solu_3l512w_c4_cod": 22, "solu_4l512w_c4_cod": 22, "solu_4l512w_wiki_finetun": 22, "solu_4l_v11_old": 22, "solu_6l768w_c4_cod": 22, "6l": [22, 31, 32], "solu_6l_v13_old": 22, "solu_8l1024w_c4_cod": 22, "8l": [22, 31, 32], "solu_8l_v21_old": 22, "qwen": [22, 32], "14b": [22, 32], "1_8b": 22, "qwen1": [22, 32], "5b": [22, 31, 32], "bigcod": 22, "santacod": [22, 32], "bigscienc": 22, "1b1": [22, 32], "1b7": [22, 32], "560m": [22, 32], "7b1": [22, 32], "distilgpt2": [22, 31], "distillgpt2": [22, 32], "distil": [22, 31], "facebook": 22, "xxl": 22, "30b": [22, 31, 32], "xxxl": 22, "xl": [22, 31, 32], "66b": [22, 31, 32], "xxxxl": 22, "gemma": [22, 32], "2b": [22, 32], "65b": [22, 32], "70b": [22, 32], "microsoft": 22, "phi": [22, 32], "1_5": [22, 32], "roneneldan": 22, "tinystori": 22, "1layer": 22, "21m": [22, 32], "28m": [22, 32], "2layer": 22, "33m": [22, 32], "3m": [22, 32], "8m": [22, 32], "instuct": 22, "stabilityai": 22, "stablelm": [22, 31, 32], "alpha": [22, 32], "x21": 22, "arwen": 22, "battlestar": 22, "x49": 22, "beren": 22, "caprica": 22, "x81": 22, "celebrimbor": 22, "darkmatt": 22, "x343": 22, "durin": 22, "eowyn": 22, "x777": 22, "expans": 22, "alias": 22, "non_hf_hosted_model_nam": 22, "offici": [22, 31], "convert_bloom_weight": 22, "convert_coder_weight": 22, "convert_mistral_weight": 22, "convert_mixtral_weight": 22, "convert_phi_weight": 22, "convert_qwen2_weight": 22, "convert_qwen_weight": 22, "get_checkpoint_label": [22, 31], "label_typ": 22, "get_num_params_of_pretrain": 22, "suffici": [22, 30], "get_pretrained_model_config": 22, "hf_cfg": 22, "automodel": 22, "autoconfig": 22, "infrastructur": [22, 30, 31, 33], "ourselv": [23, 28, 31, 33], "previous_attention_mask": 23, "pos_so_far": 23, "append": [23, 30, 31], "prefix": 23, "append_attention_mask": 23, "new_token": 23, "freez": 23, "init_cach": 23, "unfreez": 23, "past_kei": 23, "jaxtyp": [23, 30, 31], "past_valu": 23, "new_kei": 23, "new_valu": 23, "init_cache_entri": 23, "structur": [24, 31], "generic_activation_patch": 24, "specialis": [24, 30], "introduc": [24, 30], "rome": [24, 30, 31], "baulab": 24, "shift": [24, 31], "corrupt": [24, 30, 31], "continu": [24, 30, 31], "iter": [24, 28, 30, 31], "localis": [24, 30, 31], "__from__": 24, "__to": 24, "__the": 24, "confid": [24, 30, 31], "intuit": [24, 30, 31], "diffus": [24, 30], "spread": [24, 30], "connect": [24, 30], "ultim": [24, 30], "engin": [24, 30, 31, 33], "least": [24, 31], "tend": [24, 31], "extrem": [24, 30, 31, 33], "eiffel": 24, "tower": 24, "pari": 24, "factual": [24, 30], "recal": [24, 30], "colosseum": 24, "anywher": 24, "corrupted_token": [24, 30, 31], "clean_cach": [24, 30, 31], "patching_metr": 24, "patch_sett": 24, "index_axis_nam": 24, "src_po": [24, 30], "dest_po": [24, 30, 31], "index_df": 24, "datafram": 24, "return_index_df": 24, "counterfactu": [24, 30, 31], "Then": 24, "index_to_act_nam": 24, "recov": [24, 30, 31], "diff": [24, 30], "corrupted_activ": 24, "chunk": 24, "fill": 24, "flatten": [24, 30, 31], "patched_output": 24, "get_act_patch_attn_head_all_pos_everi": 24, "patch_typ": 24, "get_act_patch_attn_head_by_pos_everi": 24, "get_act_patch_attn_head_k_all_po": 24, "corruptedactiv": 24, "patchedactiv": 24, "layer_head_vector_patch_sett": 24, "axisnam": 24, "get_act_patch_attn_head_k_by_po": 24, "layer_pos_head_vector_patch_sett": 24, "get_act_patch_attn_head_out_all_po": 24, "get_act_patch_attn_head_out_by_po": 24, "get_act_patch_attn_head_pattern_all_po": 24, "layer_head_pattern_patch_sett": 24, "get_act_patch_attn_head_pattern_by_po": 24, "layer_head_pos_pattern_patch_sett": 24, "get_act_patch_attn_head_pattern_dest_src_po": 24, "layer_head_dest_src_pos_pattern_patch_sett": 24, "get_act_patch_attn_head_q_all_po": 24, "get_act_patch_attn_head_q_by_po": 24, "get_act_patch_attn_head_v_all_po": 24, "get_act_patch_attn_head_v_by_po": 24, "get_act_patch_attn_out": 24, "layer_pos_patch_sett": 24, "get_act_patch_block_everi": 24, "get_act_patch_mlp_out": 24, "get_act_patch_resid_mid": 24, "get_act_patch_resid_pr": 24, "clean_activ": 24, "hookedtransformertrainconfig": 25, "num_epoch": 25, "001": 25, "momentum": 25, "max_grad_norm": 25, "weight_decai": 25, "optimizer_nam": 25, "adam": 25, "warmup_step": 25, "save_everi": 25, "save_dir": 25, "wandb": 25, "wandb_project_nam": 25, "print_everi": 25, "max_step": 25, "hyperparamet": [25, 28], "epoch": 25, "rate": [25, 31], "decai": 25, "warmup": 25, "wandb_project": 25, "termin": 25, "assist": 27, "get_device_for_block_index": 27, "target": 27, "move_to_and_update_config": 27, "vari": [28, 30], "throughout": [28, 31], "locallyoverridendefault": 28, "overriden": 28, "input_slic": 28, "syntax": [28, 30, 31], "reduc": [28, 30, 31], "extra": 28, "leav": [28, 31], "elif": 28, "1d": 28, "sliceinput": 28, "valueerror": 28, "abov": [28, 30, 31], "max_ctx": 28, "int32": 28, "unwrap": 28, "slice_input": 28, "calc_fan_in_and_fan_out": 28, "fan": 28, "d_out": 28, "composition_scor": 28, "broadcast_dim": 28, "leading_dims_left_and_right": 28, "download_file_from_hf": 28, "repo_nam": 28, "file_nam": 28, "subfold": 28, "home": 28, "runner": 28, "force_is_torch": 28, "json": 28, "pth": 28, "extens": [28, 30], "layer_typ": [28, 30], "shorthand": 28, "feedback": [28, 30, 31, 33], "loop": [28, 30, 31, 33], "hack": [28, 31], "stuff": [28, 29, 31], "readabl": 28, "digit": [28, 31], "word": [28, 30, 31], "k6": 28, "scale4ln1": 28, "appear": [28, 31], "distinguish": [28, 30], "hook_k": [28, 31], "hook_pr": [28, 31], "27": [28, 30, 31], "hook_norm": [28, 31], "pre5": 28, "get_attention_mask": 28, "leftmost": 28, "rightmost": 28, "consid": 28, "get_cumsum_along_dim": 28, "dataset_nam": 28, "explor": [28, 31], "000": [28, 31], "enorm": [28, 31], "100gb": 28, "2tb": 28, "effort": [28, 30], "dataload": 28, "fanci": 28, "data_dir": 28, "approx": [28, 30, 31], "ton": [28, 33], "divers": [28, 30, 31], "coloss": 28, "crawl": 28, "bigger": 28, "c4_code": 28, "friendli": 28, "22m": [28, 31], "5m": 28, "20220301": 28, "en": [28, 31], "get_devic": [28, 30, 31], "get_input_with_manually_prepended_bo": 28, "autotoken": [28, 29], "get_nested_attr": 28, "attr_str": 28, "retriev": 28, "hierarchi": 28, "get_offset_position_id": 28, "offset": [28, 30, 31], "get_tokenizer_with_bo": 28, "Such": [28, 30], "llamatoken": 28, "get_tokens_with_bos_remov": 28, "init_kaiming_normal_": 28, "nonlinear": 28, "std": 28, "init_kaiming_uniform_": 28, "init_xavier_normal_": 28, "init_xavier_uniform_": 28, "is_lower_triangular": 28, "is_squar": 28, "keep_single_column": 28, "col_nam": 28, "lm_accuraci": 28, "seq_len": [28, 30, 31], "altern": 28, "override_or_use_default_valu": 28, "default_flag": 28, "print_gpu_mem": 28, "step_nam": 28, "repeat_along_head_dimens": 28, "clone_tensor": 28, "sample_logit": 28, "final_logit": [28, 30], "vocab_s": 28, "high": [28, 30, 31], "argmaxi": 28, "90": 28, "renormalis": 28, "mutual": 28, "neither": [28, 30], "input_token": 28, "todo": 28, "edg": 28, "randn": [28, 31], "uniqu": 28, "return_count": 28, "set_nested_attr": 28, "prepend_space_to_answ": 28, "eleph": 28, "endoftext": [28, 30, 31], "14": [28, 30, 31], "51": [28, 31], "0th": [28, 30], "59": [28, 31, 32], "ground": [28, 30], "1th": [28, 30], "41": [28, 31], "18": [28, 30, 31, 32], "tree": 28, "2th": [28, 30], "3th": [28, 30], "45": [28, 31], "car": 28, "4th": [28, 30], "13": [28, 30, 31], "92": [28, 30], "55": [28, 30, 31], "river": 28, "5th": [28, 30], "79": 28, "25": [28, 30, 31, 32], "street": 28, "6th": [28, 30], "77": 28, "21": [28, 30, 31], "7th": [28, 30], "75": 28, "hill": 28, "8th": [28, 30], "swing": 28, "9th": [28, 30], "46": [28, 31], "61": [28, 32], "park": [28, 30], "ever": 28, "improv": [28, 30, 31], "to_numpi": [28, 30, 31], "tokenize_and_concaten": 28, "max_length": 28, "column_nam": 28, "num_proc": 28, "eo": [28, 31], "reshap": [28, 30], "____": 28, "drop": [28, 31], "faster": [28, 29, 30, 31], "parallelis": [28, 31], "chop": 28, "20": [28, 30, 31, 32], "privileg": 28, "earli": [28, 31], "cnn": [28, 31], "bos_token_id": 28, "regardless": 28, "nbval_ignore_output": [29, 30, 31], "janki": [29, 31], "vscode": [29, 30, 31], "development_mod": [29, 31], "in_github": [29, 31], "getenv": [29, 31], "github_act": [29, 31], "in_colab": [29, 30, 31], "unmaintain": 29, "backup": 29, "circuitsvi": [29, 30, 31], "isn": 29, "node": [29, 30, 31], "curl": [29, 30, 31], "fssl": [29, 30, 31], "deb": [29, 30, 31], "nodesourc": [29, 30, 31], "setup_16": [29, 30, 31], "sudo": [29, 30, 31], "bash": [29, 30, 31], "apt": [29, 30, 31], "nodej": [29, 30, 31], "ipython": [29, 30, 31], "get_ipython": [29, 30, 31], "restart": 29, "kernel": 29, "magic": 29, "load_ext": 29, "autoreload": [29, 30, 31], "plotli": [29, 30, 31], "render": [29, 31], "argh": [29, 31], "pio": [29, 30, 31], "notebook_connect": [29, 31], "cv": [29, 31], "hello": [29, 31], "lt": [29, 30, 31], "autograd": [29, 31], "grad_mod": [29, 31], "0x7eff49319290": 29, "gt": [29, 30, 31], "section": [29, 30, 31], "pariti": 29, "guarante": 29, "mind": 29, "deep": 29, "return_tensor": 29, "mask_index": 29, "squeez": [29, 31], "mask_token_id": 29, "logprob": 29, "log_softmax": [29, 30], "34": [29, 30, 31], "system": [29, 31], "luck": 29, "runtim": [30, 31], "hardwar": [30, 31], "acceler": [30, 31], "tabl": [30, 31], "pane": [30, 31], "sidebar": [30, 31], "navig": [30, 31], "outlin": 30, "tab": 30, "dropdown": [30, 31], "arrow": [30, 31], "page": [30, 31], "ctrl": [30, 31], "repo": 30, "noqa": [30, 31], "ip": [30, 31], "extension_manag": [30, 31], "functool": [30, 31], "express": [30, 31], "px": [30, 31], "attention_head": 30, "fancy_einsum": [30, 31], "ifram": 30, "differenti": [30, 31], "simplic": 30, "imshow": [30, 31], "color_continuous_midpoint": [30, 31], "color_continuous_scal": [30, 31], "rdbu": [30, 31], "scatter": [30, 31], "xaxi": [30, 31], "yaxi": [30, 31], "caxi": [30, 31], "color": [30, 31], "principl": [30, 31, 33], "fun": [30, 31, 33], "ml": [30, 31, 33], "gap": [30, 31, 33], "feel": [30, 31, 33], "plai": [30, 31, 33], "flow": [30, 31, 33], "goal": [30, 31, 33], "toolkit": [30, 31], "stylist": 30, "slowli": 30, "convei": 30, "simpl": [30, 31], "tag": 30, "asid": 30, "flavour": 30, "weed": 30, "star": 30, "tagexampl": 30, "capabl": [30, 31], "interview": [30, 31], "kevin": [30, 31], "wang": 30, "twitter": 30, "thread": 30, "overview": 30, "bottl": [30, 31], "milk": [30, 31], "26": [30, 31], "Their": 30, "skimp": 30, "rigour": 30, "suggest": 30, "evid": 30, "our": [30, 31], "80m": [30, 31], "simplif": 30, "stabl": 30, "example_prompt": 30, "example_answ": 30, "39": [30, 31], "09": [30, 31], "70": 30, "07": [30, 31], "15": [30, 31], "38": [30, 31], "67": 30, "35": [30, 31], "54": [30, 31], "11": [30, 31, 32], "84": [30, 31], "73": 30, "hi": [30, 31], "06": 30, "her": [30, 31], "74": 30, "52": [30, 31, 32], "49": [30, 31], "jesu": 30, "97": 30, "42": [30, 31], "him": 30, "subword": 30, "frequent": 30, "substr": [30, 31], "massiv": [30, 31], "headach": 30, "annoi": [30, 31], "total": [30, 31], "devot": 30, "sensibl": 30, "later": [30, 31], "wherev": 30, "flesh": 30, "prompt_format": 30, "jame": 30, "dan": 30, "sid": 30, "appl": 30, "martin": 30, "ami": 30, "drink": 30, "correct_token": 30, "insert": 30, "easiest": 30, "filler": 30, "newlin": 30, "intellig": 30, "complic": 30, "adjust": [30, 31], "aggreg": 30, "original_logit": 30, "upon": 30, "subject": [30, 31], "logits_to_ave_logit_diff": 30, "per_prompt": 30, "answer_logit": 30, "gather": 30, "answer_logit_diff": 30, "detach": [30, 31], "decim": [30, 31], "original_average_logit_diff": 30, "3370": 30, "2020": 30, "7090": 30, "7970": 30, "7200": 30, "2810": 30, "6010": 30, "7670": 30, "552": 30, "put": [30, 31], "33": [30, 31], "dive": 30, "spend": [30, 31], "engag": 30, "decent": [30, 31], "hypothes": 30, "cheat": [30, 31], "hypothesi": 30, "scienc": 30, "belief": 30, "trap": 30, "confus": [30, 31], "flounder": 30, "dogmat": 30, "Being": 30, "overconfid": 30, "unwil": 30, "realiti": 30, "contradict": 30, "flinch": 30, "disconfirm": 30, "imagin": 30, "focu": 30, "primit": 30, "nearbi": 30, "came": 30, "trigram": 30, "symmetri": 30, "earlier": [30, 31], "cancel": 30, "inhibit": 30, "spoiler": 30, "abl": [30, 31], "simplist": 30, "background": 30, "central": 30, "importantli": [30, 31], "perfectli": [30, 31], "final_residual_stream": 30, "motiv": 30, "eleg": 30, "particularli": 30, "aspect": 30, "nicer": 30, "inde": 30, "log_prob": 30, "logsumexp": 30, "isol": 30, "decid": 30, "pronoun": 30, "person": 30, "refin": 30, "happen": [30, 31], "rel": 30, "friendlier": 30, "almost": 30, "answer_residual_direct": 30, "logit_diff_direct": 30, "account": 30, "w_u_fold": 30, "layer_norm": 30, "unigram": [30, 31], "statist": [30, 31], "occur": [30, 31], "opposit": 30, "hook_normalis": 30, "sub_layer_typ": 30, "final_token_residual_stream": 30, "scaled_final_token_residual_stream": 30, "average_logit_diff": 30, "residual_stack_to_logit_diff": 30, "scaled_residual_stack": 30, "fascinatingli": 30, "utterli": 30, "unabl": 30, "hover": [30, 31], "n_pre": 30, "n_mid": 30, "n_post": 30, "middl": [30, 31], "accumulated_residu": 30, "logit_lens_logit_diff": 30, "arang": 30, "hover_nam": [30, 31], "terminologi": 30, "overload": 30, "kth": 30, "again": 30, "per_layer_residu": 30, "per_layer_logit_diff": 30, "independ": [30, 31, 33], "overal": 30, "l9h6": 30, "l9h9": 30, "l10h7": 30, "l11h10": 30, "harm": 30, "discuss": 30, "strongli": 30, "observ": [30, 31], "144": 30, "hand": [30, 31], "claim": 30, "surpris": 30, "7x": 30, "per_head_residu": 30, "per_head_logit_diff": 30, "rearrang": 30, "weren": 30, "alan": [30, 31], "coonei": [30, 31], "illustr": [30, 31], "mistak": 30, "mayb": [30, 31], "sai": [30, 31], "period": [30, 31], "summari": 30, "sole": 30, "17": [30, 31], "visualize_attention_pattern": 30, "local_cach": 30, "local_token": 30, "max_width": 30, "700": 30, "isinst": 30, "batch_index": 30, "combin": [30, 31], "attention_head_nam": 30, "show_cod": 30, "title_html": 30, "br": 30, "div": 30, "width": [30, 31], "top_positive_logit_attr_head": 30, "positive_html": 30, "top_negative_logit_attr_head": 30, "negative_html": 30, "conceptu": 30, "clearli": 30, "compos": [30, 31], "ideal": [30, 31], "david": [30, 31], "bau": [30, 31], "meng": [30, 31], "trace": [30, 31], "anim": 30, "piec": 30, "lai": 30, "pro": 30, "con": 30, "Or": 30, "bake": 30, "claus": 30, "tack": 30, "gaussian": 30, "nois": 30, "beforehand": 30, "19": [30, 31], "corrupted_prompt": [30, 31], "corrupted_logit": [30, 31], "corrupted_cach": 30, "corrupted_average_logit_diff": 30, "patch_residual_compon": 30, "corrupted_residual_compon": 30, "normalize_patched_logit_diff": 30, "patched_logit_diff": [30, 31], "wors": [30, 31], "patched_residual_stream_diff": 30, "hook_fn": 30, "patched_logit": [30, 31], "abus": 30, "prompt_position_label": 30, "tok": 30, "_": [30, 31], "enumer": [30, 31], "reus": 30, "patched_attn_diff": 30, "patched_mlp_diff": 30, "patched_attn_logit": 30, "patched_attn_logit_diff": 30, "patched_mlp_logit": 30, "patched_mlp_logit_diff": 30, "late": [30, 31], "contrast": 30, "statement": 30, "mlp0": 30, "destroi": 30, "guess": 30, "frame": 30, "unprincipl": 30, "invers": [30, 31], "plausibli": 30, "dedic": 30, "overcom": 30, "love": 30, "someon": 30, "That": 30, "patch_head_vector": 30, "corrupted_head_vector": 30, "patched_head_z_diff": 30, "l8h6": 30, "l8h10": 30, "l7h9": 30, "l5h5": 30, "l6h9": 30, "l3h0": 30, "semi": 30, "disentangl": 30, "familiar": 30, "28": [30, 31, 32], "patched_head_v_diff": 30, "heatmap": 30, "29": [30, 31], "against": 30, "lesson": 30, "30": [30, 31, 32], "head_label": 30, "range_x": 30, "range_i": 30, "31": [30, 31], "patch_head_pattern": 30, "corrupted_head_pattern": 30, "patched_head_attn_diff": 30, "32": [30, 31, 32], "reconsolid": 30, "At": 30, "transit": 30, "extend": 30, "l7h3": 30, "specul": 30, "mysteri": [30, 31], "top_heads_by_output_patch": 30, "first_mid_lay": 30, "first_late_lay": 30, "early_head": 30, "mid_head": 30, "logical_and": 30, "late_head": 30, "diagram": 30, "l1h2": 30, "latest": 30, "definit": 30, "priori": 30, "stroke": 30, "didn": 30, "bracket": 30, "minor": 30, "serv": [30, 31], "particip": 30, "behav": 30, "l5h0": 30, "had": [30, 31], "wrote": [30, 31, 33], "whole": [30, 31], "overkil": 30, "simpler": 30, "repurpos": 30, "machineri": 30, "life": [30, 31], "built": 30, "example_text": [30, 31], "seek": 30, "machin": [30, 31], "example_repeated_text": 30, "example_repeated_token": 30, "example_repeated_logit": 30, "example_repeated_cach": 30, "induction_head_label": 30, "81": 30, "65": 30, "800": 30, "accord": 30, "wildli": 30, "mark": [30, 31], "success": 30, "characteris": 30, "superfici": 30, "boost": [30, 31], "anti": 30, "suppress": [30, 31], "pick": [30, 31], "signal": 30, "hook_": 30, "hook_attn": 30, "token_po": 30, "metadata": 30, "36": [30, 31, 32], "prev_token_scor": 30, "prev_token_hook": 30, "dim1": [30, 31], "dim2": [30, 31], "duplicate_token_scor": 30, "duplicate_token_hook": 30, "induction_scor": [30, 31], "induction_hook": 30, "manual_se": [30, 31], "original_token": 30, "randint": [30, 31], "20000": [30, 31], "repeated_token": [30, 31], "pattern_filt": 30, "endswith": [30, 31], "hook_pattern": [30, 31], "0390": 30, "0310": 30, "1890": 30, "1720": 30, "0680": 30, "1570": 30, "0210": 30, "4820": 30, "0030": 30, "1320": 30, "0050": 30, "0020": 30, "0090": 30, "0040": 30, "0010": 30, "instantli": 30, "37": [30, 31], "seen": [30, 31], "proof": 30, "mosaic": 30, "40": [30, 31, 32], "fascin": 30, "knock": 30, "naiv": [30, 31], "convers": 30, "flaw": 30, "knockout": 30, "send": 30, "redund": 30, "job": 30, "underestim": 30, "57": [30, 31], "99": [30, 31], "top_name_mov": 30, "top_name_mover_lay": 30, "top_name_mover_head": 30, "ablate_top_head_hook": 30, "ablated_logit": 30, "ablated_cach": 30, "2f": [30, 31], "l10h10": 30, "margin": 30, "obvious": 30, "per_head_ablated_residu": 30, "per_head_ablated_logit_diff": 30, "04": [30, 31], "uniformli": [30, 31], "042": 30, "5200": 30, "4700": 30, "8200": 30, "5100": 30, "2600": 30, "1800": 30, "4300": 30, "5700": 30, "3500": 30, "2900": 30, "6800": 30, "4900": 30, "8700": 30, "4200": 30, "reader": [30, 31], "becom": [30, 31], "gentler": 31, "tip": 31, "auto": 31, "0x7f896b867010": 31, "todai": [31, 33], "speak": [31, 33], "human": [31, 33], "palm": [31, 33], "nor": [31, 33], "offend": [31, 33], "jump": 31, "anthrop": [31, 33], "team": [31, 33], "got": [31, 33], "frustrat": [31, 33], "deepspe": [31, 33], "littl": [31, 33], "industri": [31, 33], "heavili": [31, 33], "credit": [31, 33], "nelson": [31, 33], "elhag": [31, 33], "chri": [31, 33], "olah": [31, 33], "model_description_text": 31, "hyper": 31, "1758": 31, "box": 31, "On": 31, "insid": 31, "kinda": 31, "gpt2_cache_no_batch_dim": 31, "gpt2_cach": 31, "gpt2_text": 31, "summar": 31, "supervis": 31, "taskspecif": 31, "gpt2_token": 31, "gpt2_logit": 31, "lock": 31, "grid": 31, "gpt2_str_token": 31, "neural": 31, "perspect": 31, "surgic": 31, "power": 31, "surround": 31, "current_activation_valu": 31, "new_activation_valu": 31, "substitut": 31, "relationship": 31, "underr": 31, "incredibli": 31, "shamelessli": 31, "probepoint": 31, "qualiti": 31, "head_ablation_hook": 31, "layer_to_abl": 31, "head_index_to_abl": 31, "original_loss": 31, "ablated_loss": 31, "3f": 31, "999": 31, "453": 31, "stai": 31, "clean_prompt": 31, "clean_token": 31, "logits_to_logit_diff": 31, "correct_answ": 31, "incorrect_answ": 31, "correct_index": 31, "incorrect_index": 31, "clean_logit": 31, "clean_logit_diff": 31, "corrupted_logit_diff": 31, "276": 31, "738": 31, "residual_stream_patching_hook": 31, "clean_resid_pr": 31, "num_posit": 31, "ioi_patching_result": 31, "temp_hook_fn": 31, "ish": 31, "token_label": 31, "workflow": 31, "michael": 31, "jordan": 31, "surnam": 31, "terribl": 31, "halfwai": 31, "input_tensor": 31, "random_token": 31, "repeated_logit": 31, "correct_log_prob": 31, "loss_by_posit": 31, "manipul": 31, "hook_funct": 31, "induction_score_stor": 31, "induction_score_hook": 31, "induction_strip": 31, "pattern_hook_names_filt": 31, "highli": 31, "stripe": 31, "induction_head_lay": 31, "induction_head_index": 31, "single_random_sequ": 31, "repeated_random_sequ": 31, "visualize_pattern_hook": 31, "3d": 31, "four": 31, "300m": 31, "soon": 31, "distilgpt": 31, "distilgpt2_induction_score_stor": 31, "classic": 31, "openai": 31, "85m": [31, 32], "700m": 31, "22b": 31, "300b": 31, "180b": 31, "600": 31, "265": 31, "108m": 31, "bookscorpu": 31, "free": 31, "512": [31, 32], "tractabl": 31, "motif": 31, "80": [31, 32], "shuffl": 31, "scan": 31, "hope": 31, "40m": 31, "100m": 31, "200m": 31, "340m": [31, 32], "older": 31, "15b": 31, "13m": [31, 32], "digress": 31, "usefulli": 31, "variengien": 31, "websit": 31, "adapt": 31, "cleantransformerdemo": 31, "new_activ": 31, "old_activ": 31, "remind": 31, "50267": 31, "named_paramet": 31, "startswith": 31, "fallback": 31, "spam": 31, "dest_posit": 31, "brown": 31, "fox": 31, "lazi": 31, "dog": 31, "num": 31, "print_name_shape_hook_funct": 31, "not_in_late_block_filt": 31, "hook_q": 31, "hook_v": 31, "hook_attn_scor": 31, "hook_attn_out": 31, "hook_resid_mid": 31, "hook_post": 31, "hook_mlp_out": 31, "hook_resid_post": 31, "preconcept": 31, "pain": 31, "overhead": 31, "elementwis": 31, "consequ": 31, "rare": 31, "dramat": 31, "degre": 31, "punctuat": 31, "ass": 31, "randomredditor": 31, "unembed_bia": 31, "bias_valu": 31, "bias_indic": 31, "sort": 31, "repr": 31, "03": 31, "98": 31, "68": 31, "48": [31, 32], "47": 31, "72": [31, 32], "44": [31, 32], "82": 31, "\u30b5\u30fc\u30c6\u30a3": 31, "83": 31, "x18": 31, "x14": 31, "\u9f8d": 31, "x1b": 31, "x05": 31, "x00": 31, "x06": 31, "x07": 31, "x0c": 31, "x02": 31, "oreandonlin": 31, "x11": 31, "x10": 31, "favour": 31, "6x": 31, "john_bia": 31, "mary_bia": 31, "4f": 31, "exp": 31, "8995": 31, "6034": 31, "6550x": 31, "finit": 31, "invert": 31, "de": 31, "uncommon": 31, "iz": 31, "charact": 31, "example_text_str_token": 31, "example_text_token": 31, "50256": 31, "464": 31, "717": 31, "1517": 31, "345": 31, "761": 31, "284": 31, "3785": 31, "503": 31, "318": 31, "1635": 31, "4919": 31, "1243": 31, "389": 31, "11241": 31, "1143": 31, "4600": 31, "19849": 31, "1462": 31, "62": 31, "2536": 31, "482": 31, "641": 31, "63": 31, "30778": 31, "257": 31, "4731": 31, "656": 31, "262": 31, "16326": 31, "292": 31, "1351": 31, "286": 31, "850": 31, "37336": 31, "25666": 31, "290": 31, "523": 31, "8781": 31, "7301": 31, "644": 31, "2420": 31, "3073": 31, "588": 31, "1675": 31, "10176": 31, "428": 31, "1309": 31, "338": 31, "779": 31, "340": 31, "319": 31, "7322": 31, "signifi": 31, "example_multi_text": 31, "cat": 31, "sat": 31, "mat": 31, "example_multi_text_token": 31, "3797": 31, "3332": 31, "2603": 31, "1107": 31, "1327": 31, "th": 31, "cat_text": 31, "cat_logit": 31, "cat_prob": 31, "capital_the_token_index": 31, "ascii": 31, "annoy": 31, "arithmet": 31, "impress": 31, "2342": 31, "2017": 31, "21445": 31, "1000000": 31, "999999": 31, "214": 31, "000000": 31, "9999": 31, "tim": 31, "ne": 31, "el": 31, "messier": 31, "takeawai": 31, "unexpect": 31, "notic": 31, "trip": 31, "confusingli": 31, "forth": 31, "ioi_logits_with_bo": 31, "clair": 31, "mary_logit_with_bo": 31, "claire_logit_with_bo": 31, "ioi_logits_without_bo": 31, "mary_logit_without_bo": 31, "claire_logit_without_bo": 31, "754": 31, "782": 31, "air": 31, "understood": 31, "requisit": 31, "attention_scor": 31, "ab_factor": 31, "9105": 31, "linalg": 31, "eig": 31, "2877e": 31, "00": 31, "8626e": 31, "3121e": 31, "9038e": 31, "08": 31, "1527e": 31, "2877": 31, "3121": 31, "3126e": 31, "3963e": 31, "2029e": 31, "7690e": 31, "2164e": 31, "3126": 31, "3963": 31, "smallest": 31, "300": 31, "abc_factor": 31, "unfactor": 31, "160": 31, "0830": 31, "43": 31, "ab_unfactor": 31, "isclos": 31, "subspac": 31, "coincid": 31, "assert": 31, "negat": 31, "proxi": 31, "lambda_i": 31, "ov_circuit_all_head": 31, "ov_circuit_all_heads_eigenvalu": 31, "complex64": 31, "ov_copying_scor": 31, "zmax": 31, "zmin": 31, "l11h11": 31, "imag": 31, "imaginari": 31, "full_ov_circuit": 31, "full_ov_circuit_eigenvalu": 31, "full_ov_copying_scor": 31, "interestingli": 31, "correl": 31, "outlier": 31, "thank": 31, "ansh": 31, "radhakrishnan": 31, "establish": 31, "53": 31, "presid": 31, "barack": 31, "obama": 31, "caught": 31, "embarrass": 31, "scandal": 31, "nthe": 31, "financi": 31, "said": 31, "he": 31, "talk": 31, "wife": 31, "chelsea": 31, "she": 31, "woman": 31, "lightweight": 31, "bundl": 31, "squarethenadd": 31, "hook_squar": 31, "twolayermodel": 31, "layer1": 31, "layer2": 31, "hook_in": 31, "hook_mid": 31, "hook_out": 31, "x_in": 31, "x_mid": 31, "x_out": 31, "model_out": 31, "cache_object": 31, "780": 31, "784": 31, "56": [31, 32], "set_to_zero_hook": 31, "num_checkpoint": 31, "piecewis": 31, "schedul": 31, "crash": 31, "11b": [31, 32], "centr": 31, "hoc": 31, "count": 31, "checkpoint_label": 31, "log_i": 31, "marker": 31, "brief": 31, "suddenli": 31, "500": 31, "visibl": 31, "bump": 31, "curv": 31, "briefli": 31, "deliber": 31, "justic": 31, "chosen": 31, "60": [31, 32], "500m": 31, "58": 31, "arbitrarili": 31, "fast": 31, "checkpoint_indic": 31, "checkpointed_model": 31, "tokens_trained_on": 31, "model_for_this_checkpoint": 31, "tokens_seen_for_this_checkpoint": 31, "induction_loss_for_this_checkpoint": 31, "contextualis": 31, "strategi": 31, "95": 31, "log_x": 31, "302m": 32, "4096": 32, "708m": 32, "1280": 32, "5120": 32, "1600": 32, "6400": 32, "42m": 32, "2048": 32, "50272": 32, "8192": 32, "2560": 32, "10240": 32, "128": 32, "16384": 32, "20480": 32, "7168": 32, "28672": 32, "9216": 32, "36864": 32, "50400": 32, "6144": 32, "50432": 32, "96": 32, "24576": 32, "2m": 32, "50304": 32, "7m": 32, "805m": 32, "50688": 32, "50278": 32, "736": 32, "2944": 32, "101m": 32, "197m": 32, "1536": 32, "48262": 32, "4m": 32, "0m": 32, "50277": 32, "524k": 32, "50259": 32, "32000": 32, "11008": 32, "13824": 32, "32b": 32, "6656": 32, "17920": 32, "22016": 32, "78b": 32, "32016": 32, "128256": 32, "14336": 32, "25m": 32, "28996": 32, "393k": 32, "6m": 32, "47b": 32, "250880": 32, "679m": 32, "0b": 32, "49280": 32, "151936": 32, "5504": 32, "152064": 32, "13696": 32, "308m": 32, "2816": 32, "6912": 32, "51200": 32, "256000": 32, "64000": 32, "39b": 32, "formerli": 33, "transfer": 33}, "objects": {"transformer_lens": [[9, 0, 0, "-", "ActivationCache"], [10, 0, 0, "-", "FactoredMatrix"], [11, 0, 0, "-", "HookedEncoder"], [12, 0, 0, "-", "HookedSAE"], [13, 0, 0, "-", "HookedSAEConfig"], [14, 0, 0, "-", "HookedSAETransformer"], [15, 0, 0, "-", "HookedTransformer"], [16, 0, 0, "-", "HookedTransformerConfig"], [17, 0, 0, "-", "SVDInterpreter"], [18, 0, 0, "-", "components"], [19, 0, 0, "-", "evals"], [20, 0, 0, "-", "head_detector"], [21, 0, 0, "-", "hook_points"], [22, 0, 0, "-", "loading_from_pretrained"], [23, 0, 0, "-", "past_key_value_caching"], [24, 0, 0, "-", "patching"], [25, 0, 0, "-", "train"], [28, 0, 0, "-", "utils"]], "transformer_lens.ActivationCache": [[9, 1, 1, "", "ActivationCache"]], "transformer_lens.ActivationCache.ActivationCache": [[9, 2, 1, "", "accumulated_resid"], [9, 2, 1, "", "apply_ln_to_stack"], [9, 2, 1, "", "apply_slice_to_batch_dim"], [9, 2, 1, "", "compute_head_results"], [9, 2, 1, "", "decompose_resid"], [9, 2, 1, "", "get_full_resid_decomposition"], [9, 2, 1, "", "get_neuron_results"], [9, 2, 1, "", "items"], [9, 2, 1, "", "keys"], [9, 2, 1, "", "logit_attrs"], [9, 2, 1, "", "remove_batch_dim"], [9, 2, 1, "", "stack_activation"], [9, 2, 1, "", "stack_head_results"], [9, 2, 1, "", "stack_neuron_results"], [9, 2, 1, "", "to"], [9, 2, 1, "", "toggle_autodiff"], [9, 2, 1, "", "values"]], "transformer_lens.FactoredMatrix": [[10, 1, 1, "", "FactoredMatrix"]], "transformer_lens.FactoredMatrix.FactoredMatrix": [[10, 3, 1, "", "AB"], [10, 3, 1, "", "BA"], [10, 3, 1, "", "S"], [10, 3, 1, "", "T"], [10, 3, 1, "", "U"], [10, 3, 1, "", "Vh"], [10, 2, 1, "", "collapse_l"], [10, 2, 1, "", "collapse_r"], [10, 3, 1, "", "eigenvalues"], [10, 2, 1, "", "get_corner"], [10, 2, 1, "", "make_even"], [10, 3, 1, "", "ndim"], [10, 2, 1, "", "norm"], [10, 3, 1, "", "pair"], [10, 2, 1, "", "svd"], [10, 2, 1, "", "unsqueeze"]], "transformer_lens.HookedEncoder": [[11, 1, 1, "", "HookedEncoder"]], "transformer_lens.HookedEncoder.HookedEncoder": [[11, 3, 1, "", "OV"], [11, 3, 1, "", "QK"], [11, 3, 1, "", "W_E"], [11, 3, 1, "", "W_E_pos"], [11, 3, 1, "", "W_K"], [11, 3, 1, "", "W_O"], [11, 3, 1, "", "W_Q"], [11, 3, 1, "", "W_U"], [11, 3, 1, "", "W_V"], [11, 3, 1, "", "W_in"], [11, 3, 1, "", "W_out"], [11, 3, 1, "", "W_pos"], [11, 2, 1, "", "all_head_labels"], [11, 3, 1, "", "b_K"], [11, 3, 1, "", "b_O"], [11, 3, 1, "", "b_Q"], [11, 3, 1, "", "b_U"], [11, 3, 1, "", "b_V"], [11, 3, 1, "", "b_in"], [11, 3, 1, "", "b_out"], [11, 2, 1, "", "cpu"], [11, 2, 1, "", "cuda"], [11, 2, 1, "", "forward"], [11, 2, 1, "", "from_pretrained"], [11, 2, 1, "", "mps"], [11, 2, 1, "", "run_with_cache"], [11, 2, 1, "", "to"]], "transformer_lens.HookedSAE": [[12, 1, 1, "", "HookedSAE"]], "transformer_lens.HookedSAE.HookedSAE": [[12, 2, 1, "", "forward"]], "transformer_lens.HookedSAEConfig": [[13, 1, 1, "", "HookedSAEConfig"]], "transformer_lens.HookedSAEConfig.HookedSAEConfig": [[13, 4, 1, "", "d_in"], [13, 4, 1, "", "d_sae"], [13, 4, 1, "", "device"], [13, 4, 1, "", "dtype"], [13, 2, 1, "", "from_dict"], [13, 4, 1, "", "hook_name"], [13, 4, 1, "", "seed"], [13, 2, 1, "", "set_seed_everywhere"], [13, 2, 1, "", "to_dict"], [13, 4, 1, "", "use_error_term"]], "transformer_lens.HookedSAETransformer": [[14, 1, 1, "", "HookedSAETransformer"], [14, 5, 1, "", "get_deep_attr"], [14, 5, 1, "", "set_deep_attr"]], "transformer_lens.HookedSAETransformer.HookedSAETransformer": [[14, 2, 1, "", "__init__"], [14, 2, 1, "", "add_sae"], [14, 2, 1, "", "reset_saes"], [14, 2, 1, "", "run_with_cache_with_saes"], [14, 2, 1, "", "run_with_hooks_with_saes"], [14, 2, 1, "", "run_with_saes"], [14, 2, 1, "", "saes"]], "transformer_lens.HookedTransformer": [[15, 1, 1, "", "HookedTransformer"], [15, 1, 1, "", "Output"]], "transformer_lens.HookedTransformer.HookedTransformer": [[15, 3, 1, "", "OV"], [15, 3, 1, "", "QK"], [15, 3, 1, "", "W_E"], [15, 3, 1, "", "W_E_pos"], [15, 3, 1, "", "W_K"], [15, 3, 1, "", "W_O"], [15, 3, 1, "", "W_Q"], [15, 3, 1, "", "W_U"], [15, 3, 1, "", "W_V"], [15, 3, 1, "", "W_gate"], [15, 3, 1, "", "W_in"], [15, 3, 1, "", "W_out"], [15, 3, 1, "", "W_pos"], [15, 2, 1, "", "__init__"], [15, 2, 1, "", "accumulated_bias"], [15, 2, 1, "", "all_composition_scores"], [15, 2, 1, "", "all_head_labels"], [15, 3, 1, "", "b_K"], [15, 3, 1, "", "b_O"], [15, 3, 1, "", "b_Q"], [15, 3, 1, "", "b_U"], [15, 3, 1, "", "b_V"], [15, 3, 1, "", "b_in"], [15, 3, 1, "", "b_out"], [15, 2, 1, "", "center_unembed"], [15, 2, 1, "", "center_writing_weights"], [15, 2, 1, "", "check_hooks_to_add"], [15, 2, 1, "", "cpu"], [15, 2, 1, "", "cuda"], [15, 2, 1, "", "fold_layer_norm"], [15, 2, 1, "", "fold_value_biases"], [15, 2, 1, "", "forward"], [15, 2, 1, "", "from_pretrained"], [15, 2, 1, "", "from_pretrained_no_processing"], [15, 2, 1, "", "generate"], [15, 2, 1, "", "get_token_position"], [15, 2, 1, "", "init_weights"], [15, 2, 1, "", "input_to_embed"], [15, 4, 1, "", "ln_final"], [15, 2, 1, "", "load_and_process_state_dict"], [15, 2, 1, "", "load_sample_training_dataset"], [15, 2, 1, "", "loss_fn"], [15, 2, 1, "", "move_model_modules_to_device"], [15, 2, 1, "", "mps"], [15, 2, 1, "", "process_weights_"], [15, 2, 1, "", "refactor_factored_attn_matrices"], [15, 2, 1, "", "run_with_cache"], [15, 2, 1, "", "sample_datapoint"], [15, 2, 1, "", "set_tokenizer"], [15, 2, 1, "", "set_use_attn_in"], [15, 2, 1, "", "set_use_attn_result"], [15, 2, 1, "", "set_use_hook_mlp_in"], [15, 2, 1, "", "set_use_split_qkv_input"], [15, 2, 1, "", "to"], [15, 2, 1, "", "to_single_str_token"], [15, 2, 1, "", "to_single_token"], [15, 2, 1, "", "to_str_tokens"], [15, 2, 1, "", "to_string"], [15, 2, 1, "", "to_tokens"], [15, 2, 1, "", "tokens_to_residual_directions"]], "transformer_lens.HookedTransformer.Output": [[15, 4, 1, "", "logits"], [15, 4, 1, "", "loss"]], "transformer_lens.HookedTransformerConfig": [[16, 1, 1, "", "HookedTransformerConfig"]], "transformer_lens.HookedTransformerConfig.HookedTransformerConfig": [[16, 4, 1, "", "act_fn"], [16, 4, 1, "", "attention_dir"], [16, 4, 1, "", "attn_only"], [16, 4, 1, "", "attn_types"], [16, 4, 1, "", "checkpoint_index"], [16, 4, 1, "", "checkpoint_label_type"], [16, 4, 1, "", "checkpoint_value"], [16, 4, 1, "", "d_head"], [16, 4, 1, "", "d_mlp"], [16, 4, 1, "", "d_model"], [16, 4, 1, "", "d_vocab"], [16, 4, 1, "", "d_vocab_out"], [16, 4, 1, "", "default_prepend_bos"], [16, 4, 1, "", "device"], [16, 4, 1, "", "dtype"], [16, 4, 1, "", "eps"], [16, 4, 1, "", "experts_per_token"], [16, 4, 1, "", "final_rms"], [16, 4, 1, "", "from_checkpoint"], [16, 2, 1, "", "from_dict"], [16, 4, 1, "", "gated_mlp"], [16, 4, 1, "", "init_mode"], [16, 4, 1, "", "init_weights"], [16, 4, 1, "", "initializer_range"], [16, 4, 1, "", "load_in_4bit"], [16, 4, 1, "", "model_name"], [16, 4, 1, "", "n_ctx"], [16, 4, 1, "", "n_devices"], [16, 4, 1, "", "n_heads"], [16, 4, 1, "", "n_key_value_heads"], [16, 4, 1, "", "n_layers"], [16, 4, 1, "", "n_params"], [16, 4, 1, "", "normalization_type"], [16, 4, 1, "", "num_experts"], [16, 4, 1, "", "original_architecture"], [16, 4, 1, "", "parallel_attn_mlp"], [16, 4, 1, "", "positional_embedding_type"], [16, 4, 1, "", "post_embedding_ln"], [16, 4, 1, "", "rotary_adjacent_pairs"], [16, 4, 1, "", "rotary_base"], [16, 4, 1, "", "rotary_dim"], [16, 4, 1, "", "scale_attn_by_inverse_layer_idx"], [16, 4, 1, "", "seed"], [16, 2, 1, "", "set_seed_everywhere"], [16, 2, 1, "", "to_dict"], [16, 4, 1, "", "tokenizer_name"], [16, 4, 1, "", "tokenizer_prepends_bos"], [16, 4, 1, "", "trust_remote_code"], [16, 4, 1, "", "use_attn_in"], [16, 4, 1, "", "use_attn_result"], [16, 4, 1, "", "use_attn_scale"], [16, 4, 1, "", "use_hook_mlp_in"], [16, 4, 1, "", "use_hook_tokens"], [16, 4, 1, "", "use_local_attn"], [16, 4, 1, "", "use_split_qkv_input"], [16, 4, 1, "", "window_size"]], "transformer_lens.SVDInterpreter": [[17, 1, 1, "", "SVDInterpreter"]], "transformer_lens.SVDInterpreter.SVDInterpreter": [[17, 2, 1, "", "get_singular_vectors"]], "transformer_lens.components": [[18, 1, 1, "", "AbstractAttention"], [18, 1, 1, "", "Attention"], [18, 1, 1, "", "BertBlock"], [18, 1, 1, "", "BertEmbed"], [18, 1, 1, "", "BertMLMHead"], [18, 1, 1, "", "Embed"], [18, 1, 1, "", "GatedMLP"], [18, 1, 1, "", "GroupedQueryAttention"], [18, 1, 1, "", "LayerNorm"], [18, 1, 1, "", "LayerNormPre"], [18, 1, 1, "", "MLP"], [18, 1, 1, "", "MoE"], [18, 1, 1, "", "PosEmbed"], [18, 1, 1, "", "RMSNorm"], [18, 1, 1, "", "RMSNormPre"], [18, 1, 1, "", "TokenTypeEmbed"], [18, 1, 1, "", "TransformerBlock"], [18, 1, 1, "", "Unembed"]], "transformer_lens.components.AbstractAttention": [[18, 3, 1, "", "OV"], [18, 3, 1, "", "QK"], [18, 2, 1, "", "__init__"], [18, 4, 1, "", "alibi"], [18, 2, 1, "", "apply_causal_mask"], [18, 2, 1, "", "apply_rotary"], [18, 2, 1, "", "calculate_attention_scores"], [18, 2, 1, "", "calculate_qkv_matrices"], [18, 2, 1, "", "calculate_sin_cos_rotary"], [18, 2, 1, "", "calculate_z_scores"], [18, 2, 1, "", "create_alibi_bias"], [18, 2, 1, "", "create_alibi_multipliers"], [18, 2, 1, "", "create_alibi_slope"], [18, 2, 1, "", "forward"], [18, 2, 1, "", "rotate_every_two"]], "transformer_lens.components.Attention": [[18, 2, 1, "", "__init__"]], "transformer_lens.components.BertBlock": [[18, 2, 1, "", "forward"]], "transformer_lens.components.BertEmbed": [[18, 2, 1, "", "forward"]], "transformer_lens.components.BertMLMHead": [[18, 2, 1, "", "forward"]], "transformer_lens.components.Embed": [[18, 2, 1, "", "forward"]], "transformer_lens.components.GatedMLP": [[18, 4, 1, "", "act_fn"], [18, 2, 1, "", "forward"], [18, 4, 1, "", "ln"]], "transformer_lens.components.GroupedQueryAttention": [[18, 3, 1, "", "W_K"], [18, 3, 1, "", "W_V"], [18, 2, 1, "", "__init__"], [18, 3, 1, "", "b_K"], [18, 3, 1, "", "b_V"], [18, 2, 1, "", "calculate_attention_scores"], [18, 2, 1, "", "calculate_qkv_matrices"], [18, 2, 1, "", "calculate_z_scores"]], "transformer_lens.components.LayerNorm": [[18, 2, 1, "", "__init__"], [18, 2, 1, "", "forward"]], "transformer_lens.components.LayerNormPre": [[18, 2, 1, "", "__init__"], [18, 2, 1, "", "forward"]], "transformer_lens.components.MLP": [[18, 4, 1, "", "act_fn"], [18, 2, 1, "", "forward"], [18, 4, 1, "", "ln"]], "transformer_lens.components.MoE": [[18, 2, 1, "", "forward"]], "transformer_lens.components.PosEmbed": [[18, 2, 1, "", "forward"]], "transformer_lens.components.RMSNorm": [[18, 2, 1, "", "__init__"], [18, 2, 1, "", "forward"]], "transformer_lens.components.RMSNormPre": [[18, 2, 1, "", "__init__"], [18, 2, 1, "", "forward"]], "transformer_lens.components.TokenTypeEmbed": [[18, 2, 1, "", "forward"]], "transformer_lens.components.TransformerBlock": [[18, 2, 1, "", "forward"], [18, 4, 1, "", "ln1"], [18, 4, 1, "", "ln2"], [18, 4, 1, "", "mlp"]], "transformer_lens.components.Unembed": [[18, 2, 1, "", "forward"]], "transformer_lens.evals": [[19, 1, 1, "", "IOIDataset"], [19, 5, 1, "", "evaluate"], [19, 5, 1, "", "evaluate_on_dataset"], [19, 5, 1, "", "induction_loss"], [19, 5, 1, "", "ioi_eval"], [19, 5, 1, "", "make_code_data_loader"], [19, 5, 1, "", "make_owt_data_loader"], [19, 5, 1, "", "make_pile_data_loader"], [19, 5, 1, "", "make_wiki_data_loader"], [19, 5, 1, "", "sanity_check"]], "transformer_lens.evals.IOIDataset": [[19, 2, 1, "", "get_default_names"], [19, 2, 1, "", "get_default_nouns"], [19, 2, 1, "", "get_default_templates"], [19, 2, 1, "", "get_sample"]], "transformer_lens.head_detector": [[20, 5, 1, "", "compute_head_attention_similarity_score"], [20, 5, 1, "", "detect_head"], [20, 5, 1, "", "get_duplicate_token_head_detection_pattern"], [20, 5, 1, "", "get_induction_head_detection_pattern"], [20, 5, 1, "", "get_previous_token_head_detection_pattern"], [20, 5, 1, "", "get_supported_heads"]], "transformer_lens.hook_points": [[21, 1, 1, "", "HookPoint"], [21, 1, 1, "", "HookedRootModule"], [21, 1, 1, "", "LensHandle"]], "transformer_lens.hook_points.HookPoint": [[21, 2, 1, "", "add_hook"], [21, 2, 1, "", "add_perma_hook"], [21, 2, 1, "", "clear_context"], [21, 2, 1, "", "forward"], [21, 2, 1, "", "layer"], [21, 2, 1, "", "remove_hooks"]], "transformer_lens.hook_points.HookedRootModule": [[21, 2, 1, "", "add_caching_hooks"], [21, 2, 1, "", "add_hook"], [21, 2, 1, "", "add_perma_hook"], [21, 2, 1, "", "cache_all"], [21, 2, 1, "", "cache_some"], [21, 2, 1, "", "check_and_add_hook"], [21, 2, 1, "", "check_hooks_to_add"], [21, 2, 1, "", "clear_contexts"], [21, 2, 1, "", "get_caching_hooks"], [21, 2, 1, "", "hook_points"], [21, 2, 1, "", "hooks"], [21, 2, 1, "", "remove_all_hook_fns"], [21, 2, 1, "", "reset_hooks"], [21, 2, 1, "", "run_with_cache"], [21, 2, 1, "", "run_with_hooks"], [21, 2, 1, "", "setup"]], "transformer_lens.hook_points.LensHandle": [[21, 4, 1, "", "context_level"], [21, 4, 1, "", "hook"], [21, 4, 1, "", "is_permanent"]], "transformer_lens.loading_from_pretrained": [[22, 1, 1, "", "Config"], [22, 6, 1, "", "MODEL_ALIASES"], [22, 6, 1, "", "NON_HF_HOSTED_MODEL_NAMES"], [22, 6, 1, "", "OFFICIAL_MODEL_NAMES"], [22, 5, 1, "", "convert_bloom_weights"], [22, 5, 1, "", "convert_coder_weights"], [22, 5, 1, "", "convert_mistral_weights"], [22, 5, 1, "", "convert_mixtral_weights"], [22, 5, 1, "", "convert_phi_weights"], [22, 5, 1, "", "convert_qwen2_weights"], [22, 5, 1, "", "convert_qwen_weights"], [22, 5, 1, "", "get_checkpoint_labels"], [22, 5, 1, "", "get_num_params_of_pretrained"], [22, 5, 1, "", "get_pretrained_model_config"]], "transformer_lens.loading_from_pretrained.Config": [[22, 4, 1, "", "d_head"], [22, 4, 1, "", "d_mlp"], [22, 4, 1, "", "d_model"], [22, 4, 1, "", "d_vocab"], [22, 4, 1, "", "debug"], [22, 4, 1, "", "init_range"], [22, 4, 1, "", "layer_norm_eps"], [22, 4, 1, "", "n_ctx"], [22, 4, 1, "", "n_heads"], [22, 4, 1, "", "n_layers"]], "transformer_lens.past_key_value_caching": [[23, 1, 1, "", "HookedTransformerKeyValueCache"], [23, 1, 1, "", "HookedTransformerKeyValueCacheEntry"]], "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache": [[23, 2, 1, "", "append_attention_mask"], [23, 4, 1, "", "entries"], [23, 2, 1, "", "freeze"], [23, 4, 1, "", "frozen"], [23, 2, 1, "", "init_cache"], [23, 4, 1, "", "previous_attention_mask"], [23, 2, 1, "", "unfreeze"]], "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry": [[23, 2, 1, "", "append"], [23, 4, 1, "", "frozen"], [23, 2, 1, "", "init_cache_entry"], [23, 4, 1, "", "past_keys"], [23, 4, 1, "", "past_values"]], "transformer_lens.patching": [[24, 5, 1, "", "generic_activation_patch"], [24, 5, 1, "", "get_act_patch_attn_head_all_pos_every"], [24, 5, 1, "", "get_act_patch_attn_head_by_pos_every"], [24, 5, 1, "", "get_act_patch_attn_head_k_all_pos"], [24, 5, 1, "", "get_act_patch_attn_head_k_by_pos"], [24, 5, 1, "", "get_act_patch_attn_head_out_all_pos"], [24, 5, 1, "", "get_act_patch_attn_head_out_by_pos"], [24, 5, 1, "", "get_act_patch_attn_head_pattern_all_pos"], [24, 5, 1, "", "get_act_patch_attn_head_pattern_by_pos"], [24, 5, 1, "", "get_act_patch_attn_head_pattern_dest_src_pos"], [24, 5, 1, "", "get_act_patch_attn_head_q_all_pos"], [24, 5, 1, "", "get_act_patch_attn_head_q_by_pos"], [24, 5, 1, "", "get_act_patch_attn_head_v_all_pos"], [24, 5, 1, "", "get_act_patch_attn_head_v_by_pos"], [24, 5, 1, "", "get_act_patch_attn_out"], [24, 5, 1, "", "get_act_patch_block_every"], [24, 5, 1, "", "get_act_patch_mlp_out"], [24, 5, 1, "", "get_act_patch_resid_mid"], [24, 5, 1, "", "get_act_patch_resid_pre"], [24, 5, 1, "", "layer_head_dest_src_pos_pattern_patch_setter"], [24, 5, 1, "", "layer_head_pattern_patch_setter"], [24, 5, 1, "", "layer_head_pos_pattern_patch_setter"], [24, 5, 1, "", "layer_head_vector_patch_setter"], [24, 5, 1, "", "layer_pos_head_vector_patch_setter"], [24, 5, 1, "", "layer_pos_patch_setter"]], "transformer_lens.train": [[25, 1, 1, "", "HookedTransformerTrainConfig"], [25, 5, 1, "", "train"]], "transformer_lens.train.HookedTransformerTrainConfig": [[25, 4, 1, "", "batch_size"], [25, 4, 1, "", "device"], [25, 4, 1, "", "lr"], [25, 4, 1, "", "max_grad_norm"], [25, 4, 1, "", "max_steps"], [25, 4, 1, "", "momentum"], [25, 4, 1, "", "num_epochs"], [25, 4, 1, "", "optimizer_name"], [25, 4, 1, "", "print_every"], [25, 4, 1, "", "save_dir"], [25, 4, 1, "", "save_every"], [25, 4, 1, "", "seed"], [25, 4, 1, "", "wandb"], [25, 4, 1, "", "wandb_project_name"], [25, 4, 1, "", "warmup_steps"], [25, 4, 1, "", "weight_decay"]], "transformer_lens.utilities": [[27, 0, 0, "-", "devices"]], "transformer_lens.utilities.devices": [[27, 5, 1, "", "get_device_for_block_index"], [27, 5, 1, "", "move_to_and_update_config"]], "transformer_lens.utils": [[28, 1, 1, "", "LocallyOverridenDefaults"], [28, 1, 1, "", "Slice"], [28, 6, 1, "", "SliceInput"], [28, 5, 1, "", "calc_fan_in_and_fan_out"], [28, 5, 1, "", "composition_scores"], [28, 5, 1, "", "download_file_from_hf"], [28, 5, 1, "", "gelu_fast"], [28, 5, 1, "", "gelu_new"], [28, 5, 1, "", "get_act_name"], [28, 5, 1, "", "get_attention_mask"], [28, 5, 1, "", "get_corner"], [28, 5, 1, "", "get_cumsum_along_dim"], [28, 5, 1, "", "get_dataset"], [28, 5, 1, "", "get_device"], [28, 5, 1, "", "get_input_with_manually_prepended_bos"], [28, 5, 1, "", "get_nested_attr"], [28, 5, 1, "", "get_offset_position_ids"], [28, 5, 1, "", "get_tokenizer_with_bos"], [28, 5, 1, "", "get_tokens_with_bos_removed"], [28, 5, 1, "", "init_kaiming_normal_"], [28, 5, 1, "", "init_kaiming_uniform_"], [28, 5, 1, "", "init_xavier_normal_"], [28, 5, 1, "", "init_xavier_uniform_"], [28, 5, 1, "", "is_lower_triangular"], [28, 5, 1, "", "is_square"], [28, 5, 1, "", "keep_single_column"], [28, 5, 1, "", "lm_accuracy"], [28, 5, 1, "", "lm_cross_entropy_loss"], [28, 5, 1, "", "override_or_use_default_value"], [28, 5, 1, "", "print_gpu_mem"], [28, 5, 1, "", "remove_batch_dim"], [28, 5, 1, "", "repeat_along_head_dimension"], [28, 5, 1, "", "sample_logits"], [28, 5, 1, "", "set_nested_attr"], [28, 5, 1, "", "solu"], [28, 5, 1, "", "test_prompt"], [28, 5, 1, "", "to_numpy"], [28, 5, 1, "", "tokenize_and_concatenate"], [28, 5, 1, "", "transpose"]], "transformer_lens.utils.LocallyOverridenDefaults": [[28, 2, 1, "", "__init__"]], "transformer_lens.utils.Slice": [[28, 2, 1, "", "__init__"], [28, 2, 1, "", "apply"], [28, 2, 1, "", "indices"], [28, 4, 1, "", "slice"], [28, 2, 1, "", "unwrap"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:attribute", "5": "py:function", "6": "py:data"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"], "6": ["py", "data", "Python data"]}, "titleterms": {"citat": 0, "contribut": 1, "setup": [1, 29, 30, 31], "devcontain": 1, "manual": 1, "test": 1, "run": [1, 31], "format": 1, "document": 1, "docstr": 1, "style": 1, "guid": 1, "section": 1, "order": 1, "support": 1, "sphinx": 1, "properti": [1, 32], "refer": 1, "other": [1, 31], "function": [1, 30], "class": [1, 31], "math": 1, "markup": 1, "galleri": 2, "get": [3, 4], "start": [3, 4, 6], "advic": 3, "read": [3, 30], "code": 3, "instal": 3, "huggingfac": 3, "gate": 3, "access": [3, 31], "mechanist": [4, 33], "interpret": [4, 31, 33], "special": 5, "case": 5, "mixtur": 5, "expert": 5, "error": 5, "rate": 5, "tutori": 6, "where": 6, "To": 6, "demo": [6, 30, 31], "transform": [7, 31], "len": [7, 30, 31], "api": 7, "content": 7, "transformer_len": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "submodul": [8, 26], "subpackag": 8, "activationcach": 9, "factoredmatrix": 10, "hookedencod": 11, "hookedsa": 12, "hookedsaeconfig": 13, "hookedsaetransform": 14, "hookedtransform": 15, "hookedtransformerconfig": 16, "svdinterpret": 17, "compon": 18, "eval": 19, "head_detector": 20, "hook_point": 21, "loading_from_pretrain": 22, "past_key_value_cach": 23, "patch": [24, 30, 31], "train": [25, 31], "util": [26, 27, 28], "devic": 27, "bert": 29, "transformerlen": [29, 33], "exploratori": 30, "analysi": 30, "tip": 30, "thi": 30, "environ": 30, "ignor": 30, "import": [30, 31], "pytorch": 30, "plot": 30, "helper": 30, "introduct": [30, 31], "indirect": [30, 31], "object": [30, 31], "identif": [30, 31], "brainstorm": 30, "what": 30, "": 30, "actual": 30, "go": 30, "On": 30, "option": 30, "direct": 30, "logit": 30, "attribut": 30, "layer": 30, "head": [30, 31], "attent": 30, "activ": [30, 31], "residu": 30, "stream": 30, "decompos": 30, "consolid": 30, "understand": 30, "visual": 30, "pattern": 30, "compar": 30, "paper": 30, "bonu": 30, "explor": 30, "anomali": 30, "earli": 30, "ar": 30, "induct": [30, 31], "implic": 30, "backup": 30, "name": [30, 31], "mover": 30, "main": 31, "notebook": 31, "load": 31, "model": [31, 32, 33], "cach": 31, "all": 31, "hook": 31, "interven": 31, "task": 31, "avail": 31, "an": 31, "overview": 31, "open": 31, "sourc": 31, "librari": [31, 33], "some": 31, "friendli": 31, "i": 31, "ve": 31, "includ": 31, "resourc": 31, "architectur": 31, "paramet": 31, "fold": 31, "layernorm": 31, "For": 31, "curiou": 31, "featur": 31, "deal": 31, "token": 31, "gotcha": 31, "prepend_bo": 31, "factor": 31, "matrix": 31, "basic": 31, "exampl": 31, "medium": 31, "eigenvalu": 31, "copi": 31, "score": 31, "gener": [31, 33], "text": 31, "point": 31, "toi": 31, "pre": 31, "checkpoint": 31, "phase": 31, "transit": 31, "tabl": 32, "A": 33, "languag": 33}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx": 57}, "alltitles": {"Citation": [[0, "citation"]], "Contributing": [[1, "contributing"]], "Setup": [[1, "setup"], [29, "Setup"], [30, "Setup"], [31, "Setup"]], "DevContainer": [[1, "devcontainer"]], "Manual Setup": [[1, "manual-setup"]], "Testing": [[1, "testing"]], "Running the tests": [[1, "running-the-tests"]], "Formatting": [[1, "formatting"]], "Documentation": [[1, "documentation"]], "Docstring Style Guide": [[1, "docstring-style-guide"]], "Sections and Order": [[1, "sections-and-order"]], "Supported Sphinx Properties": [[1, "supported-sphinx-properties"]], "References to Other Functions/Classes": [[1, "references-to-other-functions-classes"]], "Maths": [[1, "maths"]], "Markup": [[1, "markup"]], "Gallery": [[2, "gallery"]], "Getting Started": [[3, "getting-started"]], "Advice for Reading the Code": [[3, "advice-for-reading-the-code"]], "Installation": [[3, "installation"]], "Huggingface Gated Access": [[3, "huggingface-gated-access"]], "Getting Started in Mechanistic Interpretability": [[4, "getting-started-in-mechanistic-interpretability"]], "Special Cases": [[5, "special-cases"]], "Mixture of Experts error rates": [[5, "mixture-of-experts-error-rates"]], "Tutorials": [[6, "tutorials"]], "Where To Start": [[6, "where-to-start"]], "Demos": [[6, "demos"]], "Transformer Lens API": [[7, "transformer-lens-api"]], "Contents": [[7, "contents"]], "transformer_lens": [[8, "transformer-lens"]], "Submodules": [[8, "submodules"], [26, "submodules"]], "Subpackages": [[8, "subpackages"]], "transformer_lens.ActivationCache": [[9, "module-transformer_lens.ActivationCache"]], "transformer_lens.FactoredMatrix": [[10, "module-transformer_lens.FactoredMatrix"]], "transformer_lens.HookedEncoder": [[11, "module-transformer_lens.HookedEncoder"]], "transformer_lens.HookedSAE": [[12, "module-transformer_lens.HookedSAE"]], "transformer_lens.HookedSAEConfig": [[13, "module-transformer_lens.HookedSAEConfig"]], "transformer_lens.HookedSAETransformer": [[14, "module-transformer_lens.HookedSAETransformer"]], "transformer_lens.HookedTransformer": [[15, "module-transformer_lens.HookedTransformer"]], "transformer_lens.HookedTransformerConfig": [[16, "module-transformer_lens.HookedTransformerConfig"]], "transformer_lens.SVDInterpreter": [[17, "module-transformer_lens.SVDInterpreter"]], "transformer_lens.components": [[18, "module-transformer_lens.components"]], "transformer_lens.evals": [[19, "module-transformer_lens.evals"]], "transformer_lens.head_detector": [[20, "module-transformer_lens.head_detector"]], "transformer_lens.hook_points": [[21, "module-transformer_lens.hook_points"]], "transformer_lens.loading_from_pretrained": [[22, "module-transformer_lens.loading_from_pretrained"]], "transformer_lens.past_key_value_caching": [[23, "module-transformer_lens.past_key_value_caching"]], "transformer_lens.patching": [[24, "module-transformer_lens.patching"]], "transformer_lens.train": [[25, "module-transformer_lens.train"]], "transformer_lens.utilities": [[26, "transformer-lens-utilities"]], "transformer_lens.utilities.devices": [[27, "module-transformer_lens.utilities.devices"]], "transformer_lens.utils": [[28, "module-transformer_lens.utils"]], "BERT in TransformerLens": [[29, "BERT-in-TransformerLens"]], "BERT": [[29, "BERT"]], "Exploratory Analysis Demo": [[30, "Exploratory-Analysis-Demo"]], "Tips for Reading This": [[30, "Tips-for-Reading-This"]], "Environment Setup (ignore)": [[30, "Environment-Setup-(ignore)"]], "Imports": [[30, "Imports"]], "PyTorch Setup": [[30, "PyTorch-Setup"]], "Plotting Helper Functions (ignore)": [[30, "Plotting-Helper-Functions-(ignore)"]], "Introduction": [[30, "Introduction"], [31, "Introduction"]], "Indirect Object Identification": [[30, "Indirect-Object-Identification"]], "Brainstorm What\u2019s Actually Going On (Optional)": [[30, "Brainstorm-What's-Actually-Going-On-(Optional)"]], "Direct Logit Attribution": [[30, "Direct-Logit-Attribution"]], "Logit Lens": [[30, "Logit-Lens"]], "Layer Attribution": [[30, "Layer-Attribution"]], "Head Attribution": [[30, "Head-Attribution"]], "Attention Analysis": [[30, "Attention-Analysis"]], "Activation Patching": [[30, "Activation-Patching"]], "Residual Stream": [[30, "Residual-Stream"]], "Layers": [[30, "Layers"]], "Heads": [[30, "Heads"]], "Decomposing Heads": [[30, "Decomposing-Heads"]], "Consolidating Understanding": [[30, "Consolidating-Understanding"]], "Visualizing Attention Patterns": [[30, "Visualizing-Attention-Patterns"]], "Comparing to the Paper": [[30, "Comparing-to-the-Paper"]], "Bonus: Exploring Anomalies": [[30, "Bonus:-Exploring-Anomalies"]], "Early Heads are Induction Heads(?!)": [[30, "Early-Heads-are-Induction-Heads(?!)"]], "Implications": [[30, "Implications"]], "Backup Name Mover Heads": [[30, "Backup-Name-Mover-Heads"]], "Transformer Lens Main Demo Notebook": [[31, "Transformer-Lens-Main-Demo-Notebook"]], "Loading and Running Models": [[31, "Loading-and-Running-Models"]], "Caching all Activations": [[31, "Caching-all-Activations"]], "Hooks: Intervening on Activations": [[31, "Hooks:-Intervening-on-Activations"]], "Activation Patching on the Indirect Object Identification Task": [[31, "Activation-Patching-on-the-Indirect-Object-Identification-Task"]], "Hooks: Accessing Activations": [[31, "Hooks:-Accessing-Activations"]], "Available Models": [[31, "Available-Models"]], "An overview of the important open source models in the library": [[31, "An-overview-of-the-important-open-source-models-in-the-library"]], "An overview of some interpretability-friendly models I\u2019ve trained and included": [[31, "An-overview-of-some-interpretability-friendly-models-I've-trained-and-included"]], "Other Resources:": [[31, "Other-Resources:"]], "Transformer architecture": [[31, "Transformer-architecture"]], "Parameter Names": [[31, "Parameter-Names"]], "Activation + Hook Names": [[31, "Activation-+-Hook-Names"]], "Folding LayerNorm (For the Curious)": [[31, "Folding-LayerNorm-(For-the-Curious)"]], "Features": [[31, "Features"]], "Dealing with tokens": [[31, "Dealing-with-tokens"]], "Gotcha: prepend_bos": [[31, "Gotcha:-prepend_bos"]], "Factored Matrix Class": [[31, "Factored-Matrix-Class"]], "Basic Examples": [[31, "Basic-Examples"]], "Medium Example: Eigenvalue Copying Scores": [[31, "Medium-Example:-Eigenvalue-Copying-Scores"]], "Generating Text": [[31, "Generating-Text"]], "Hook Points": [[31, "Hook-Points"]], "Toy Example": [[31, "Toy-Example"]], "Loading Pre-Trained Checkpoints": [[31, "Loading-Pre-Trained-Checkpoints"]], "Example: Induction Head Phase Transition": [[31, "Example:-Induction-Head-Phase-Transition"]], "Model Properties Table": [[32, "model-properties-table"]], "TransformerLens": [[33, "transformerlens"]], "A Library for Mechanistic Interpretability of Generative Language Models": [[33, "a-library-for-mechanistic-interpretability-of-generative-language-models"]]}, "indexentries": {"activationcache (class in transformer_lens.activationcache)": [[9, "transformer_lens.ActivationCache.ActivationCache"]], "accumulated_resid() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.accumulated_resid"]], "apply_ln_to_stack() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.apply_ln_to_stack"]], "apply_slice_to_batch_dim() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.apply_slice_to_batch_dim"]], "compute_head_results() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.compute_head_results"]], "decompose_resid() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.decompose_resid"]], "get_full_resid_decomposition() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.get_full_resid_decomposition"]], "get_neuron_results() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.get_neuron_results"]], "items() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.items"]], "keys() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.keys"]], "logit_attrs() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.logit_attrs"]], "module": [[9, "module-transformer_lens.ActivationCache"], [10, "module-transformer_lens.FactoredMatrix"], [11, "module-transformer_lens.HookedEncoder"], [12, "module-transformer_lens.HookedSAE"], [13, "module-transformer_lens.HookedSAEConfig"], [14, "module-transformer_lens.HookedSAETransformer"], [15, "module-transformer_lens.HookedTransformer"], [16, "module-transformer_lens.HookedTransformerConfig"], [17, "module-transformer_lens.SVDInterpreter"], [18, "module-transformer_lens.components"], [19, "module-transformer_lens.evals"], [20, "module-transformer_lens.head_detector"], [21, "module-transformer_lens.hook_points"], [22, "module-transformer_lens.loading_from_pretrained"], [23, "module-transformer_lens.past_key_value_caching"], [24, "module-transformer_lens.patching"], [25, "module-transformer_lens.train"], [27, "module-transformer_lens.utilities.devices"], [28, "module-transformer_lens.utils"]], "remove_batch_dim() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.remove_batch_dim"]], "stack_activation() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.stack_activation"]], "stack_head_results() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.stack_head_results"]], "stack_neuron_results() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.stack_neuron_results"]], "to() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.to"]], "toggle_autodiff() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.toggle_autodiff"]], "transformer_lens.activationcache": [[9, "module-transformer_lens.ActivationCache"]], "values() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.values"]], "ab (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.AB"]], "ba (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.BA"]], "factoredmatrix (class in transformer_lens.factoredmatrix)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix"]], "s (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.S"]], "t (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.T"]], "u (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.U"]], "vh (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.Vh"]], "collapse_l() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.collapse_l"]], "collapse_r() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.collapse_r"]], "eigenvalues (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.eigenvalues"]], "get_corner() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.get_corner"]], "make_even() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.make_even"]], "ndim (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.ndim"]], "norm() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.norm"]], "pair (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.pair"]], "svd() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.svd"]], "transformer_lens.factoredmatrix": [[10, "module-transformer_lens.FactoredMatrix"]], "unsqueeze() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.unsqueeze"]], "hookedencoder (class in transformer_lens.hookedencoder)": [[11, "transformer_lens.HookedEncoder.HookedEncoder"]], "ov (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.OV"]], "qk (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.QK"]], "w_e (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_E"]], "w_e_pos (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_E_pos"]], "w_k (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_K"]], "w_o (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_O"]], "w_q (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_Q"]], "w_u (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_U"]], "w_v (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_V"]], "w_in (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_in"]], "w_out (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_out"]], "w_pos (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_pos"]], "all_head_labels() (transformer_lens.hookedencoder.hookedencoder method)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.all_head_labels"]], "b_k (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.b_K"]], "b_o (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.b_O"]], "b_q (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.b_Q"]], "b_u (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.b_U"]], "b_v (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.b_V"]], "b_in (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.b_in"]], "b_out (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.b_out"]], "cpu() (transformer_lens.hookedencoder.hookedencoder method)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.cpu"]], "cuda() (transformer_lens.hookedencoder.hookedencoder method)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.cuda"]], "forward() (transformer_lens.hookedencoder.hookedencoder method)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.forward"]], "from_pretrained() (transformer_lens.hookedencoder.hookedencoder class method)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.from_pretrained"]], "mps() (transformer_lens.hookedencoder.hookedencoder method)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.mps"]], "run_with_cache() (transformer_lens.hookedencoder.hookedencoder method)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.run_with_cache"]], "to() (transformer_lens.hookedencoder.hookedencoder method)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.to"]], "transformer_lens.hookedencoder": [[11, "module-transformer_lens.HookedEncoder"]], "hookedsae (class in transformer_lens.hookedsae)": [[12, "transformer_lens.HookedSAE.HookedSAE"]], "forward() (transformer_lens.hookedsae.hookedsae method)": [[12, "transformer_lens.HookedSAE.HookedSAE.forward"]], "transformer_lens.hookedsae": [[12, "module-transformer_lens.HookedSAE"]], "hookedsaeconfig (class in transformer_lens.hookedsaeconfig)": [[13, "transformer_lens.HookedSAEConfig.HookedSAEConfig"]], "d_in (transformer_lens.hookedsaeconfig.hookedsaeconfig attribute)": [[13, "transformer_lens.HookedSAEConfig.HookedSAEConfig.d_in"]], "d_sae (transformer_lens.hookedsaeconfig.hookedsaeconfig attribute)": [[13, "transformer_lens.HookedSAEConfig.HookedSAEConfig.d_sae"]], "device (transformer_lens.hookedsaeconfig.hookedsaeconfig attribute)": [[13, "transformer_lens.HookedSAEConfig.HookedSAEConfig.device"]], "dtype (transformer_lens.hookedsaeconfig.hookedsaeconfig attribute)": [[13, "transformer_lens.HookedSAEConfig.HookedSAEConfig.dtype"]], "from_dict() (transformer_lens.hookedsaeconfig.hookedsaeconfig class method)": [[13, "transformer_lens.HookedSAEConfig.HookedSAEConfig.from_dict"]], "hook_name (transformer_lens.hookedsaeconfig.hookedsaeconfig attribute)": [[13, "transformer_lens.HookedSAEConfig.HookedSAEConfig.hook_name"]], "seed (transformer_lens.hookedsaeconfig.hookedsaeconfig attribute)": [[13, "transformer_lens.HookedSAEConfig.HookedSAEConfig.seed"]], "set_seed_everywhere() (transformer_lens.hookedsaeconfig.hookedsaeconfig method)": [[13, "transformer_lens.HookedSAEConfig.HookedSAEConfig.set_seed_everywhere"]], "to_dict() (transformer_lens.hookedsaeconfig.hookedsaeconfig method)": [[13, "transformer_lens.HookedSAEConfig.HookedSAEConfig.to_dict"]], "transformer_lens.hookedsaeconfig": [[13, "module-transformer_lens.HookedSAEConfig"]], "use_error_term (transformer_lens.hookedsaeconfig.hookedsaeconfig attribute)": [[13, "transformer_lens.HookedSAEConfig.HookedSAEConfig.use_error_term"]], "hookedsaetransformer (class in transformer_lens.hookedsaetransformer)": [[14, "transformer_lens.HookedSAETransformer.HookedSAETransformer"]], "__init__() (transformer_lens.hookedsaetransformer.hookedsaetransformer method)": [[14, "transformer_lens.HookedSAETransformer.HookedSAETransformer.__init__"]], "add_sae() (transformer_lens.hookedsaetransformer.hookedsaetransformer method)": [[14, "transformer_lens.HookedSAETransformer.HookedSAETransformer.add_sae"]], "get_deep_attr() (in module transformer_lens.hookedsaetransformer)": [[14, "transformer_lens.HookedSAETransformer.get_deep_attr"]], "reset_saes() (transformer_lens.hookedsaetransformer.hookedsaetransformer method)": [[14, "transformer_lens.HookedSAETransformer.HookedSAETransformer.reset_saes"]], "run_with_cache_with_saes() (transformer_lens.hookedsaetransformer.hookedsaetransformer method)": [[14, "transformer_lens.HookedSAETransformer.HookedSAETransformer.run_with_cache_with_saes"]], "run_with_hooks_with_saes() (transformer_lens.hookedsaetransformer.hookedsaetransformer method)": [[14, "transformer_lens.HookedSAETransformer.HookedSAETransformer.run_with_hooks_with_saes"]], "run_with_saes() (transformer_lens.hookedsaetransformer.hookedsaetransformer method)": [[14, "transformer_lens.HookedSAETransformer.HookedSAETransformer.run_with_saes"]], "saes() (transformer_lens.hookedsaetransformer.hookedsaetransformer method)": [[14, "transformer_lens.HookedSAETransformer.HookedSAETransformer.saes"]], "set_deep_attr() (in module transformer_lens.hookedsaetransformer)": [[14, "transformer_lens.HookedSAETransformer.set_deep_attr"]], "transformer_lens.hookedsaetransformer": [[14, "module-transformer_lens.HookedSAETransformer"]], "hookedtransformer (class in transformer_lens.hookedtransformer)": [[15, "transformer_lens.HookedTransformer.HookedTransformer"]], "ov (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.OV"]], "output (class in transformer_lens.hookedtransformer)": [[15, "transformer_lens.HookedTransformer.Output"]], "qk (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.QK"]], "w_e (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_E"]], "w_e_pos (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_E_pos"]], "w_k (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_K"]], "w_o (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_O"]], "w_q (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_Q"]], "w_u (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_U"]], "w_v (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_V"]], "w_gate (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_gate"]], "w_in (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_in"]], "w_out (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_out"]], "w_pos (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_pos"]], "__init__() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.__init__"]], "accumulated_bias() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.accumulated_bias"]], "all_composition_scores() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.all_composition_scores"]], "all_head_labels() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.all_head_labels"]], "b_k (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.b_K"]], "b_o (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.b_O"]], "b_q (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.b_Q"]], "b_u (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.b_U"]], "b_v (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.b_V"]], "b_in (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.b_in"]], "b_out (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.b_out"]], "center_unembed() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.center_unembed"]], "center_writing_weights() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.center_writing_weights"]], "check_hooks_to_add() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.check_hooks_to_add"]], "cpu() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.cpu"]], "cuda() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.cuda"]], "fold_layer_norm() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.fold_layer_norm"]], "fold_value_biases() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.fold_value_biases"]], "forward() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.forward"]], "from_pretrained() (transformer_lens.hookedtransformer.hookedtransformer class method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.from_pretrained"]], "from_pretrained_no_processing() (transformer_lens.hookedtransformer.hookedtransformer class method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.from_pretrained_no_processing"]], "generate() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.generate"]], "get_token_position() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.get_token_position"]], "init_weights() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.init_weights"]], "input_to_embed() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.input_to_embed"]], "ln_final (transformer_lens.hookedtransformer.hookedtransformer attribute)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.ln_final"]], "load_and_process_state_dict() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.load_and_process_state_dict"]], "load_sample_training_dataset() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.load_sample_training_dataset"]], "logits (transformer_lens.hookedtransformer.output attribute)": [[15, "transformer_lens.HookedTransformer.Output.logits"]], "loss (transformer_lens.hookedtransformer.output attribute)": [[15, "transformer_lens.HookedTransformer.Output.loss"]], "loss_fn() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.loss_fn"]], "move_model_modules_to_device() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.move_model_modules_to_device"]], "mps() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.mps"]], "process_weights_() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.process_weights_"]], "refactor_factored_attn_matrices() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.refactor_factored_attn_matrices"]], "run_with_cache() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.run_with_cache"]], "sample_datapoint() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.sample_datapoint"]], "set_tokenizer() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.set_tokenizer"]], "set_use_attn_in() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.set_use_attn_in"]], "set_use_attn_result() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.set_use_attn_result"]], "set_use_hook_mlp_in() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.set_use_hook_mlp_in"]], "set_use_split_qkv_input() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.set_use_split_qkv_input"]], "to() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.to"]], "to_single_str_token() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.to_single_str_token"]], "to_single_token() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.to_single_token"]], "to_str_tokens() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.to_str_tokens"]], "to_string() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.to_string"]], "to_tokens() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.to_tokens"]], "tokens_to_residual_directions() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.tokens_to_residual_directions"]], "transformer_lens.hookedtransformer": [[15, "module-transformer_lens.HookedTransformer"]], "hookedtransformerconfig (class in transformer_lens.hookedtransformerconfig)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig"]], "act_fn (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.act_fn"]], "attention_dir (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attention_dir"]], "attn_only (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_only"]], "attn_types (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_types"]], "checkpoint_index (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_index"]], "checkpoint_label_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_label_type"]], "checkpoint_value (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_value"]], "d_head (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_head"]], "d_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_mlp"]], "d_model (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_model"]], "d_vocab (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_vocab"]], "d_vocab_out (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_vocab_out"]], "default_prepend_bos (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.default_prepend_bos"]], "device (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.device"]], "dtype (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.dtype"]], "eps (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.eps"]], "experts_per_token (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.experts_per_token"]], "final_rms (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.final_rms"]], "from_checkpoint (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.from_checkpoint"]], "from_dict() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig class method)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.from_dict"]], "gated_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.gated_mlp"]], "init_mode (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.init_mode"]], "init_weights (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.init_weights"]], "initializer_range (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.initializer_range"]], "load_in_4bit (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.load_in_4bit"]], "model_name (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.model_name"]], "n_ctx (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_ctx"]], "n_devices (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_devices"]], "n_heads (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_heads"]], "n_key_value_heads (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_key_value_heads"]], "n_layers (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_layers"]], "n_params (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_params"]], "normalization_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.normalization_type"]], "num_experts (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.num_experts"]], "original_architecture (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.original_architecture"]], "parallel_attn_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.parallel_attn_mlp"]], "positional_embedding_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.positional_embedding_type"]], "post_embedding_ln (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.post_embedding_ln"]], "rotary_adjacent_pairs (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_adjacent_pairs"]], "rotary_base (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_base"]], "rotary_dim (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_dim"]], "scale_attn_by_inverse_layer_idx (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.scale_attn_by_inverse_layer_idx"]], "seed (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.seed"]], "set_seed_everywhere() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.set_seed_everywhere"]], "to_dict() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.to_dict"]], "tokenizer_name (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.tokenizer_name"]], "tokenizer_prepends_bos (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.tokenizer_prepends_bos"]], "transformer_lens.hookedtransformerconfig": [[16, "module-transformer_lens.HookedTransformerConfig"]], "trust_remote_code (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.trust_remote_code"]], "use_attn_in (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_in"]], "use_attn_result (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_result"]], "use_attn_scale (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_scale"]], "use_hook_mlp_in (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_hook_mlp_in"]], "use_hook_tokens (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_hook_tokens"]], "use_local_attn (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_local_attn"]], "use_split_qkv_input (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_split_qkv_input"]], "window_size (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.window_size"]], "svdinterpreter (class in transformer_lens.svdinterpreter)": [[17, "transformer_lens.SVDInterpreter.SVDInterpreter"]], "get_singular_vectors() (transformer_lens.svdinterpreter.svdinterpreter method)": [[17, "transformer_lens.SVDInterpreter.SVDInterpreter.get_singular_vectors"]], "transformer_lens.svdinterpreter": [[17, "module-transformer_lens.SVDInterpreter"]], "abstractattention (class in transformer_lens.components)": [[18, "transformer_lens.components.AbstractAttention"]], "attention (class in transformer_lens.components)": [[18, "transformer_lens.components.Attention"]], "bertblock (class in transformer_lens.components)": [[18, "transformer_lens.components.BertBlock"]], "bertembed (class in transformer_lens.components)": [[18, "transformer_lens.components.BertEmbed"]], "bertmlmhead (class in transformer_lens.components)": [[18, "transformer_lens.components.BertMLMHead"]], "embed (class in transformer_lens.components)": [[18, "transformer_lens.components.Embed"]], "gatedmlp (class in transformer_lens.components)": [[18, "transformer_lens.components.GatedMLP"]], "groupedqueryattention (class in transformer_lens.components)": [[18, "transformer_lens.components.GroupedQueryAttention"]], "layernorm (class in transformer_lens.components)": [[18, "transformer_lens.components.LayerNorm"]], "layernormpre (class in transformer_lens.components)": [[18, "transformer_lens.components.LayerNormPre"]], "mlp (class in transformer_lens.components)": [[18, "transformer_lens.components.MLP"]], "moe (class in transformer_lens.components)": [[18, "transformer_lens.components.MoE"]], "ov (transformer_lens.components.abstractattention property)": [[18, "transformer_lens.components.AbstractAttention.OV"]], "posembed (class in transformer_lens.components)": [[18, "transformer_lens.components.PosEmbed"]], "qk (transformer_lens.components.abstractattention property)": [[18, "transformer_lens.components.AbstractAttention.QK"]], "rmsnorm (class in transformer_lens.components)": [[18, "transformer_lens.components.RMSNorm"]], "rmsnormpre (class in transformer_lens.components)": [[18, "transformer_lens.components.RMSNormPre"]], "tokentypeembed (class in transformer_lens.components)": [[18, "transformer_lens.components.TokenTypeEmbed"]], "transformerblock (class in transformer_lens.components)": [[18, "transformer_lens.components.TransformerBlock"]], "unembed (class in transformer_lens.components)": [[18, "transformer_lens.components.Unembed"]], "w_k (transformer_lens.components.groupedqueryattention property)": [[18, "transformer_lens.components.GroupedQueryAttention.W_K"]], "w_v (transformer_lens.components.groupedqueryattention property)": [[18, "transformer_lens.components.GroupedQueryAttention.W_V"]], "__init__() (transformer_lens.components.abstractattention method)": [[18, "transformer_lens.components.AbstractAttention.__init__"]], "__init__() (transformer_lens.components.attention method)": [[18, "transformer_lens.components.Attention.__init__"]], "__init__() (transformer_lens.components.groupedqueryattention method)": [[18, "transformer_lens.components.GroupedQueryAttention.__init__"]], "__init__() (transformer_lens.components.layernorm method)": [[18, "transformer_lens.components.LayerNorm.__init__"]], "__init__() (transformer_lens.components.layernormpre method)": [[18, "transformer_lens.components.LayerNormPre.__init__"]], "__init__() (transformer_lens.components.rmsnorm method)": [[18, "transformer_lens.components.RMSNorm.__init__"]], "__init__() (transformer_lens.components.rmsnormpre method)": [[18, "transformer_lens.components.RMSNormPre.__init__"]], "act_fn (transformer_lens.components.gatedmlp attribute)": [[18, "transformer_lens.components.GatedMLP.act_fn"]], "act_fn (transformer_lens.components.mlp attribute)": [[18, "transformer_lens.components.MLP.act_fn"]], "alibi (transformer_lens.components.abstractattention attribute)": [[18, "transformer_lens.components.AbstractAttention.alibi"]], "apply_causal_mask() (transformer_lens.components.abstractattention method)": [[18, "transformer_lens.components.AbstractAttention.apply_causal_mask"]], "apply_rotary() (transformer_lens.components.abstractattention method)": [[18, "transformer_lens.components.AbstractAttention.apply_rotary"]], "b_k (transformer_lens.components.groupedqueryattention property)": [[18, "transformer_lens.components.GroupedQueryAttention.b_K"]], "b_v (transformer_lens.components.groupedqueryattention property)": [[18, "transformer_lens.components.GroupedQueryAttention.b_V"]], "calculate_attention_scores() (transformer_lens.components.abstractattention method)": [[18, "transformer_lens.components.AbstractAttention.calculate_attention_scores"]], "calculate_attention_scores() (transformer_lens.components.groupedqueryattention method)": [[18, "transformer_lens.components.GroupedQueryAttention.calculate_attention_scores"]], "calculate_qkv_matrices() (transformer_lens.components.abstractattention method)": [[18, "transformer_lens.components.AbstractAttention.calculate_qkv_matrices"]], "calculate_qkv_matrices() (transformer_lens.components.groupedqueryattention method)": [[18, "transformer_lens.components.GroupedQueryAttention.calculate_qkv_matrices"]], "calculate_sin_cos_rotary() (transformer_lens.components.abstractattention method)": [[18, "transformer_lens.components.AbstractAttention.calculate_sin_cos_rotary"]], "calculate_z_scores() (transformer_lens.components.abstractattention method)": [[18, "transformer_lens.components.AbstractAttention.calculate_z_scores"]], "calculate_z_scores() (transformer_lens.components.groupedqueryattention method)": [[18, "transformer_lens.components.GroupedQueryAttention.calculate_z_scores"]], "create_alibi_bias() (transformer_lens.components.abstractattention static method)": [[18, "transformer_lens.components.AbstractAttention.create_alibi_bias"]], "create_alibi_multipliers() (transformer_lens.components.abstractattention static method)": [[18, "transformer_lens.components.AbstractAttention.create_alibi_multipliers"]], "create_alibi_slope() (transformer_lens.components.abstractattention static method)": [[18, "transformer_lens.components.AbstractAttention.create_alibi_slope"]], "forward() (transformer_lens.components.abstractattention method)": [[18, "transformer_lens.components.AbstractAttention.forward"]], "forward() (transformer_lens.components.bertblock method)": [[18, "transformer_lens.components.BertBlock.forward"]], "forward() (transformer_lens.components.bertembed method)": [[18, "transformer_lens.components.BertEmbed.forward"]], "forward() (transformer_lens.components.bertmlmhead method)": [[18, "transformer_lens.components.BertMLMHead.forward"]], "forward() (transformer_lens.components.embed method)": [[18, "transformer_lens.components.Embed.forward"]], "forward() (transformer_lens.components.gatedmlp method)": [[18, "transformer_lens.components.GatedMLP.forward"]], "forward() (transformer_lens.components.layernorm method)": [[18, "transformer_lens.components.LayerNorm.forward"]], "forward() (transformer_lens.components.layernormpre method)": [[18, "transformer_lens.components.LayerNormPre.forward"]], "forward() (transformer_lens.components.mlp method)": [[18, "transformer_lens.components.MLP.forward"]], "forward() (transformer_lens.components.moe method)": [[18, "transformer_lens.components.MoE.forward"]], "forward() (transformer_lens.components.posembed method)": [[18, "transformer_lens.components.PosEmbed.forward"]], "forward() (transformer_lens.components.rmsnorm method)": [[18, "transformer_lens.components.RMSNorm.forward"]], "forward() (transformer_lens.components.rmsnormpre method)": [[18, "transformer_lens.components.RMSNormPre.forward"]], "forward() (transformer_lens.components.tokentypeembed method)": [[18, "transformer_lens.components.TokenTypeEmbed.forward"]], "forward() (transformer_lens.components.transformerblock method)": [[18, "transformer_lens.components.TransformerBlock.forward"]], "forward() (transformer_lens.components.unembed method)": [[18, "transformer_lens.components.Unembed.forward"]], "ln (transformer_lens.components.gatedmlp attribute)": [[18, "transformer_lens.components.GatedMLP.ln"]], "ln (transformer_lens.components.mlp attribute)": [[18, "transformer_lens.components.MLP.ln"]], "ln1 (transformer_lens.components.transformerblock attribute)": [[18, "transformer_lens.components.TransformerBlock.ln1"]], "ln2 (transformer_lens.components.transformerblock attribute)": [[18, "transformer_lens.components.TransformerBlock.ln2"]], "mlp (transformer_lens.components.transformerblock attribute)": [[18, "transformer_lens.components.TransformerBlock.mlp"]], "rotate_every_two() (transformer_lens.components.abstractattention method)": [[18, "transformer_lens.components.AbstractAttention.rotate_every_two"]], "transformer_lens.components": [[18, "module-transformer_lens.components"]], "ioidataset (class in transformer_lens.evals)": [[19, "transformer_lens.evals.IOIDataset"]], "evaluate() (in module transformer_lens.evals)": [[19, "transformer_lens.evals.evaluate"]], "evaluate_on_dataset() (in module transformer_lens.evals)": [[19, "transformer_lens.evals.evaluate_on_dataset"]], "get_default_names() (transformer_lens.evals.ioidataset static method)": [[19, "transformer_lens.evals.IOIDataset.get_default_names"]], "get_default_nouns() (transformer_lens.evals.ioidataset static method)": [[19, "transformer_lens.evals.IOIDataset.get_default_nouns"]], "get_default_templates() (transformer_lens.evals.ioidataset static method)": [[19, "transformer_lens.evals.IOIDataset.get_default_templates"]], "get_sample() (transformer_lens.evals.ioidataset method)": [[19, "transformer_lens.evals.IOIDataset.get_sample"]], "induction_loss() (in module transformer_lens.evals)": [[19, "transformer_lens.evals.induction_loss"]], "ioi_eval() (in module transformer_lens.evals)": [[19, "transformer_lens.evals.ioi_eval"]], "make_code_data_loader() (in module transformer_lens.evals)": [[19, "transformer_lens.evals.make_code_data_loader"]], "make_owt_data_loader() (in module transformer_lens.evals)": [[19, "transformer_lens.evals.make_owt_data_loader"]], "make_pile_data_loader() (in module transformer_lens.evals)": [[19, "transformer_lens.evals.make_pile_data_loader"]], "make_wiki_data_loader() (in module transformer_lens.evals)": [[19, "transformer_lens.evals.make_wiki_data_loader"]], "sanity_check() (in module transformer_lens.evals)": [[19, "transformer_lens.evals.sanity_check"]], "transformer_lens.evals": [[19, "module-transformer_lens.evals"]], "compute_head_attention_similarity_score() (in module transformer_lens.head_detector)": [[20, "transformer_lens.head_detector.compute_head_attention_similarity_score"]], "detect_head() (in module transformer_lens.head_detector)": [[20, "transformer_lens.head_detector.detect_head"]], "get_duplicate_token_head_detection_pattern() (in module transformer_lens.head_detector)": [[20, "transformer_lens.head_detector.get_duplicate_token_head_detection_pattern"]], "get_induction_head_detection_pattern() (in module transformer_lens.head_detector)": [[20, "transformer_lens.head_detector.get_induction_head_detection_pattern"]], "get_previous_token_head_detection_pattern() (in module transformer_lens.head_detector)": [[20, "transformer_lens.head_detector.get_previous_token_head_detection_pattern"]], "get_supported_heads() (in module transformer_lens.head_detector)": [[20, "transformer_lens.head_detector.get_supported_heads"]], "transformer_lens.head_detector": [[20, "module-transformer_lens.head_detector"]], "hookpoint (class in transformer_lens.hook_points)": [[21, "transformer_lens.hook_points.HookPoint"]], "hookedrootmodule (class in transformer_lens.hook_points)": [[21, "transformer_lens.hook_points.HookedRootModule"]], "lenshandle (class in transformer_lens.hook_points)": [[21, "transformer_lens.hook_points.LensHandle"]], "add_caching_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[21, "transformer_lens.hook_points.HookedRootModule.add_caching_hooks"]], "add_hook() (transformer_lens.hook_points.hookpoint method)": [[21, "transformer_lens.hook_points.HookPoint.add_hook"]], "add_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[21, "transformer_lens.hook_points.HookedRootModule.add_hook"]], "add_perma_hook() (transformer_lens.hook_points.hookpoint method)": [[21, "transformer_lens.hook_points.HookPoint.add_perma_hook"]], "add_perma_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[21, "transformer_lens.hook_points.HookedRootModule.add_perma_hook"]], "cache_all() (transformer_lens.hook_points.hookedrootmodule method)": [[21, "transformer_lens.hook_points.HookedRootModule.cache_all"]], "cache_some() (transformer_lens.hook_points.hookedrootmodule method)": [[21, "transformer_lens.hook_points.HookedRootModule.cache_some"]], "check_and_add_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[21, "transformer_lens.hook_points.HookedRootModule.check_and_add_hook"]], "check_hooks_to_add() (transformer_lens.hook_points.hookedrootmodule method)": [[21, "transformer_lens.hook_points.HookedRootModule.check_hooks_to_add"]], "clear_context() (transformer_lens.hook_points.hookpoint method)": [[21, "transformer_lens.hook_points.HookPoint.clear_context"]], "clear_contexts() (transformer_lens.hook_points.hookedrootmodule method)": [[21, "transformer_lens.hook_points.HookedRootModule.clear_contexts"]], "context_level (transformer_lens.hook_points.lenshandle attribute)": [[21, "transformer_lens.hook_points.LensHandle.context_level"]], "forward() (transformer_lens.hook_points.hookpoint method)": [[21, "transformer_lens.hook_points.HookPoint.forward"]], "get_caching_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[21, "transformer_lens.hook_points.HookedRootModule.get_caching_hooks"]], "hook (transformer_lens.hook_points.lenshandle attribute)": [[21, "transformer_lens.hook_points.LensHandle.hook"]], "hook_points() (transformer_lens.hook_points.hookedrootmodule method)": [[21, "transformer_lens.hook_points.HookedRootModule.hook_points"]], "hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[21, "transformer_lens.hook_points.HookedRootModule.hooks"]], "is_permanent (transformer_lens.hook_points.lenshandle attribute)": [[21, "transformer_lens.hook_points.LensHandle.is_permanent"]], "layer() (transformer_lens.hook_points.hookpoint method)": [[21, "transformer_lens.hook_points.HookPoint.layer"]], "remove_all_hook_fns() (transformer_lens.hook_points.hookedrootmodule method)": [[21, "transformer_lens.hook_points.HookedRootModule.remove_all_hook_fns"]], "remove_hooks() (transformer_lens.hook_points.hookpoint method)": [[21, "transformer_lens.hook_points.HookPoint.remove_hooks"]], "reset_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[21, "transformer_lens.hook_points.HookedRootModule.reset_hooks"]], "run_with_cache() (transformer_lens.hook_points.hookedrootmodule method)": [[21, "transformer_lens.hook_points.HookedRootModule.run_with_cache"]], "run_with_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[21, "transformer_lens.hook_points.HookedRootModule.run_with_hooks"]], "setup() (transformer_lens.hook_points.hookedrootmodule method)": [[21, "transformer_lens.hook_points.HookedRootModule.setup"]], "transformer_lens.hook_points": [[21, "module-transformer_lens.hook_points"]], "config (class in transformer_lens.loading_from_pretrained)": [[22, "transformer_lens.loading_from_pretrained.Config"]], "model_aliases (in module transformer_lens.loading_from_pretrained)": [[22, "transformer_lens.loading_from_pretrained.MODEL_ALIASES"]], "non_hf_hosted_model_names (in module transformer_lens.loading_from_pretrained)": [[22, "transformer_lens.loading_from_pretrained.NON_HF_HOSTED_MODEL_NAMES"]], "official_model_names (in module transformer_lens.loading_from_pretrained)": [[22, "transformer_lens.loading_from_pretrained.OFFICIAL_MODEL_NAMES"]], "convert_bloom_weights() (in module transformer_lens.loading_from_pretrained)": [[22, "transformer_lens.loading_from_pretrained.convert_bloom_weights"]], "convert_coder_weights() (in module transformer_lens.loading_from_pretrained)": [[22, "transformer_lens.loading_from_pretrained.convert_coder_weights"]], "convert_mistral_weights() (in module transformer_lens.loading_from_pretrained)": [[22, "transformer_lens.loading_from_pretrained.convert_mistral_weights"]], "convert_mixtral_weights() (in module transformer_lens.loading_from_pretrained)": [[22, "transformer_lens.loading_from_pretrained.convert_mixtral_weights"]], "convert_phi_weights() (in module transformer_lens.loading_from_pretrained)": [[22, "transformer_lens.loading_from_pretrained.convert_phi_weights"]], "convert_qwen2_weights() (in module transformer_lens.loading_from_pretrained)": [[22, "transformer_lens.loading_from_pretrained.convert_qwen2_weights"]], "convert_qwen_weights() (in module transformer_lens.loading_from_pretrained)": [[22, "transformer_lens.loading_from_pretrained.convert_qwen_weights"]], "d_head (transformer_lens.loading_from_pretrained.config attribute)": [[22, "transformer_lens.loading_from_pretrained.Config.d_head"]], "d_mlp (transformer_lens.loading_from_pretrained.config attribute)": [[22, "transformer_lens.loading_from_pretrained.Config.d_mlp"]], "d_model (transformer_lens.loading_from_pretrained.config attribute)": [[22, "transformer_lens.loading_from_pretrained.Config.d_model"]], "d_vocab (transformer_lens.loading_from_pretrained.config attribute)": [[22, "transformer_lens.loading_from_pretrained.Config.d_vocab"]], "debug (transformer_lens.loading_from_pretrained.config attribute)": [[22, "transformer_lens.loading_from_pretrained.Config.debug"]], "get_checkpoint_labels() (in module transformer_lens.loading_from_pretrained)": [[22, "transformer_lens.loading_from_pretrained.get_checkpoint_labels"]], "get_num_params_of_pretrained() (in module transformer_lens.loading_from_pretrained)": [[22, "transformer_lens.loading_from_pretrained.get_num_params_of_pretrained"]], "get_pretrained_model_config() (in module transformer_lens.loading_from_pretrained)": [[22, "transformer_lens.loading_from_pretrained.get_pretrained_model_config"]], "init_range (transformer_lens.loading_from_pretrained.config attribute)": [[22, "transformer_lens.loading_from_pretrained.Config.init_range"]], "layer_norm_eps (transformer_lens.loading_from_pretrained.config attribute)": [[22, "transformer_lens.loading_from_pretrained.Config.layer_norm_eps"]], "n_ctx (transformer_lens.loading_from_pretrained.config attribute)": [[22, "transformer_lens.loading_from_pretrained.Config.n_ctx"]], "n_heads (transformer_lens.loading_from_pretrained.config attribute)": [[22, "transformer_lens.loading_from_pretrained.Config.n_heads"]], "n_layers (transformer_lens.loading_from_pretrained.config attribute)": [[22, "transformer_lens.loading_from_pretrained.Config.n_layers"]], "transformer_lens.loading_from_pretrained": [[22, "module-transformer_lens.loading_from_pretrained"]], "hookedtransformerkeyvaluecache (class in transformer_lens.past_key_value_caching)": [[23, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache"]], "hookedtransformerkeyvaluecacheentry (class in transformer_lens.past_key_value_caching)": [[23, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry"]], "append() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry method)": [[23, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.append"]], "append_attention_mask() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[23, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.append_attention_mask"]], "entries (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[23, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.entries"]], "freeze() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[23, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.freeze"]], "frozen (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[23, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.frozen"]], "frozen (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[23, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.frozen"]], "init_cache() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache class method)": [[23, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.init_cache"]], "init_cache_entry() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry class method)": [[23, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.init_cache_entry"]], "past_keys (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[23, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.past_keys"]], "past_values (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[23, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.past_values"]], "previous_attention_mask (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[23, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.previous_attention_mask"]], "transformer_lens.past_key_value_caching": [[23, "module-transformer_lens.past_key_value_caching"]], "unfreeze() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[23, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.unfreeze"]], "generic_activation_patch() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.generic_activation_patch"]], "get_act_patch_attn_head_all_pos_every() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_attn_head_all_pos_every"]], "get_act_patch_attn_head_by_pos_every() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_attn_head_by_pos_every"]], "get_act_patch_attn_head_k_all_pos() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_attn_head_k_all_pos"]], "get_act_patch_attn_head_k_by_pos() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_attn_head_k_by_pos"]], "get_act_patch_attn_head_out_all_pos() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_attn_head_out_all_pos"]], "get_act_patch_attn_head_out_by_pos() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_attn_head_out_by_pos"]], "get_act_patch_attn_head_pattern_all_pos() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_attn_head_pattern_all_pos"]], "get_act_patch_attn_head_pattern_by_pos() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_attn_head_pattern_by_pos"]], "get_act_patch_attn_head_pattern_dest_src_pos() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_attn_head_pattern_dest_src_pos"]], "get_act_patch_attn_head_q_all_pos() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_attn_head_q_all_pos"]], "get_act_patch_attn_head_q_by_pos() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_attn_head_q_by_pos"]], "get_act_patch_attn_head_v_all_pos() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_attn_head_v_all_pos"]], "get_act_patch_attn_head_v_by_pos() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_attn_head_v_by_pos"]], "get_act_patch_attn_out() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_attn_out"]], "get_act_patch_block_every() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_block_every"]], "get_act_patch_mlp_out() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_mlp_out"]], "get_act_patch_resid_mid() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_resid_mid"]], "get_act_patch_resid_pre() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.get_act_patch_resid_pre"]], "layer_head_dest_src_pos_pattern_patch_setter() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.layer_head_dest_src_pos_pattern_patch_setter"]], "layer_head_pattern_patch_setter() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.layer_head_pattern_patch_setter"]], "layer_head_pos_pattern_patch_setter() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.layer_head_pos_pattern_patch_setter"]], "layer_head_vector_patch_setter() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.layer_head_vector_patch_setter"]], "layer_pos_head_vector_patch_setter() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.layer_pos_head_vector_patch_setter"]], "layer_pos_patch_setter() (in module transformer_lens.patching)": [[24, "transformer_lens.patching.layer_pos_patch_setter"]], "transformer_lens.patching": [[24, "module-transformer_lens.patching"]], "hookedtransformertrainconfig (class in transformer_lens.train)": [[25, "transformer_lens.train.HookedTransformerTrainConfig"]], "batch_size (transformer_lens.train.hookedtransformertrainconfig attribute)": [[25, "transformer_lens.train.HookedTransformerTrainConfig.batch_size"]], "device (transformer_lens.train.hookedtransformertrainconfig attribute)": [[25, "transformer_lens.train.HookedTransformerTrainConfig.device"]], "lr (transformer_lens.train.hookedtransformertrainconfig attribute)": [[25, "transformer_lens.train.HookedTransformerTrainConfig.lr"]], "max_grad_norm (transformer_lens.train.hookedtransformertrainconfig attribute)": [[25, "transformer_lens.train.HookedTransformerTrainConfig.max_grad_norm"]], "max_steps (transformer_lens.train.hookedtransformertrainconfig attribute)": [[25, "transformer_lens.train.HookedTransformerTrainConfig.max_steps"]], "momentum (transformer_lens.train.hookedtransformertrainconfig attribute)": [[25, "transformer_lens.train.HookedTransformerTrainConfig.momentum"]], "num_epochs (transformer_lens.train.hookedtransformertrainconfig attribute)": [[25, "transformer_lens.train.HookedTransformerTrainConfig.num_epochs"]], "optimizer_name (transformer_lens.train.hookedtransformertrainconfig attribute)": [[25, "transformer_lens.train.HookedTransformerTrainConfig.optimizer_name"]], "print_every (transformer_lens.train.hookedtransformertrainconfig attribute)": [[25, "transformer_lens.train.HookedTransformerTrainConfig.print_every"]], "save_dir (transformer_lens.train.hookedtransformertrainconfig attribute)": [[25, "transformer_lens.train.HookedTransformerTrainConfig.save_dir"]], "save_every (transformer_lens.train.hookedtransformertrainconfig attribute)": [[25, "transformer_lens.train.HookedTransformerTrainConfig.save_every"]], "seed (transformer_lens.train.hookedtransformertrainconfig attribute)": [[25, "transformer_lens.train.HookedTransformerTrainConfig.seed"]], "train() (in module transformer_lens.train)": [[25, "transformer_lens.train.train"]], "transformer_lens.train": [[25, "module-transformer_lens.train"]], "wandb (transformer_lens.train.hookedtransformertrainconfig attribute)": [[25, "transformer_lens.train.HookedTransformerTrainConfig.wandb"]], "wandb_project_name (transformer_lens.train.hookedtransformertrainconfig attribute)": [[25, "transformer_lens.train.HookedTransformerTrainConfig.wandb_project_name"]], "warmup_steps (transformer_lens.train.hookedtransformertrainconfig attribute)": [[25, "transformer_lens.train.HookedTransformerTrainConfig.warmup_steps"]], "weight_decay (transformer_lens.train.hookedtransformertrainconfig attribute)": [[25, "transformer_lens.train.HookedTransformerTrainConfig.weight_decay"]], "get_device_for_block_index() (in module transformer_lens.utilities.devices)": [[27, "transformer_lens.utilities.devices.get_device_for_block_index"]], "move_to_and_update_config() (in module transformer_lens.utilities.devices)": [[27, "transformer_lens.utilities.devices.move_to_and_update_config"]], "transformer_lens.utilities.devices": [[27, "module-transformer_lens.utilities.devices"]], "locallyoverridendefaults (class in transformer_lens.utils)": [[28, "transformer_lens.utils.LocallyOverridenDefaults"]], "slice (class in transformer_lens.utils)": [[28, "transformer_lens.utils.Slice"]], "sliceinput (in module transformer_lens.utils)": [[28, "transformer_lens.utils.SliceInput"]], "__init__() (transformer_lens.utils.locallyoverridendefaults method)": [[28, "transformer_lens.utils.LocallyOverridenDefaults.__init__"]], "__init__() (transformer_lens.utils.slice method)": [[28, "transformer_lens.utils.Slice.__init__"]], "apply() (transformer_lens.utils.slice method)": [[28, "transformer_lens.utils.Slice.apply"]], "calc_fan_in_and_fan_out() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.calc_fan_in_and_fan_out"]], "composition_scores() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.composition_scores"]], "download_file_from_hf() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.download_file_from_hf"]], "gelu_fast() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.gelu_fast"]], "gelu_new() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.gelu_new"]], "get_act_name() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.get_act_name"]], "get_attention_mask() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.get_attention_mask"]], "get_corner() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.get_corner"]], "get_cumsum_along_dim() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.get_cumsum_along_dim"]], "get_dataset() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.get_dataset"]], "get_device() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.get_device"]], "get_input_with_manually_prepended_bos() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.get_input_with_manually_prepended_bos"]], "get_nested_attr() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.get_nested_attr"]], "get_offset_position_ids() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.get_offset_position_ids"]], "get_tokenizer_with_bos() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.get_tokenizer_with_bos"]], "get_tokens_with_bos_removed() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.get_tokens_with_bos_removed"]], "indices() (transformer_lens.utils.slice method)": [[28, "transformer_lens.utils.Slice.indices"]], "init_kaiming_normal_() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.init_kaiming_normal_"]], "init_kaiming_uniform_() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.init_kaiming_uniform_"]], "init_xavier_normal_() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.init_xavier_normal_"]], "init_xavier_uniform_() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.init_xavier_uniform_"]], "is_lower_triangular() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.is_lower_triangular"]], "is_square() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.is_square"]], "keep_single_column() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.keep_single_column"]], "lm_accuracy() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.lm_accuracy"]], "lm_cross_entropy_loss() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.lm_cross_entropy_loss"]], "override_or_use_default_value() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.override_or_use_default_value"]], "print_gpu_mem() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.print_gpu_mem"]], "remove_batch_dim() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.remove_batch_dim"]], "repeat_along_head_dimension() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.repeat_along_head_dimension"]], "sample_logits() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.sample_logits"]], "set_nested_attr() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.set_nested_attr"]], "slice (transformer_lens.utils.slice attribute)": [[28, "transformer_lens.utils.Slice.slice"]], "solu() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.solu"]], "test_prompt() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.test_prompt"]], "to_numpy() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.to_numpy"]], "tokenize_and_concatenate() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.tokenize_and_concatenate"]], "transformer_lens.utils": [[28, "module-transformer_lens.utils"]], "transpose() (in module transformer_lens.utils)": [[28, "transformer_lens.utils.transpose"]], "unwrap() (transformer_lens.utils.slice class method)": [[28, "transformer_lens.utils.Slice.unwrap"]]}})