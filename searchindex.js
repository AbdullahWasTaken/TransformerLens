Search.setIndex({"docnames": ["content/citation", "content/contributing", "content/gallery", "content/getting_started", "content/getting_started_mech_interp", "content/special_cases", "content/tutorials", "generated/code/modules", "generated/code/transformer_lens", "generated/code/transformer_lens.ActivationCache", "generated/code/transformer_lens.FactoredMatrix", "generated/code/transformer_lens.HookedEncoder", "generated/code/transformer_lens.HookedTransformer", "generated/code/transformer_lens.HookedTransformerConfig", "generated/code/transformer_lens.SVDInterpreter", "generated/code/transformer_lens.components", "generated/code/transformer_lens.evals", "generated/code/transformer_lens.head_detector", "generated/code/transformer_lens.hook_points", "generated/code/transformer_lens.loading_from_pretrained", "generated/code/transformer_lens.past_key_value_caching", "generated/code/transformer_lens.patching", "generated/code/transformer_lens.train", "generated/code/transformer_lens.utilities", "generated/code/transformer_lens.utilities.devices", "generated/code/transformer_lens.utils", "generated/demos/Exploratory_Analysis_Demo", "generated/demos/Main_Demo", "generated/model_properties_table", "index"], "filenames": ["content/citation.md", "content/contributing.md", "content/gallery.md", "content/getting_started.md", "content/getting_started_mech_interp.md", "content/special_cases.md", "content/tutorials.md", "generated/code/modules.rst", "generated/code/transformer_lens.rst", "generated/code/transformer_lens.ActivationCache.rst", "generated/code/transformer_lens.FactoredMatrix.rst", "generated/code/transformer_lens.HookedEncoder.rst", "generated/code/transformer_lens.HookedTransformer.rst", "generated/code/transformer_lens.HookedTransformerConfig.rst", "generated/code/transformer_lens.SVDInterpreter.rst", "generated/code/transformer_lens.components.rst", "generated/code/transformer_lens.evals.rst", "generated/code/transformer_lens.head_detector.rst", "generated/code/transformer_lens.hook_points.rst", "generated/code/transformer_lens.loading_from_pretrained.rst", "generated/code/transformer_lens.past_key_value_caching.rst", "generated/code/transformer_lens.patching.rst", "generated/code/transformer_lens.train.rst", "generated/code/transformer_lens.utilities.rst", "generated/code/transformer_lens.utilities.devices.rst", "generated/code/transformer_lens.utils.rst", "generated/demos/Exploratory_Analysis_Demo.ipynb", "generated/demos/Main_Demo.ipynb", "generated/model_properties_table.md", "index.md"], "titles": ["Citation", "Contributing", "Gallery", "Getting Started", "Getting Started in Mechanistic Interpretability", "Special Cases", "Tutorials", "Transformer Lens API", "transformer_lens", "transformer_lens.ActivationCache", "transformer_lens.FactoredMatrix", "transformer_lens.HookedEncoder", "transformer_lens.HookedTransformer", "transformer_lens.HookedTransformerConfig", "transformer_lens.SVDInterpreter", "transformer_lens.components", "transformer_lens.evals", "transformer_lens.head_detector", "transformer_lens.hook_points", "transformer_lens.loading_from_pretrained", "transformer_lens.past_key_value_caching", "transformer_lens.patching", "transformer_lens.train", "transformer_lens.utilities", "transformer_lens.utilities.devices", "transformer_lens.utils", "Exploratory Analysis Demo", "Transformer Lens Main Demo Notebook", "Model Properties Table", "TransformerLens"], "terms": {"pleas": [0, 1, 3, 4, 27], "cite": 0, "thi": [0, 1, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 29], "librari": [0, 2, 3, 4, 6, 9, 16, 25, 26], "misc": 0, "nanda2022transformerlen": 0, "titl": [0, 1, 26, 27], "transformerlen": [0, 2, 3, 4, 6, 9, 12, 15, 19, 25, 26, 27], "author": [0, 26], "neel": [0, 2, 4, 6, 12, 14, 27], "nanda": [0, 2, 4, 12, 27], "joseph": 0, "bloom": [0, 15, 19, 28], "year": 0, "2022": [0, 25], "howpublish": 0, "url": 0, "http": [0, 1, 3, 6, 9, 12, 13, 15, 16, 17, 21, 25, 26, 27], "github": [0, 1, 3, 6, 12], "com": [0, 3, 6, 9, 12, 15, 26, 27], "neelnanda": [0, 3, 6, 12, 19], "io": [0, 3, 6, 16, 17, 26, 27], "For": [1, 9, 11, 12, 15, 17, 25, 26], "one": [1, 3, 4, 9, 11, 12, 13, 15, 17, 18, 19, 20, 21, 25, 26, 27, 29], "click": [1, 27], "your": [1, 6, 12, 13, 17, 18, 26, 27], "develop": [1, 6, 26, 27], "environ": 1, "project": [1, 6, 9, 15, 22, 26], "includ": [1, 4, 6, 9, 11, 12, 13, 16, 17, 18, 26], "It": [1, 3, 6, 9, 11, 12, 13, 15, 16, 18, 21, 25, 26, 27, 29], "can": [1, 2, 3, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 29], "us": [1, 2, 3, 5, 6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29], "local": [1, 12, 13, 15, 19, 25, 27], "v": [1, 9, 11, 12, 13, 15, 21, 26, 27], "code": [1, 4, 9, 12, 13, 15, 16, 17, 18, 19, 25, 26, 27], "codespac": 1, "poetri": 1, "packag": 1, "manag": [1, 9, 12, 18, 25], "instal": [1, 26, 27], "follow": [1, 9, 12, 25, 27, 29], "also": [1, 6, 9, 11, 12, 13, 14, 17, 18, 19, 24, 25, 26, 27], "virtual": 1, "config": [1, 12, 13, 15, 19, 21, 22], "virtualenv": 1, "true": [1, 9, 11, 12, 13, 16, 17, 18, 19, 21, 24, 25, 26, 27], "dev": 1, "doc": [1, 7, 9, 12, 27], "jupyt": 1, "If": [1, 3, 7, 9, 11, 12, 13, 15, 17, 18, 19, 21, 24, 25, 26, 27], "ad": [1, 6, 12, 13, 15, 18, 26, 27], "featur": [1, 3, 6, 11, 14, 15, 21, 25, 26, 29], "add": [1, 12, 13, 15, 18, 20, 25, 26, 27, 29], "unit": 1, "you": [1, 3, 4, 6, 9, 11, 12, 13, 14, 16, 17, 18, 19, 25, 26, 27, 29], "need": [1, 3, 9, 12, 13, 15, 18, 25, 26, 27, 29], "model": [1, 2, 3, 5, 6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 26], "ones": [1, 11, 12, 17, 26], "ar": [1, 3, 4, 5, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 25, 27, 29], "cach": [1, 9, 12, 13, 15, 17, 18, 20, 21, 25, 26, 29], "action": [1, 2, 26], "so": [1, 6, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25, 26, 27], "quickli": [1, 6], "cd": [1, 26, 27], "These": [1, 26, 27], "gpt2": [1, 12, 13, 14, 15, 16, 19, 26, 27, 28], "attn": [1, 9, 11, 12, 13, 15, 19, 21, 25, 26, 27, 28], "onli": [1, 2, 9, 10, 11, 12, 13, 15, 17, 18, 19, 25, 26, 27, 28], "1l": [1, 19, 26, 27, 28], "2l": [1, 12, 19, 27, 28], "3l": [1, 19, 27, 28], "4l": [1, 19, 27, 28], "tini": [1, 9, 12, 19, 25, 26, 27, 28], "stori": [1, 9, 12, 19, 21, 25, 26, 28], "1m": [1, 9, 12, 19, 25, 28], "note": [1, 3, 9, 10, 11, 12, 13, 15, 16, 18, 19, 25, 26, 27], "i": [1, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 29], "quit": 1, "slow": [1, 27], "we": [1, 2, 7, 9, 12, 13, 17, 20, 21, 25, 26, 27, 29], "have": [1, 3, 9, 11, 12, 15, 17, 21, 25, 26, 27, 29], "cpu": [1, 9, 11, 12, 13, 15, 19, 26, 27], "smaller": [1, 27], "like": [1, 3, 4, 6, 11, 12, 15, 16, 17, 21, 25, 26, 27, 29], "prefer": 1, "possibl": [1, 11, 12, 17, 21, 25, 26, 27, 29], "via": [1, 2, 4, 11, 12, 21, 26], "make": [1, 6, 10, 11, 12, 17, 18, 26, 27, 29], "accept": [1, 11, 12, 18, 26], "notebook": [1, 3, 6, 26, 29], "all": [1, 4, 9, 11, 12, 15, 16, 17, 18, 21, 25, 26], "suit": 1, "mention": [1, 27], "pycln": 1, "isort": 1, "black": [1, 27], "pull": 1, "request": 1, "check": [1, 3, 6, 12, 14, 15, 16, 17, 18, 25, 26, 27], "file": [1, 25], "line": [1, 26, 27], "length": [1, 9, 11, 12, 13, 15, 25, 26, 27], "set": [1, 2, 9, 11, 12, 13, 15, 16, 17, 18, 21, 22, 25, 26, 27], "100": [1, 16, 26, 27], "pyproject": 1, "toml": 1, "instead": [1, 5, 9, 12, 13, 15, 18, 26, 27], "default": [1, 5, 9, 12, 13, 14, 15, 16, 17, 18, 19, 21, 25, 26, 27], "88": [1, 27], "sure": [1, 12, 25, 26, 27], "thorough": 1, "ani": [1, 9, 11, 12, 13, 15, 18, 25, 26, 27, 29], "should": [1, 6, 9, 11, 12, 15, 17, 18, 22, 25, 26, 27], "do": [1, 3, 4, 6, 9, 11, 12, 15, 16, 18, 21, 25, 26, 27, 29], "directli": [1, 11, 13, 25, 26, 27], "automat": [1, 6, 12, 13, 25, 26, 27], "gener": [1, 6, 12, 15, 16, 20, 21, 25, 26], "api": [1, 18, 26], "when": [1, 3, 6, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 25, 26, 27], "merg": [1, 12], "main": [1, 3, 5, 6, 9, 18, 26], "thei": [1, 4, 12, 13, 15, 16, 21, 25, 26, 27, 29], "pytest": 1, "doctest": 1, "want": [1, 6, 9, 12, 14, 16, 17, 18, 20, 25, 26, 27], "view": [1, 2], "chang": [1, 2, 3, 12, 13, 18, 19, 21, 25, 26, 27], "hot": [1, 26, 27], "reload": [1, 26, 27], "give": [1, 9, 12, 13, 16, 19, 21, 25, 26, 27], "real": [1, 6, 25, 26, 27, 29], "time": [1, 6, 7, 9, 12, 17, 18, 25, 26, 27], "edit": [1, 6, 12, 21, 26, 27, 29], "googl": [1, 6, 19, 26, 27], "python": [1, 2, 13, 16, 19, 25, 27, 28], "write": [1, 2, 3, 12, 25, 26, 27, 29], "some": [1, 3, 9, 12, 14, 15, 16, 18, 21, 25, 26], "from": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 25, 26, 27, 29], "restructuredtext": 1, "rest": [1, 9, 12, 13, 16, 19, 25, 27], "In": [1, 2, 5, 9, 11, 12, 15, 16, 18, 26, 27], "case": [1, 2, 9, 12, 13, 16, 17, 18, 19, 21, 25, 26, 28], "A": [1, 2, 4, 9, 10, 11, 12, 15, 16, 18, 20, 21, 25, 26, 27], "descript": 1, "what": [1, 3, 6, 9, 12, 17, 21, 27, 29], "doe": [1, 9, 11, 12, 13, 17, 18, 21, 25, 26, 27], "much": [1, 9, 12, 16, 17, 21, 25, 26, 27], "detail": [1, 9, 12, 13, 15, 19, 21, 25, 26, 27], "necessari": [1, 27], "fulli": [1, 21, 26], "understand": [1, 9, 12, 17, 27], "warn": [1, 9, 12, 17, 18, 25], "user": [1, 2, 13, 25, 27], "e": [1, 9, 11, 12, 15, 17, 18, 19, 25, 26, 27, 28], "g": [1, 9, 11, 12, 15, 17, 18, 25, 27], "common": [1, 6, 9, 12, 15, 25, 26, 27], "pitfal": 1, "exampl": [1, 2, 9, 11, 12, 14, 15, 16, 18, 25, 26], "here": [1, 2, 12, 13, 15, 16, 17, 25, 26, 27], "print": [1, 9, 16, 22, 25, 26, 27], "1": [1, 4, 9, 11, 12, 13, 15, 17, 18, 19, 20, 25, 26, 27, 28], "2": [1, 3, 4, 9, 11, 12, 13, 15, 16, 17, 19, 25, 26, 27, 28, 29], "3": [1, 5, 9, 10, 11, 12, 15, 16, 21, 25, 26, 27, 28, 29], "arg": [1, 15, 18], "param_without_type_signatur": 1, "each": [1, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 25, 26, 27], "indent": 1, "onc": [1, 12, 25, 26, 27], "more": [1, 6, 9, 10, 12, 13, 15, 17, 21, 25, 26, 27, 29], "param_2": 1, "anoth": [1, 26, 27], "paramet": [1, 6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 25, 26], "return": [1, 9, 10, 11, 12, 15, 16, 17, 18, 19, 21, 22, 24, 25, 26, 27], "without": [1, 9, 12, 15, 25, 26, 27], "type": [1, 5, 6, 9, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 24, 25, 26, 27], "signatur": [1, 11, 12, 27], "rais": [1, 12, 17, 19, 25, 27], "inform": [1, 12, 13, 15, 18, 19, 26, 27], "about": [1, 6, 9, 12, 16, 18, 21, 25, 26, 27, 29], "error": [1, 9, 12, 17, 19, 27], "mai": [1, 9, 11, 12, 13, 15, 25, 26, 27], "part": [1, 9, 12, 15, 21, 26, 27, 29], "codebas": [1, 27], "cross": [1, 9, 12, 25, 26, 27], "referenc": 1, "omit": [1, 17, 27], "full": [1, 4, 9, 11, 12, 13, 15, 25, 27], "path": [1, 4, 25], "same": [1, 3, 9, 10, 12, 13, 15, 17, 18, 20, 21, 25, 26, 27], "mod": 1, "transformer_len": [1, 3, 7, 26, 27], "modul": [1, 7, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 25, 27], "const": 1, "loading_from_pretrain": [1, 7, 8, 12, 27], "official_model_nam": [1, 12, 19], "hookedtransform": [1, 3, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 17, 19, 21, 22, 24, 25, 26, 27], "meth": [1, 9], "from_pretrain": [1, 3, 5, 9, 11, 12, 14, 16, 19, 25, 26, 27], "attr": 1, "cfg": [1, 11, 12, 14, 15, 16, 19, 20, 24, 25, 26, 27], "latex": 1, "re": [1, 3, 4, 6, 9, 12, 13, 17, 26, 27], "place": [1, 6, 11, 12, 25, 26, 27], "string": [1, 11, 12, 13, 16, 17, 18, 19, 25, 26, 27], "backward": [1, 18, 26, 27], "slash": 1, "must": [1, 9, 11, 12, 13, 15, 17, 18, 25, 26, 27], "repeat": [1, 12, 16, 20, 25, 26, 27], "inlin": 1, "displai": [1, 26, 27], "mode": [1, 9, 12, 13, 15, 25, 26, 27], "b": [1, 10, 11, 12, 15, 16, 19, 21, 25, 27, 28], "2ab": 1, "nowrap": 1, "begin": [1, 3, 12, 16, 17, 25, 26, 27], "eqnarrai": 1, "y": [1, 9, 12, 17, 26, 27], "ax": [1, 12, 21, 27], "bx": 1, "c": [1, 19, 25, 27, 28], "f": [1, 26, 27], "x": [1, 9, 12, 15, 17, 18, 19, 25, 26, 27], "2xy": 1, "end": [1, 6, 12, 18, 21, 25, 26, 27], "ital": 1, "text": [1, 6, 9, 12, 13, 15, 16, 18, 19, 20, 25, 26], "bold": 1, "list": [1, 3, 4, 9, 11, 12, 13, 16, 17, 18, 20, 21, 25, 26, 27], "item": [1, 9, 25, 26, 27], "number": [1, 9, 12, 13, 14, 15, 16, 19, 21, 22, 24, 25, 26, 27], "quot": 1, "level": [1, 18, 26, 27, 29], "extern": [1, 26], "link": [1, 12, 16], "domain": 1, "invalid": 1, "research": [2, 3, 4, 6, 26, 27, 29], "done": [2, 4, 5, 9, 12, 13, 15, 18, 26, 27], "involv": [2, 26, 27], "progress": [2, 12, 27], "measur": [2, 16, 17, 21, 25, 26], "grokk": [2, 6], "mechanist": [2, 3, 6, 21, 26, 27], "interpret": [2, 3, 6, 9, 12, 14, 17, 21, 25, 26], "iclr": 2, "spotlight": 2, "2023": 2, "lawrenc": 2, "chan": 2, "tom": [2, 26], "lieberum": 2, "jess": 2, "smith": 2, "jacob": 2, "steinhardt": 2, "find": [2, 6, 9, 10, 12, 21, 26, 27], "neuron": [2, 6, 9, 12, 26, 27], "haystack": 2, "studi": [2, 4, 21, 26, 27], "spars": 2, "probe": 2, "gurne": 2, "matthew": 2, "pauli": 2, "katherin": 2, "harvei": 2, "dmitrii": 2, "troitskii": 2, "dimitri": 2, "bertsima": 2, "toward": [2, 15, 21, 26], "autom": 2, "circuit": [2, 11, 12, 15, 16, 17, 21, 25, 26, 27], "discoveri": 2, "arthur": [2, 27], "conmi": [2, 27], "augustin": 2, "n": [2, 15, 22, 25, 26, 27], "mavor": 2, "parker": 2, "aengu": 2, "lynch": 2, "stefan": 2, "heimersheim": 2, "adri\u00e0": 2, "garriga": 2, "alonso": 2, "actual": [2, 12, 17, 18, 27], "othello": [2, 6, 19, 28], "gpt": [2, 3, 4, 6, 9, 11, 12, 13, 15, 16, 19, 25, 26, 27, 28, 29], "ha": [2, 3, 4, 9, 10, 11, 12, 15, 16, 19, 20, 21, 25, 26, 27], "linear": [2, 6, 11, 12, 15, 19, 26, 27], "emerg": [2, 6], "world": [2, 6, 27, 29], "represent": [2, 6], "docstr": 2, "4": [2, 13, 15, 16, 25, 26, 27, 28], "layer": [2, 5, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 24, 25, 27], "attent": [2, 6, 9, 11, 12, 13, 15, 17, 21, 25, 27], "transform": [2, 3, 4, 6, 9, 11, 12, 13, 15, 19, 20, 21, 25, 26], "jett": 2, "janiak": 2, "toi": [2, 12], "univers": 2, "icml": 2, "bilal": 2, "chughtai": 2, "n2g": 2, "scalabl": 2, "approach": [2, 9, 26, 27], "quantifi": [2, 17], "larg": [2, 6, 13, 15, 19, 25, 27, 28, 29], "languag": [2, 11, 12, 15, 16, 22, 25, 26, 27], "workshop": 2, "rtml": 2, "alex": [2, 27], "foot": [2, 12, 27], "esben": 2, "kran": 2, "ioanni": 2, "konsta": 2, "fazl": 2, "barez": 2, "elicit": 2, "latent": 2, "predict": [2, 6, 9, 11, 12, 15, 16, 17, 25, 26, 27], "tune": [2, 11, 19, 25, 27, 28], "len": [2, 9, 19], "nora": 2, "belros": 2, "zach": 2, "furman": 2, "logan": 2, "danni": 2, "halawi": 2, "igor": 2, "ostrovski": 2, "lev": 2, "mckinnei": 2, "stella": 2, "biderman": 2, "contribut": [2, 9, 12, 26], "being": [2, 9, 11, 12, 13, 17, 18, 21, 25, 26, 27], "induct": [2, 4, 16, 17, 19], "head": [2, 4, 6, 9, 11, 12, 13, 14, 15, 16, 17, 19, 21, 25], "phase": 2, "replic": [2, 4, 12, 14, 16, 26, 27], "partial": [2, 26, 27], "context": [2, 9, 12, 18, 21, 25, 26, 27], "learn": [2, 3, 6, 13, 22, 25, 26, 27, 29], "connor": 2, "kissan": 2, "decis": [2, 3], "script": [2, 6], "train": [2, 6, 7, 8, 9, 11, 12, 13, 16, 19, 25, 26, 29], "which": [2, 3, 5, 6, 9, 11, 12, 13, 16, 17, 18, 19, 20, 21, 25, 26, 27], "intermedi": [2, 9, 12, 18, 27], "activ": [2, 3, 4, 6, 9, 11, 12, 13, 14, 18, 21, 25, 29], "perform": [2, 5, 6, 15, 16, 18, 25, 26, 27], "attribut": [2, 4, 6, 9, 15, 21, 25, 27], "ablat": [2, 26, 27], "up": [2, 3, 4, 9, 12, 13, 18, 21, 22, 25, 26, 27], "initi": [2, 7, 12, 13, 15, 18, 24, 25, 26, 27], "work": [2, 3, 4, 6, 9, 11, 12, 15, 18, 19, 25, 26, 27, 29], "found": [2, 5, 12, 13, 26, 27], "demo": [3, 14, 19, 28], "how": [3, 6, 9, 12, 17, 21, 22, 26, 27, 29], "basic": [3, 6, 12, 16, 25, 26], "To": [3, 4, 9, 12, 13, 15, 18, 19, 26, 27], "see": [3, 6, 9, 11, 12, 13, 15, 17, 19, 21, 25, 26, 27, 29], "exploratori": [3, 6, 17, 25, 27, 29], "analysi": [3, 6, 9, 12, 17, 25, 27, 29], "practic": [3, 4, 6, 26, 27], "look": [3, 4, 6, 7, 9, 12, 15, 17, 21, 26, 27], "out": [3, 6, 9, 12, 14, 21, 25, 26, 27], "my": [3, 6, 12, 13, 25, 26, 27, 29], "analys": [3, 6, 9, 12, 27], "indirect": [3, 4, 6, 16], "object": [3, 4, 6, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 25], "identif": [3, 4, 6, 16], "record": [3, 6, 27], "myself": [3, 6, 27], "veri": [3, 4, 6, 9, 13, 14, 16, 25, 26, 27, 29], "young": [3, 4, 27], "small": [3, 4, 5, 6, 9, 12, 16, 19, 25, 26, 27, 28, 29], "field": [3, 4, 12, 25, 27, 29], "lot": [3, 4, 6, 9, 10, 20, 21, 25, 26, 27, 29], "open": [3, 4, 12, 16, 29], "problem": [3, 4, 27, 29], "would": [3, 4, 11, 15, 26, 27, 29], "help": [3, 4, 13, 21, 26, 27], "try": [3, 4, 9, 12, 17, 26, 27], "concret": [3, 4, 26, 27], "figur": [3, 21, 26, 27], "where": [3, 5, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 22, 25, 26, 27], "skill": [3, 27], "kei": [3, 4, 9, 11, 12, 13, 15, 16, 17, 20, 21, 25, 26, 27], "resourc": [3, 4], "new": [3, 6, 9, 12, 18, 19, 20, 25, 26, 27], "tutori": [3, 4, 26, 27], "scratch": [3, 4, 26], "an": [3, 4, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 29], "accompani": [3, 4, 6, 27], "templat": [3, 16], "yourself": [3, 12, 26, 27], "One": [3, 12, 26, 27, 29], "signific": [3, 18, 26, 27], "design": [3, 9, 26, 27, 29], "made": [3, 16, 26, 27], "wa": [3, 5, 9, 11, 12, 13, 16, 21, 26, 27], "singl": [3, 9, 11, 12, 15, 20, 21, 25, 26, 27], "implement": [3, 11, 12, 15, 21, 25, 26, 27], "could": [3, 26, 27], "support": [3, 6, 11, 12, 13, 17, 18, 25, 26, 27], "rang": [3, 4, 12, 14, 17, 21, 25, 26, 27], "subtli": [3, 15], "differ": [3, 5, 9, 11, 12, 13, 15, 16, 17, 18, 21, 25, 26, 27], "style": [3, 9, 11, 12, 13, 15, 17, 26, 27, 29], "upsid": 3, "just": [3, 4, 9, 12, 13, 16, 21, 25, 26, 27], "arbitrari": [3, 12, 26, 27], "name": [3, 9, 12, 13, 16, 17, 18, 19, 21, 22, 25], "But": [3, 9, 12, 21, 25, 26, 27], "downsid": 3, "py": [3, 11], "compon": [3, 7, 8, 9, 11, 12, 25, 26, 27], "difficult": [3, 9], "recommend": [3, 7, 9, 12, 13, 14, 18, 26, 27], "clean": [3, 21, 25, 26, 27], "minim": [3, 27], "intern": [3, 9, 12, 21, 26, 27, 29], "architectur": [3, 11, 26], "significantli": [3, 11, 12, 16, 21, 26, 27], "clearer": 3, "better": [3, 12, 13, 16, 17, 19, 26, 27], "document": [3, 12, 25, 27], "pip": [3, 26, 27], "git": 3, "import": [3, 9, 12, 14, 16, 20, 21, 25, 29], "known": [3, 29], "easytransform": [3, 27, 29], "break": [3, 9, 26, 27], "been": [3, 9, 12, 25, 27], "sinc": [3, 9, 12, 15, 18, 26, 27], "renam": 3, "old": [3, 19, 27], "version": [3, 6, 12, 16, 18, 26, 27], "legaci": [3, 17], "run": [3, 5, 9, 12, 15, 18, 19, 20, 21, 22, 26, 29], "v1": 3, "mean": [4, 9, 12, 13, 14, 15, 17, 18, 25, 26, 27], "": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 25, 27, 29], "both": [4, 9, 12, 15, 17, 18, 20, 26, 27], "low": [4, 10, 12, 15, 25, 27], "hang": [4, 27], "fruit": [4, 27], "bar": [4, 12], "entri": [4, 15, 20, 21, 27], "The": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29], "standard": [4, 5, 12, 13, 26, 27], "answer": [4, 9, 21, 25, 26, 27], "why": [4, 9, 15, 25, 26, 27], "yet": [4, 11, 12, 26, 27, 29], "aren": [4, 19, 27], "t": [4, 9, 10, 11, 12, 13, 14, 15, 16, 19, 25, 26, 27, 29], "enough": [4, 9, 26, 27], "peopl": [4, 27], "guid": [4, 27], "arena": 4, "callum": [4, 27], "mcdougal": [4, 27], "comprehens": [4, 27], "introduct": 4, "mech": [4, 26], "interp": [4, 26], "written": [4, 6, 26], "snippet": 4, "copi": [4, 11, 26], "come": [4, 12, 13, 21, 26, 27], "exercis": [4, 26], "solut": [4, 26, 27], "notabl": [4, 12, 18, 26, 27], "video": [4, 6, 26, 27], "me": [4, 19, 27, 29], "good": [4, 6, 9, 16, 25, 26, 27, 29], "cover": [4, 12, 27], "foundat": [4, 27], "concept": [4, 26, 27], "wild": [4, 9, 26, 27], "techniqu": [4, 6, 12, 21, 26, 27], "direct": [4, 9, 12, 14, 18, 21, 27], "logit": [4, 5, 6, 9, 11, 12, 15, 16, 21, 25, 27], "patch": [4, 6, 7, 8], "paper": [4, 6, 9, 12, 13, 15, 16, 21, 27], "read": [4, 6, 9, 12, 27], "200": [4, 27], "explain": [4, 6, 26, 27], "jargon": 4, "unfamiliar": [4, 26], "term": [4, 9, 12, 26], "go": [4, 6, 21, 27], "across": [4, 9, 11, 12, 14, 19, 21, 24, 26, 27], "youtub": 4, "channel": 4, "content": [4, 16, 26, 27], "walkthrough": [4, 26, 27], "due": [5, 12, 27], "top": [5, 12, 25, 26, 27], "k": [5, 9, 10, 11, 12, 14, 15, 21, 25, 26, 27], "gate": [5, 12, 15], "hidden": [5, 13, 27], "amplifi": 5, "greatli": [5, 27, 29], "select": [5, 9, 25, 26, 27], "lead": [5, 6, 11, 18, 25, 27], "higher": [5, 12, 26], "than": [5, 9, 12, 13, 15, 16, 17, 18, 21, 25, 26, 27], "normal": [5, 9, 12, 13, 15, 25, 26, 27, 29], "varianc": [5, 26], "final": [5, 9, 11, 12, 13, 15, 25, 26, 27], "test": [5, 6, 12, 16, 17, 25, 26, 27], "mixtral": [5, 19, 28], "half": [5, 10, 11, 12, 15, 16, 27], "precis": [5, 17, 21, 26, 27], "deviat": [5, 13, 27], "absolut": [5, 11, 12, 13, 15, 17, 25, 26, 27], "compar": [5, 16, 27, 29], "those": [5, 12, 18, 25, 26], "around": [5, 9, 11, 12, 18, 21, 24, 26, 27], "2e": 5, "There": [5, 9, 11, 17, 19, 25, 26, 27, 29], "two": [5, 10, 11, 15, 17, 19, 21, 25, 26, 27], "wai": [5, 9, 12, 18, 25, 26, 27], "mitig": 5, "disabl": [5, 12, 17, 18, 26], "preprocess": [5, 11, 26], "option": [5, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25], "from_pretrained_no_process": [5, 12], "increas": [5, 21, 26, 27], "data": [5, 6, 12, 16, 25, 26, 27], "colab": [6, 26, 27, 29], "blob": 6, "ipynb": 6, "causal": [6, 11, 13, 21, 26, 27], "intervent": [6, 21, 26, 27], "identifi": [6, 12, 21, 26, 27], "matter": [6, 12, 21, 26, 27], "produc": [6, 12, 21, 26], "output": [6, 9, 11, 12, 13, 15, 17, 18, 21, 25, 26, 27], "incomplet": 6, "gradient": [6, 9, 18, 22, 27], "take": [6, 9, 12, 15, 18, 21, 25, 26, 27, 29], "approxim": [6, 26, 27], "individu": [6, 9, 12, 15, 26], "bad": [6, 12], "residu": [6, 9, 11, 12, 13, 15, 21, 27], "stream": [6, 9, 11, 12, 13, 15, 21, 25, 27], "probabl": [6, 12, 16, 17, 21, 25, 26, 27], "best": [6, 12, 26, 27], "after": [6, 9, 12, 13, 15, 18, 22, 26, 27, 29], "demonstr": [6, 14, 26, 27], "focus": [6, 26, 27], "less": [6, 12, 15, 26], "rigor": [6, 26, 27], "get": [6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 24, 26, 27, 29], "grasp": 6, "steal": 6, "liber": [6, 18], "phenomenon": 6, "memoris": 6, "minimis": 6, "loss": [6, 9, 12, 16, 18, 21, 22, 25, 26, 27], "longer": 6, "generalis": [6, 26, 27], "sharp": [6, 27], "decreas": [6, 15, 25, 26], "well": [6, 12, 14, 18, 21, 25, 26, 27], "show": [6, 12, 14, 17, 26, 27, 29], "task": [6, 11, 12, 13, 16, 21, 22, 26], "modular": [6, 25], "addit": [6, 11, 12, 26], "verifi": [6, 26, 27], "grok": 6, "light": 6, "explan": [6, 21, 26], "ll": [6, 12, 17, 26, 27], "pair": [6, 10, 12, 15, 17, 25, 26, 27], "seri": [6, 9, 27], "base": [6, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 26, 27, 28], "detector": [6, 17], "detect": [6, 17, 26, 27], "sever": [6, 9, 12, 25, 26, 27], "creat": [6, 9, 12, 15, 18, 26, 27], "own": [6, 26, 27], "custom": [6, 12, 13, 15, 16, 18, 25, 26, 27], "algorithm": [6, 10, 13, 27, 29], "interact": [6, 26, 27], "neuroscop": [6, 27], "hacki": [6, 25], "bug": [6, 9, 13, 25, 27], "web": [6, 27], "visualis": [6, 26], "even": [6, 10, 12, 13, 15, 16, 19, 26, 27, 29], "profession": 6, "front": 6, "visual": [6, 11, 27], "dynam": [6, 13, 27], "updat": [6, 12, 20, 21, 24, 26, 27], "llama": [6, 19, 28], "convert": [6, 11, 12, 25, 26, 27], "meta": [6, 12, 19, 25, 26, 27], "7b": [6, 19, 27, 28], "now": [6, 12, 13, 26, 27], "until": [6, 9, 12, 18, 26, 27], "multi": [6, 9, 25, 27], "gpu": [6, 9, 10, 11, 12, 26, 27], "great": [6, 27, 29], "avail": [6, 9, 12, 13, 17, 19], "access": [6, 9, 13, 18, 25, 26], "know": [6, 9, 11, 26, 27], "No": [6, 27], "posit": [6, 9, 11, 12, 13, 15, 16, 17, 18, 19, 21, 25, 26, 27], "experi": [6, 13, 26, 27, 29], "embed": [6, 9, 11, 12, 13, 15, 26, 27], "previou": [6, 9, 12, 15, 17, 26, 27], "token": [6, 9, 11, 12, 13, 14, 15, 16, 17, 19, 21, 25, 26], "port": 6, "weight": [6, 11, 12, 13, 15, 22, 25, 26, 27, 29], "excel": [6, 9, 26, 27, 29], "sequenc": [6, 11, 12, 13, 15, 16, 17, 18, 21, 25, 26, 27], "investig": [6, 9, 12, 17, 26, 27], "worth": [6, 9, 26, 27], "interest": [6, 11, 12, 26, 27], "topic": 6, "svd": [6, 10, 12, 14, 27], "conjectur": 6, "post": [6, 9, 14, 15, 26, 27], "singular": [6, 10, 12, 14, 27], "valu": [6, 9, 10, 11, 12, 13, 15, 17, 19, 20, 21, 25, 26, 27, 29], "decomposit": [6, 9, 10, 12, 26, 27], "matric": [6, 10, 11, 12, 14, 15, 26, 27], "surprisingli": 6, "reproduc": [6, 13, 17], "further": [6, 9, 12, 25, 26, 27], "tracr": 6, "cool": 6, "deepmind": 6, "tool": [6, 27, 29], "compil": 6, "program": [6, 27, 29], "rasp": 6, "jax": 6, "form": [6, 9, 10, 12, 21, 26, 27], "pytorch": [6, 12, 13, 16, 18, 27], "brows": 7, "first": [7, 9, 12, 13, 16, 19, 21, 25, 26, 27], "activationcach": [7, 8, 11, 12, 17, 21, 25, 26, 27], "submodul": 7, "factoredmatrix": [7, 8, 11, 15, 25, 27], "hookedencod": [7, 8, 24], "hookedtransformerconfig": [7, 8, 12, 15, 19, 20, 24], "svdinterpret": [7, 8], "eval": [7, 8, 27], "head_detector": [7, 8], "hook_point": [7, 8, 12, 27], "past_key_value_cach": [7, 8], "util": [7, 8, 9, 10, 12, 17, 18, 19, 22, 26, 27], "subpackag": 7, "core": [9, 12, 26, 27, 29], "wrapper": [9, 11, 12, 21, 24, 27], "store": [9, 12, 13, 15, 18, 20, 21, 22, 26, 27], "forward": [9, 11, 12, 13, 15, 18, 20, 27], "pass": [9, 12, 13, 15, 17, 18, 19, 20, 25, 27], "provid": [9, 11, 12, 15, 18, 24, 25], "varieti": [9, 27], "helper": [9, 12, 15, 16, 18, 21, 25, 27], "function": [9, 11, 12, 13, 15, 17, 18, 19, 21, 22, 24, 25, 27, 29], "them": [9, 12, 15, 18, 21, 25, 26, 27], "start": [9, 12, 15, 21, 25, 26, 27], "class": [9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 25], "skim": 9, "method": [9, 11, 12, 13, 18, 19, 20, 25, 26, 27], "refer": [9, 12, 15, 18, 26, 27], "back": [9, 13, 15, 27], "depend": [9, 12, 27], "cache_dict": 9, "dict": [9, 11, 12, 13, 15, 16, 17, 18, 25], "str": [9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27], "tensor": [9, 10, 11, 12, 14, 15, 17, 20, 21, 25, 26, 27], "has_batch_dim": 9, "bool": [9, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 25], "run_with_cach": [9, 11, 12, 18, 26, 27], "particular": [9, 14, 17, 26, 27], "behaviour": [9, 12, 26, 27], "modal": 9, "step": [9, 12, 13, 19, 22, 25, 26, 27], "most": [9, 12, 18, 25, 26, 27, 29], "respons": [9, 13, 26], "prompt": [9, 12, 15, 16, 21, 25, 26, 27], "did": [9, 25, 26, 27], "chicken": 9, "road": [9, 25], "might": [9, 11, 26], "specif": [9, 11, 12, 15, 17, 21, 26, 27], "sublay": 9, "mlp": [9, 11, 12, 13, 15, 21, 25, 26, 27], "kind": [9, 26, 27], "commonli": 9, "fall": 9, "under": [9, 12, 15], "categori": [9, 26], "dla": 9, "load": [9, 11, 12, 13, 16, 19, 25, 26, 29], "pretrain": [9, 11, 12, 13, 16, 19, 25, 26, 27], "_logit": 9, "residual_stream": 9, "label": [9, 12, 13, 15, 19, 26, 27], "decompose_resid": [9, 26], "return_label": [9, 26], "0": [9, 11, 12, 13, 14, 15, 17, 19, 22, 25, 26, 27, 28], "emb": [9, 15, 25, 27], "pos_emb": [9, 13, 27], "0_attn_out": 9, "proceed": 9, "space": [9, 11, 12, 25, 26, 27], "match": [9, 12, 17, 26], "logit_attr": 9, "shape": [9, 11, 12, 15, 21, 25, 26, 27], "torch": [9, 11, 12, 13, 15, 18, 19, 21, 24, 25, 26, 27], "size": [9, 12, 13, 15, 16, 22, 25, 26, 27], "10": [9, 12, 14, 25, 26, 27, 28], "7": [9, 16, 26, 27, 28], "most_important_component_idx": 9, "argmax": [9, 26], "3_attn_out": 9, "dig": [9, 26, 27, 29], "granular": 9, "get_full_resid_decomposit": 9, "larger": [9, 16, 26, 27], "stack": [9, 11, 12, 21, 25, 26, 27], "remain": [9, 12, 18, 27], "equal": [9, 13], "struggl": 9, "construct": [9, 11], "joke": 9, "last": [9, 12, 25, 27], "trivial": 9, "few": [9, 11, 26, 27], "call": [9, 11, 12, 13, 15, 18, 19, 25, 26, 27], "accumulated_resid": [9, 26], "other": [9, 11, 12, 15, 17, 18, 19, 21, 26], "biggest": 9, "footgun": [9, 18], "sourc": [9, 12, 13, 15, 16, 21, 29], "keep": [9, 12, 18, 26, 27, 29], "track": [9, 26], "index": [9, 11, 12, 13, 14, 15, 19, 21, 24, 25, 26, 27], "dimens": [9, 12, 13, 15, 18, 21, 25, 26, 27], "vector": [9, 10, 12, 14, 15, 21, 26, 27], "q": [9, 11, 12, 15, 21], "z": [9, 12, 15, 17, 21, 26, 27], "batch": [9, 11, 12, 15, 16, 18, 20, 21, 22, 25, 26, 27], "po": [9, 11, 12, 15, 21, 25, 26, 27], "head_index": [9, 12, 14, 15, 21, 26, 27], "d_head": [9, 11, 12, 13, 15, 19, 20, 25, 26, 27, 28], "pattern": [9, 11, 12, 15, 17, 21, 27], "result": [9, 11, 12, 13, 15, 17, 19, 21, 25, 26, 27, 29], "softmax": [9, 12, 15, 25, 27], "attn_scor": [9, 15], "pre": [9, 12, 13, 15, 17, 25], "query_po": [9, 15, 26], "key_po": [9, 15, 26], "d_model": [9, 11, 12, 13, 15, 19, 25, 26, 27, 28], "mid": [9, 26], "solu_ln": [9, 13], "between": [9, 12, 15, 17, 21, 25, 26, 27, 29], "layernorm": [9, 11, 12, 13, 15, 25, 26], "d_mlp": [9, 11, 12, 13, 15, 19, 25, 27, 28], "resid_pr": [9, 13, 15, 21, 26, 27], "resid_mid": [9, 21], "resid_post": [9, 13, 26], "attn_out": [9, 12, 13, 21, 26], "mlp_out": [9, 12, 13, 15, 21, 26], "ln": [9, 12, 13, 15, 26, 27], "lnpre": [9, 13], "scale": [9, 12, 13, 15, 25, 26, 27], "sometim": [9, 16, 26], "miss": [9, 26], "becaus": [9, 10, 11, 12, 13, 15, 16, 25, 26, 27, 29], "appli": [9, 12, 13, 15, 18, 21, 25, 26, 27], "remove_batch_dim": [9, 18, 25, 27], "batch_siz": [9, 11, 15, 16, 18, 20, 22, 26, 27], "robust": [9, 26], "annot": [9, 27], "layers_cov": 9, "queri": [9, 11, 12, 13, 15, 17, 21, 27], "batch_and_pos_dim": 9, "ve": [9, 12, 15, 16, 18, 26, 29], "remov": [9, 10, 12, 15, 18, 25, 26, 27, 29], "slice": [9, 18, 25, 26], "dictionari": [9, 11, 12, 13, 17, 18, 25, 27], "whether": [9, 11, 12, 13, 15, 16, 18, 19, 21, 22, 25, 26, 27], "int": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27], "none": [9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 26, 27], "incl_mid": [9, 26], "fals": [9, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27], "apply_ln": [9, 26], "pos_slic": [9, 18, 26], "union": [9, 11, 12, 14, 15, 17, 18, 19, 20, 21, 24, 25, 26], "tupl": [9, 10, 11, 12, 15, 17, 18, 21, 25, 27], "ndarrai": [9, 12, 25], "mlp_input": [9, 12], "float": [9, 10, 11, 12, 13, 15, 17, 19, 20, 21, 22, 25, 26, 27], "accumul": [9, 12, 26], "sub": [9, 27], "www": 9, "lesswrong": 9, "ackrb8wdpdan6v6ru": 9, "thought": [9, 26, 27], "believ": [9, 16, 26], "point": [9, 11, 12, 13, 14, 18, 25, 26, 29], "vocabulari": [9, 13, 26, 27], "rememb": 9, "norm": [9, 10, 12, 13, 15, 19, 22, 26, 27], "decod": 9, "therefor": [9, 12, 25], "multipli": [9, 12, 15, 17, 26, 27], "unembed": [9, 11, 12, 26, 27], "matrix": [9, 10, 11, 12, 13, 14, 15, 17, 25, 26], "w_u": [9, 11, 12, 26, 27], "broken": [9, 18, 25, 26, 27], "down": [9, 12, 15, 26, 27], "einop": [9, 26, 27], "einsum": [9, 26, 27], "panda": [9, 21], "pd": [9, 21], "devic": [9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 26, 27], "answer_token": [9, 26], "to_single_token": [9, 12, 26, 27], "2975": 9, "accum_resid": 9, "last_token_accum": 9, "9": [9, 25, 26, 27, 28], "64": [9, 19, 25, 27, 28], "50257": [9, 19, 27, 28], "layers_unembed": 9, "d_vocab": [9, 11, 12, 13, 14, 19, 21, 25, 27, 28], "rank": [9, 10, 12, 15, 25, 26, 27], "correct": [9, 21, 24, 25, 26, 27], "sorted_indic": 9, "argsort": 9, "dim": [9, 12, 25, 26, 27], "descend": [9, 27], "rank_answ": 9, "nonzero": 9, "as_tupl": 9, "0_pre": 9, "4442": 9, "1_pre": [9, 26], "382": 9, "2_pre": 9, "982": 9, "3_pre": 9, "1160": 9, "4_pre": 9, "408": 9, "5_pre": 9, "145": 9, "6_pre": 9, "78": 9, "7_pre": 9, "387": 9, "final_post": 9, "6": [9, 12, 19, 25, 26, 27, 28], "dtype": [9, 11, 12, 13, 15, 19, 24, 26, 27], "int64": [9, 25], "exclud": [9, 17], "n_layer": [9, 11, 12, 13, 19, 21, 24, 26, 27, 28], "immedi": [9, 15, 25, 26, 27], "indic": [9, 11, 15, 18, 21, 25, 26, 27], "taken": [9, 12, 27], "input": [9, 11, 12, 13, 15, 18, 19, 20, 21, 25, 26, 27], "l": [9, 11, 12, 26, 27], "noth": [9, 11, 12, 18, 25, 26, 27], "current": [9, 11, 12, 13, 15, 17, 26, 27], "essenti": [9, 12, 26, 27, 29], "rather": [9, 12, 13, 15, 21, 25, 26, 27], "graph": [9, 26, 27], "apply_ln_to_stack": [9, 12, 25, 26], "residual_stack": [9, 26], "num_compon": 9, "batch_slic": 9, "batch_and_pos_dims_out": 9, "eg": [9, 12, 16, 21, 25, 26, 27], "treat": [9, 12, 13, 26, 27], "factor": [9, 10, 12, 13, 26], "simul": [9, 12, 26, 27], "global": [9, 15, 18, 25, 26, 27], "entir": [9, 12, 21, 26], "element": [9, 12, 15, 17, 21, 25, 27], "unchang": [9, 11, 12, 25, 26, 27], "whose": [9, 11, 12, 16, 25, 26], "trail": [9, 10, 25], "assum": [9, 11, 12, 15, 18, 21, 22, 25, 26], "hook_scal": [9, 25, 26, 27], "unemb": [9, 12, 13, 15, 26, 27], "map": [9, 11, 12, 15, 17, 18, 26, 27], "ie": [9, 11, 12, 13, 15, 19, 21, 25, 26, 27], "ln2": [9, 15, 25, 27], "ln1": [9, 13, 15, 25, 27], "ln_final": [9, 12, 26, 27], "over": [9, 12, 21, 25, 26, 27], "alreadi": [9, 12, 25, 26, 27], "apply_slice_to_batch_dim": 9, "compute_head_result": 9, "comput": [9, 10, 12, 15, 17, 18, 20, 21, 25, 26, 27, 29], "amount": [9, 13, 26], "sum": [9, 10, 12, 13, 15, 17, 25, 26, 27], "plu": 9, "b_o": [9, 11, 12, 27], "intend": [9, 13, 25], "enabl": [9, 12, 26, 27, 29], "use_attn_result": [9, 12, 13], "forget": 9, "liter": [9, 11, 12, 14, 17, 18, 21], "incl_emb": 9, "decompos": 9, "incl": 9, "expand_neuron": 9, "bias": [9, 11, 12, 13, 22, 26], "expand": [9, 12, 15], "everi": [9, 11, 12, 15, 18, 21, 22, 25, 26, 27], "get_neuron_result": 9, "neuron_slic": 9, "num_neuron": 9, "subset": [9, 13, 16, 26, 27], "specifi": [9, 11, 12, 13, 15, 16, 17, 18, 24, 25, 27], "expens": [9, 10], "cheap": 9, "hook_emb": [9, 25, 27], "hook_pos_emb": [9, 27], "block": [9, 12, 13, 15, 21, 25, 26, 27], "hook_resid_pr": [9, 27], "incorrect_token": [9, 26], "typic": [9, 11, 12, 15, 17, 26, 27], "calcul": [9, 10, 11, 12, 13, 15, 17, 25, 26, 27], "revers": [9, 10, 21, 25, 26, 27, 29], "dot": [9, 12, 15, 25], "product": [9, 10, 11, 15, 27], "incorrect": [9, 12, 21, 26, 27], "arxiv": [9, 12, 13, 15, 16], "org": [9, 12, 13, 15, 16, 27, 29], "ab": [9, 10, 12, 15, 17, 26, 27], "2211": [9, 16], "00593": [9, 16], "john": [9, 26, 27], "mari": [9, 26, 27], "went": [9, 26, 27], "shop": [9, 26, 27], "gave": [9, 16, 26, 27], "bag": [9, 26], "were": [9, 12, 13, 16, 25, 26, 27, 29], "choos": [9, 26, 27], "impact": 9, "final_ln": 9, "residual_stack_item": 9, "dure": [9, 15, 18, 20, 27, 29], "stack_activ": 9, "activation_nam": [9, 21, 26], "sublayer_typ": 9, "flexibl": 9, "given": [9, 10, 11, 12, 14, 17, 18, 19, 21, 24, 25, 26, 27], "strictli": [9, 27], "befor": [9, 11, 12, 13, 15, 18, 25, 26, 27], "get_act_nam": [9, 25, 26, 27], "infer": [9, 12, 15, 21, 26, 27], "incl_remaind": 9, "stack_head_result": [9, 26], "axi": [9, 15, 21, 25, 26, 27], "n_head": [9, 11, 12, 13, 15, 19, 20, 21, 25, 26, 27, 28], "notat": [9, 26], "l0h0": 9, "stack_neuron_result": 9, "l0n0": 9, "super": [9, 12, 25, 27], "memori": [9, 10, 11, 12, 13, 26, 27], "short": [9, 25, 26, 27, 29], "move_model": 9, "move": [9, 11, 12, 21, 26, 27], "mostli": [9, 26, 27], "finish": [9, 12, 25, 26, 27], "save": [9, 12, 13, 17, 22, 25, 26, 27], "howev": [9, 12, 15, 16, 26, 27], "oper": [9, 26, 27], "slower": 9, "unless": [9, 12, 13, 16, 27], "deprec": 9, "toggle_autodiff": 9, "toggl": [9, 12], "autodiff": [9, 27], "set_grad_en": [9, 26, 27], "state": [9, 12, 18, 26, 27, 29], "pretti": [9, 12, 25, 26, 27], "danger": 9, "turn": [9, 12, 25, 26, 27], "off": [9, 12, 16, 25, 26, 27], "abil": [9, 21, 26], "complet": [9, 15, 26, 27], "easi": [9, 12, 25, 26, 27, 29], "bunch": [9, 11, 12, 18, 26, 27], "don": [9, 11, 12, 13, 14, 16, 25, 26, 27, 29], "realis": [9, 26], "consum": [9, 10], "downstream": 9, "delet": [9, 25, 26], "stick": [9, 26], "often": [9, 12, 13, 19, 25, 26, 27], "troubl": 9, "its": [9, 12, 15, 18, 26, 27, 29], "mess": [9, 12, 25, 27], "inference_mod": 9, "decor": 9, "achiev": [9, 27], "similar": [9, 11, 12, 15, 17, 26, 27], "effect": [9, 12, 21, 26, 27], "requires_grad": 9, "repres": [10, 11, 13, 15, 17, 21, 25, 26, 27], "effici": [10, 15, 25, 27], "eigenvalu": 10, "ldim": [10, 27], "mdim": [10, 27], "rdim": [10, 27], "properti": [10, 11, 12, 15, 25, 26, 27], "leading_dim": [10, 25], "ba": 10, "sens": [10, 18, 26, 27], "u": [10, 12, 21, 25, 26, 27], "vh": [10, 12], "collapse_l": 10, "collaps": [10, 26, 27], "left": [10, 12, 15, 25, 26, 27, 29], "side": [10, 12], "orthogon": [10, 12], "self": [10, 11, 12, 15, 25, 27], "collapse_r": 10, "analog": [10, 26, 27], "apart": [10, 25, 26, 27], "zero": [10, 12, 15, 17, 25, 26, 27], "bav": 10, "kv": 10, "abav": 10, "kav": 10, "av": 10, "eigenvector": [10, 27], "get_corn": [10, 25, 26], "make_even": 10, "sqrt": [10, 12, 13, 25], "diag": 10, "equival": [10, 12, 15, 26, 27], "factoris": [10, 12, 15, 27], "row": [10, 12, 21], "col": 10, "ndim": 10, "frobeniu": [10, 27], "squar": [10, 15, 25, 27], "m": [10, 15, 25, 26, 27], "st": 10, "transpos": [10, 25], "obviou": [10, 12, 26], "thing": [10, 12, 13, 15, 21, 26, 27, 29], "unsqueez": [10, 25], "hook": [11, 12, 13, 15, 18, 26], "encod": [11, 15, 25, 27], "contain": [11, 12, 15, 16, 17, 18, 19, 20, 25, 26, 27], "bert": [11, 15, 19, 27, 28], "separ": [11, 12, 13, 18, 25, 26, 27], "move_to_devic": [11, 12], "kwarg": [11, 12, 19, 25, 26, 27], "hookedrootmodul": [11, 12, 18, 27], "hookpoint": [11, 12, 18, 26, 27], "inherit": [11, 27], "limit": [11, 12, 26], "mvp": 11, "mask": [11, 12, 15, 25, 26], "mlm": 11, "next": [11, 12, 25, 26, 27], "sentenc": [11, 12, 15, 17, 26, 27], "nsp": 11, "dropout": 11, "inconsist": [11, 14], "fine": [11, 27], "fold": [11, 12, 15, 19, 26], "ov": [11, 12, 14, 15, 26, 27], "o": [11, 27], "qk": [11, 12, 15, 26], "w_e": [11, 12, 27], "conveni": [11, 12, 13, 18, 25, 27], "w_e_po": [11, 12], "n_ctx": [11, 12, 13, 15, 19, 27, 28], "concaten": [11, 12, 25, 26, 27], "w_po": [11, 12, 27], "overcomplet": [11, 12], "basi": [11, 12], "w_k": [11, 12, 13, 15, 27], "w_o": [11, 12, 15, 26, 27], "w_q": [11, 12, 15, 27], "w_v": [11, 12, 15, 27], "w_in": [11, 12, 14, 15, 27], "w_out": [11, 12, 14, 15, 27], "all_head_label": [11, 12], "format": [11, 12, 18, 26, 27], "h": [11, 12, 26, 27], "b_k": [11, 12, 15, 27], "b_q": [11, 12, 27], "b_u": [11, 12, 26, 27], "bia": [11, 12, 13, 15, 26, 27], "b_v": [11, 12, 15, 27], "b_in": [11, 12, 15, 27], "b_out": [11, 12, 15, 27], "buffer": [11, 12], "modifi": [11, 12], "cuda": [11, 12, 13, 16, 19], "associ": [11, 12, 18], "optim": [11, 12, 22, 26], "live": [11, 12, 26, 27], "while": [11, 12, 15, 18, 26, 27], "return_typ": [11, 12, 18, 26, 27], "token_type_id": [11, 15], "one_zero_attention_mask": 11, "binari": [11, 15], "id": [11, 12, 15], "belong": [11, 15], "cl": [11, 15, 27], "sep": [11, 15], "sequence_length": [11, 15, 17, 25], "attend": [11, 13, 15, 25, 26, 27], "ignor": [11, 12, 13, 15, 18, 25, 27], "primarili": 11, "pad": [11, 12, 15, 25, 26, 27], "variabl": 11, "instanc": [11, 15, 17, 18, 26], "shorter": [11, 12, 27], "right": [11, 12, 15, 21, 25, 26, 27], "classmethod": [11, 12, 13, 20], "model_nam": [11, 12, 13, 19, 27], "checkpoint_index": [11, 12, 13, 19, 27], "checkpoint_valu": [11, 12, 13, 19, 27], "hf_model": [11, 12], "float32": [11, 12, 13, 15, 19, 26], "from_pretrained_kwarg": [11, 12], "huggingfac": [11, 12, 13, 16, 19, 25, 27, 29], "bertformaskedlm": 11, "unlik": [11, 12, 21, 27], "mp": [11, 12], "model_arg": [11, 12, 18], "return_cache_object": [11, 12], "otherwis": [11, 12, 16, 17, 25], "device_or_dtyp": [11, 12, 24], "print_detail": [11, 12, 24, 25], "cast": [11, 12], "non_block": [11, 12], "memory_format": [11, 12], "channels_last": [11, 12], "Its": [11, 12], "complex": [11, 12, 13, 26, 27], "integr": [11, 12, 19], "tri": [11, 12, 26, 27, 29], "asynchron": [11, 12], "respect": [11, 12, 18, 25, 27], "host": [11, 12, 19], "pin": [11, 12], "below": [11, 12, 26], "desir": [11, 12], "4d": [11, 12], "keyword": [11, 12, 18, 27], "argument": [11, 12, 13, 18, 19, 25, 27], "xdoctest": [11, 12], "ignore_w": [11, 12], "non": [11, 12, 13, 15, 16, 25, 26, 27], "determinist": [11, 12, 25, 26], "nn": [11, 12, 18, 27], "1913": [11, 12], "3420": [11, 12], "5113": [11, 12], "2325": [11, 12], "doubl": [11, 12], "in_featur": [11, 12], "out_featur": [11, 12], "float64": [11, 12], "requir": [11, 12, 21, 25], "env": [11, 12], "torch_doctest_cuda1": [11, 12], "gpu1": [11, 12], "1914": [11, 12], "5112": [11, 12], "2324": [11, 12], "float16": [11, 12], "cdoubl": [11, 12], "3741": [11, 12], "j": [11, 12, 13, 15, 19, 26, 27, 28], "2382": [11, 12], "5593": [11, 12], "4443": [11, 12], "complex128": [11, 12], "6122": [11, 12], "1150": [11, 12], "fairli": [12, 26, 27], "extract": [12, 27], "harder": [12, 21, 26], "aim": [12, 26, 29], "simplifi": [12, 26, 27], "attach": [12, 27], "within": [12, 15, 17, 18, 21, 25, 26, 27], "inspect": [12, 26], "alter": 12, "facilit": 12, "deeper": 12, "pretrainedtokenizerbas": 12, "default_padding_sid": 12, "50": [12, 22, 27], "initialis": [12, 13], "although": [12, 15, 18], "instanti": [12, 13, 27], "randomli": [12, 13, 27], "__init__": [12, 15, 18, 25, 27], "test_prompt": [12, 25, 26, 27], "w_gate": [12, 15], "tokenizer_nam": [12, 13], "cannot": [12, 25, 27], "explicitli": [12, 13, 15, 16, 19, 21, 27], "n_devic": [12, 13, 19, 24], "greater": [12, 17], "split": [12, 15, 19, 25, 26, 27], "multipl": [12, 17, 24, 25, 27], "accumulated_bia": 12, "include_mlp_bias": 12, "layers_accumulated_ov": 12, "all_composition_scor": [12, 25], "composit": [12, 26, 27], "score": [12, 15, 17, 21, 26], "l1": 12, "h1": 12, "l2": 12, "h2": [12, 26], "upper": [12, 15], "triangular": [12, 17, 25, 27], "third": [12, 27], "pub": [12, 25], "2021": 12, "framework": [12, 15, 26, 27], "html": [12, 25, 26], "20abov": 12, "20diagram": 12, "20show": 12, "20q": 12, "2d": [12, 25], "2c": 12, "20k": [12, 25], "20and": 12, "20v": 12, "2dcomposit": 12, "three": [12, 21, 25, 26], "metric": [12, 17, 21, 26, 27], "center_unemb": [12, 26], "state_dict": 12, "center": [12, 13, 15, 26, 27], "subtract": [12, 17, 26], "themselv": 12, "As": [12, 25, 26, 27], "translat": [12, 26, 27], "invari": 12, "log": [12, 22, 25, 26, 27], "prob": [12, 25, 26, 27], "slightli": [12, 25, 26], "misl": 12, "someth": [12, 16, 26], "center_writing_weight": [12, 26, 27], "fold_layer_norm": [12, 19], "check_hooks_to_add": [12, 18], "hook_point_nam": [12, 18], "dir": [12, 18], "fwd": [12, 18], "is_perman": [12, 18], "prepend": [12, 13, 16, 18, 19, 25, 27], "overrid": [12, 13, 18, 19, 25], "fold_bias": 12, "center_weight": 12, "rm": [12, 15], "consist": [12, 26, 27], "neighbour": 12, "further_com": [12, 13], "md": [12, 13], "fold_value_bias": 12, "alwai": [12, 13, 21, 26, 27], "constant": [12, 13, 15, 26, 27], "togeth": [12, 25, 26, 27], "doesn": [12, 16, 25, 26, 27], "easier": [12, 16, 26, 27, 29], "formal": 12, "b_o_new": 12, "b_o_origin": 12, "sum_head": 12, "b_v_head": 12, "w_o_head": 12, "loss_per_token": 12, "prepend_bo": [12, 13, 16, 19, 25, 26], "use_default_valu": 12, "padding_sid": [12, 25, 26], "start_at_lay": 12, "shortformer_pos_emb": [12, 15], "attention_mask": [12, 15, 20, 25], "stop_at_lay": 12, "past_kv_cach": [12, 15], "hookedtransformerkeyvaluecach": [12, 15, 20], "either": [12, 17, 18, 19, 21, 26, 27], "flag": [12, 13, 16, 18, 21, 25, 26, 27], "entropi": [12, 25, 26, 27], "per": [12, 21, 25, 26, 27], "averag": [12, 16, 26, 27], "scalar": [12, 15, 18, 27], "default_prepend_bo": [12, 13, 16, 19, 25, 27], "bo": [12, 13, 17, 19, 25, 26, 27], "impli": 12, "usag": [12, 26], "accordingli": [12, 13, 15, 19, 26, 27], "lose": [12, 13, 19], "empir": [12, 13, 19, 21, 27], "seem": [12, 13, 16, 19, 26, 27], "inclus": 12, "skip": [12, 26, 27], "neg": [12, 25, 26, 27], "shortform": [12, 13, 15, 19], "positional_embedding_typ": [12, 13, 15], "stop": 12, "exclus": [12, 25], "etc": [12, 21, 26, 27, 29], "24": [12, 25, 26, 27, 28], "frozen": [12, 20], "pai": [12, 15, 26], "through": [12, 26, 27], "correctli": 12, "okai": 12, "twice": [12, 16, 26, 27], "accident": [12, 18], "second": [12, 16, 26, 27], "fold_ln": [12, 19, 26, 27], "refactor_factored_attn_matric": [12, 26], "automodelforcausallm": 12, "process": [12, 13, 19, 25, 26, 27], "autoregress": [12, 22], "neo": [12, 15, 19, 27, 28], "gptj": [12, 19], "opt": [12, 19, 27, 28], "solu": [12, 13, 19, 25, 27, 28], "checkpoint": [12, 13, 19, 22], "stanford": [12, 13, 15, 19, 27, 28], "crfm": [12, 19, 27], "load_and_process_state_dict": 12, "alia": [12, 19, 25, 27], "subsequ": [12, 19, 26, 27], "regular": [12, 15], "batchnorm": [12, 26, 27], "mathemat": [12, 15, 26, 27], "w_": 12, "b_": 12, "w": 12, "layernormpr": [12, 15], "eff": 12, "ext": 12, "wise": [12, 17], "computation": [12, 27], "handl": [12, 18], "wish": 12, "defin": [12, 15, 18, 25, 26, 27], "x_1": [12, 27], "x_0": [12, 27], "x_2": [12, 27], "frac": [12, 27], "x_3": 12, "cdot": 12, "x_4": 12, "relat": [12, 15, 26, 27], "idea": [12, 15, 21, 26, 27, 29], "preced": [12, 25, 26, 27], "never": [12, 27], "w_write": 12, "keepdim": 12, "affect": [12, 21, 26], "fed": [12, 17], "exactli": [12, 19, 26, 27], "1000": [12, 16, 25, 27], "recreat": 12, "onto": [12, 19, 26], "By": [12, 16, 18, 19, 21, 25, 26, 27], "els": [12, 13, 15, 19, 25, 26, 27], "mix": [12, 25, 26, 27], "linearli": 12, "technic": [12, 26, 27], "deriv": [12, 27], "broadcast_b_v": 12, "broadcast": 12, "And": [12, 21, 26, 27], "destination_posit": [12, 27], "source_posit": [12, 27], "along": [12, 15, 25, 26, 27], "source_": 12, "destin": [12, 13, 21, 27], "behavior": [12, 13, 19, 26], "cache_dir": [12, 25], "torch_dtyp": 12, "compat": [12, 19], "especi": [12, 26, 27], "bfloat16": 12, "boolean": [12, 18, 21, 25, 26, 27], "max_new_token": [12, 27], "stop_at_eo": 12, "eos_token_id": [12, 25], "do_sampl": 12, "top_k": [12, 25, 26, 27], "top_p": [12, 25], "temperatur": [12, 25, 27], "freq_penalti": [12, 25], "use_past_kv_cach": 12, "verbos": 12, "pos_plus_new_token": 12, "sampl": [12, 16, 25], "eos_token": 12, "reach": [12, 27], "avoid": [12, 20, 25, 26, 27], "fiddl": 12, "rag": 12, "eot": 12, "throw": 12, "awai": [12, 26], "enter": [12, 26, 27, 29], "messi": [12, 27], "maximum": [12, 13, 15, 22, 27], "stable_lm": 12, "distribut": [12, 24, 25, 26, 27], "greedi": [12, 25], "search": [12, 17, 26, 27], "max": [12, 26], "mass": 12, "cumul": [12, 25], "random": [12, 13, 16, 22, 26, 27], "temp": [12, 25], "inf": 12, "uniform": [12, 25], "frequenc": [12, 25, 26], "penalti": [12, 25], "penalis": 12, "speed": [12, 26], "applic": [12, 25], "whatev": [12, 26], "tqdm": [12, 27], "get_token_posit": [12, 26, 27], "single_token": [12, 27], "present": 12, "gotcha": [12, 14, 26], "Be": 12, "care": [12, 15, 18, 26, 27], "weird": [12, 13, 26, 27], "carefulli": [12, 26], "correspond": [12, 15, 17, 21, 25, 26, 27], "dummi": [12, 18, 27], "init_weight": [12, 13], "empti": [12, 18], "bulk": 12, "seed": [12, 13, 22, 27], "ensur": [12, 26], "determin": [12, 15, 21, 24, 25, 26, 27], "NOT": [12, 18, 25, 27], "scheme": 12, "far": [12, 25, 26, 27], "tell": [12, 16, 26, 27], "date": 12, "gotten": 12, "round": [12, 16, 26, 27], "issu": [12, 26, 27], "18182": 12, "fan_in": [12, 25], "tha": 12, "kaim": [12, 25], "despit": [12, 27], "fact": [12, 26, 27, 29], "xavier": [12, 25], "fan_out": 12, "transformerencod": 12, "exact": 12, "72253": 12, "mup": [12, 13], "haven": 12, "2203": 12, "03466": 12, "input_to_emb": 12, "relev": [12, 13, 15, 21, 25, 26, 27], "special": [12, 27], "redwood": [12, 26, 27], "load_sample_training_dataset": 12, "dataset": [12, 16, 22, 25, 27], "10k": [12, 16, 25], "get_dataset": [12, 25], "appropri": [12, 27], "info": [12, 13, 21, 25, 27], "download": [12, 25, 27], "locat": [12, 21, 26], "pt": 12, "openwebtext": [12, 16, 25], "karma": [12, 16], "reddit": [12, 16], "hard": [12, 26, 27], "pile": [12, 16, 19, 25, 27, 28], "imperfectli": 12, "suppli": 12, "valid": [12, 16, 26], "loss_fn": [12, 27], "per_token": [12, 25, 27], "lm_cross_entropy_loss": [12, 25], "move_model_modules_to_devic": 12, "process_weights_": 12, "allow": [12, 17, 21, 25, 26, 27], "cleaner": 12, "experiment": 12, "argu": [12, 27], "somewhat": [12, 26, 27], "w_qk": [12, 15, 27], "w_ov": [12, 15, 27], "mani": [12, 15, 20, 21, 22, 26, 27], "hopefulli": [12, 29], "attempt": 12, "column": [12, 21, 25], "rotat": [12, 13, 15, 27], "nth": 12, "formula": 12, "r": 12, "think": [12, 16, 25, 26, 27], "setup": [12, 18, 21], "refactor": 12, "diagon": [12, 26, 27], "asymmetri": 12, "fiddli": 12, "deal": [12, 15, 25, 26], "preserv": [12, 26, 27], "too": [12, 21, 26], "bilinear": [12, 27], "dimension": [12, 13], "coordin": 12, "sample_datapoint": 12, "implicitli": [12, 21, 27], "hasn": 12, "manual": [12, 25, 27], "replac": [12, 13, 21, 26, 27, 29], "choic": [12, 26], "truncat": [12, 16, 25, 27], "set_token": [12, 13], "pretrainedtoken": 12, "set_use_attn_in": 12, "use_attn_in": [12, 13], "set_use_attn_result": 12, "expos": [12, 29], "easili": [12, 25, 26, 27], "burn": 12, "set_use_hook_mlp_in": 12, "use_hook_mlp_in": [12, 13], "set_use_split_qkv_input": 12, "use_split_qkv_input": [12, 13], "to_single_str_token": 12, "int_token": 12, "uncertain": 12, "to_token": [12, 25, 26, 27], "to_str_token": [12, 14, 26, 27], "weirdli": [12, 26, 27], "gotcha2": 12, "letter": [12, 27], "capit": [12, 26, 27], "shoot": [12, 27], "gotcha3": 12, "exce": 12, "str_token": [12, 26], "to_str": [12, 26, 27], "numpi": [12, 13, 25, 26], "arrai": [12, 14, 25], "long": [12, 27], "window": [12, 13, 25], "tokens_to_residual_direct": [12, 26], "mislead": [12, 26], "integ": [12, 25, 26, 27], "residual_direct": 12, "namedtupl": 12, "dataclass": [13, 18], "configur": [13, 22, 24], "act_fn": [13, 15, 28], "ep": 13, "1e": [13, 19], "05": [13, 19], "use_attn_scal": 13, "use_local_attn": 13, "original_architectur": 13, "from_checkpoint": 13, "checkpoint_label_typ": [13, 27], "window_s": [13, 15], "attn_typ": [13, 15], "init_mod": 13, "normalization_typ": 13, "attention_dir": 13, "attn_onli": [13, 28], "initializer_rang": 13, "scale_attn_by_inverse_layer_idx": 13, "final_rm": 13, "d_vocab_out": [13, 15], "parallel_attn_mlp": 13, "rotary_dim": [13, 15], "n_param": [13, 28], "use_hook_token": 13, "gated_mlp": 13, "tokenizer_prepends_bo": 13, "n_key_value_head": [13, 15], "post_embedding_ln": 13, "rotary_bas": 13, "10000": [13, 15, 27], "trust_remote_cod": 13, "rotary_adjacent_pair": 13, "num_expert": 13, "experts_per_token": 13, "AND": 13, "feedforward": 13, "network": [13, 26, 27], "vocab": 13, "lowercas": 13, "relu": [13, 25, 28], "gelu": [13, 15, 19, 27, 28], "silu": [13, 28], "gelu_new": [13, 25], "gelu_fast": [13, 25], "epsilon": 13, "5": [13, 15, 16, 17, 19, 21, 25, 26, 27, 28], "THEN": 13, "intens": 13, "famili": [13, 27], "certain": [13, 21], "distanc": [13, 15, 26], "weight_init_mod": 13, "xavier_uniform": 13, "xavier_norm": 13, "kaiming_uniform": 13, "kaiming_norm": 13, "pipelin": 13, "parallel": [13, 25, 26], "aka": 13, "unidirect": 13, "bidirect": [13, 27], "8": [13, 15, 16, 17, 26, 27, 28], "gain": [13, 25], "layer_id": [13, 15], "mistral": [13, 15, 16, 19, 28], "numer": [13, 14, 15, 27], "stabil": [13, 15, 27], "fp16": 13, "rotari": [13, 15], "describ": [13, 25, 26], "blog": [13, 15], "eleuth": [13, 15, 25, 27], "ai": [13, 15, 19, 25, 27], "res_stream": 13, "sinusoid": 13, "rmsnorm": [13, 15], "dumb": 13, "origin": [13, 14, 15, 26, 27], "mainli": 13, "curs": 13, "law": 13, "pdf": [13, 15, 16], "2001": 13, "08361": 13, "meaning": [13, 21], "Will": [13, 21], "let": [13, 25, 26, 27, 29], "interven": [13, 18, 21, 26], "add_bos_token": [13, 25], "control": [13, 21, 26, 27], "group": [13, 15], "expert": 13, "moe": [13, 15], "from_dict": 13, "config_dict": 13, "set_seed_everywher": 13, "to_dict": 13, "get_singular_vector": 14, "vector_typ": 14, "layer_index": [14, 26], "num_vector": 14, "plot": [14, 27], "pysvelt": [14, 27], "instabl": 14, "d": [14, 16, 17, 19, 26, 28], "medium": [14, 19, 28], "svd_interpret": 14, "22": [14, 16, 25, 26, 27], "all_token": 14, "np": [14, 25, 26], "def": [14, 26, 27], "plot_matrix": 14, "filter": [14, 18, 19, 25, 27], "topk": [14, 26], "topktabl": 14, "obj_typ": 14, "abstractattent": 15, "abc": [15, 27], "pure": 15, "glossari": 15, "order": [15, 21, 25, 26], "sorri": 15, "underli": [15, 21, 26, 27], "destination_residu": 15, "destination_po": 15, "source_po": [15, 27], "abstract": [15, 26, 27], "groupedqueryattent": 15, "enforc": 15, "child": 15, "better_abc": 15, "abstract_attribut": 15, "stackoverflow": 15, "question": [15, 26, 27], "23831510": 15, "256": [15, 27, 28], "Not": 15, "moment": 15, "reason": [15, 26, 27], "alibi": 15, "apply_causal_mask": 15, "pos_plus_past_kv_pos_offset": 15, "past_kv_pos_offset": [15, 25], "offset_po": [15, 25], "apply_rotari": 15, "calculate_attention_scor": 15, "calculate_qkv_matric": 15, "query_input": 15, "key_input": 15, "value_input": 15, "calculate_sin_cos_rotari": 15, "sine": 15, "cosin": 15, "wave": 15, "inexplic": 15, "adjac": [15, 26], "neox": [15, 19, 27, 28], "clue": [15, 26], "resolv": 15, "calculate_z_scor": 15, "static": [15, 16], "create_alibi_bia": 15, "head_idx": 15, "2108": 15, "12409": 15, "broad": [15, 26], "behind": [15, 26], "proport": [15, 25], "encourag": [15, 25], "distant": 15, "0000": [15, 26], "0625": 15, "1250": 15, "1875": 15, "0039": 15, "0078": 15, "0117": 15, "create_alibi_multipli": 15, "geometr": 15, "ratio": [15, 25, 26, 27], "With": [15, 27], "16": [15, 25, 26, 27, 28], "5000": 15, "2500": [15, 26], "0312": 15, "0156": 15, "7071": 15, "3536": 15, "1768": 15, "0884": 15, "0442": 15, "0221": 15, "0110": 15, "0055": 15, "create_alibi_slop": 15, "slope": 15, "triangl": 15, "lower": [15, 16, 17, 25, 26, 27], "bottom": [15, 27], "corner": 15, "kv_head_index": 15, "past_kv_cache_entri": 15, "hookedtransformerkeyvaluecacheentri": [15, 20], "additive_attention_mask": 15, "irrelev": [15, 26, 27], "past": [15, 20, 26], "rotate_every_two": 15, "x0": 15, "x1": 15, "param": [15, 22, 25, 27], "convent": [15, 25, 26, 27], "mistal": 15, "bertblock": 15, "transformerblock": 15, "except": [15, 26, 27], "overridden": [15, 18, 25], "subclass": [15, 18], "recip": [15, 18], "afterward": [15, 18], "former": [15, 18], "regist": [15, 18], "latter": [15, 18, 27], "silent": [15, 18], "bertemb": 15, "input_id": 15, "bertmlmhead": 15, "purpos": [15, 16, 26, 27], "resid": 15, "gatedmlp": 15, "equat": 15, "pre_linear": 15, "callabl": [15, 18, 21], "2305": 15, "13245v2": 15, "hood": 15, "_w_k": 15, "_w_v": 15, "getter": 15, "similarli": 15, "kept": 15, "repeat_interleav": 15, "unexpand": 15, "expan": 15, "n_query_head": 15, "gpa": 15, "normalis": [15, 26], "posemb": 15, "root": [15, 27], "rmsnormpr": 15, "tokentypeemb": 15, "1810": 15, "04805": 15, "block_index": 15, "positional_embeddings_typ": 15, "_description_": 15, "_type_": [15, 18], "evalu": [16, 18, 26, 27], "rough": [16, 27], "anyth": [16, 26], "properli": [16, 26], "cheapli": 16, "roughli": [16, 26, 27], "baselin": 16, "ioidataset": 16, "noun": 16, "num_sampl": 16, "symmetr": 16, "ioi_ev": 16, "476": 16, "met": 16, "alic": 16, "bob": 16, "charli": 16, "ball": [16, 26], "book": 16, "397": 16, "get_default_nam": 16, "get_default_noun": 16, "get_default_templ": 16, "get_sampl": 16, "evaluate_on_dataset": 16, "data_load": 16, "induction_loss": [16, 27], "subseq_len": 16, "384": [16, 27], "accuraci": [16, 17, 25], "make_code_data_load": 16, "codeparrot": [16, 25], "dump": 16, "presum": [16, 26], "natur": [16, 26, 27], "make_owt_data_load": 16, "corpu": [16, 25], "make_pile_data_load": 16, "eleutherai": [16, 19], "english": [16, 27, 29], "academ": 16, "internet": [16, 27], "make_wiki_data_load": 16, "wikitext": 16, "wikipedia": [16, 25, 27], "articl": [16, 25, 26, 27], "realli": [16, 17, 25, 26, 27], "expect": [16, 17, 26, 27], "anyon": 16, "bother": 16, "quarantin": 16, "nowadai": 16, "leakag": 16, "though": [16, 25, 26, 27], "sanity_check": 16, "feed": [16, 25, 27], "paragraph": [16, 27], "zoom": [16, 21, 26], "quick": [16, 17, 27], "saniti": [16, 26], "ok": [16, 26, 27], "gone": [16, 26, 27], "wrong": [16, 18, 26], "compute_head_attention_similarity_scor": 17, "attention_pattern": [17, 27], "detection_pattern": 17, "exclude_bo": 17, "exclude_current_token": 17, "error_measur": 17, "mul": 17, "comparison": 17, "exclude_bcurrent_token": 17, "detect_head": 17, "seq": [17, 25], "previous_token_head": 17, "duplicate_token_head": 17, "induction_head": 17, "headnam": 17, "itself": [17, 25, 26], "divid": [17, 25, 26], "straightforward": [17, 26], "big": [17, 19, 25, 26, 27], "fraction": 17, "alloc": 17, "prohibit": 17, "cours": [17, 26], "raw": [17, 26], "interv": 17, "perfect": [17, 26], "mismatch": 17, "examin": 17, "switch": 17, "advantag": 17, "closer": 17, "head_nam": 17, "exist": [17, 26, 27], "ntensor": 17, "ioi": [17, 26, 27], "spacifi": 17, "analyz": 17, "paid": [17, 26, 27], "get_duplicate_token_head_detection_pattern": 17, "duplic": [17, 26, 27], "dynalist": 17, "n2zwtnoyhru1s4vnfsaq519j": 17, "2ukvedzonghl5uhugvhroxeo": 17, "get_induction_head_detection_pattern": 17, "_tfvup5csv5orithmqwj0gsi": 17, "get_previous_token_head_detection_pattern": 17, "0o5vohe9xezn8ertywkh7ioc": 17, "get_supported_head": 17, "inspir": [18, 27, 29], "garcon": [18, 27, 29], "act": [18, 21, 25, 26, 27], "ident": [18, 25, 26, 27], "wrap": [18, 27], "add_hook": [18, 26], "bwd": 18, "fn": 18, "hook_nam": 18, "add_perma_hook": [18, 27], "clear_context": 18, "remove_hook": 18, "including_perman": 18, "build": [18, 27, 29], "interfac": [18, 27, 29], "nice": [18, 26], "variou": [18, 26, 27], "run_with_hook": [18, 26, 27], "temporari": [18, 25, 27], "persist": 18, "debug": [18, 19, 22], "fix": [18, 26, 27], "still": [18, 26], "solv": [18, 26, 27, 29], "intent": 18, "reset_hook": [18, 27], "goe": [18, 26, 27], "reset_hooks_end": [18, 26], "add_caching_hook": 18, "names_filt": [18, 26], "incl_bwd": 18, "namesfilt": 18, "lambda": [18, 26, 27], "cache_al": 18, "cache_som": 18, "check_and_add_hook": 18, "get_caching_hook": 18, "fwd_hook": [18, 26, 27], "bwd_hook": 18, "exit": [18, 25], "clear": [18, 27], "whenev": 18, "reset": 18, "my_hook": 18, "hooked_loss": 18, "remove_all_hook_fn": 18, "model_kwarg": 18, "everyth": [18, 21, 25, 27], "degrad": 18, "lenshandl": 18, "removablehandl": 18, "context_level": 18, "hold": 18, "perman": 18, "hug": 19, "face": 19, "hub": [19, 25], "768": [19, 26, 27, 28], "layer_norm_ep": 19, "init_rang": 19, "02": 19, "1024": [19, 25, 27, 28], "3072": [19, 27, 28], "12": [19, 26, 27, 28], "model_alias": 19, "01": 19, "yi": [19, 28], "34b": [19, 28], "chat": [19, 27, 28], "6b": [19, 27, 28], "arthurconmi": 19, "redwood_attn_2l": [19, 28], "baidicoot": 19, "codellama": [19, 28], "instruct": [19, 27, 28], "hf": 19, "codellamallama": [19, 28], "3b": [19, 27, 28], "125m": [19, 27, 28], "20b": [19, 27, 28], "pythia": [19, 28], "4b": [19, 28], "dedup": [19, 28], "v0": [19, 28], "12b": [19, 28], "13b": [19, 27, 28], "14m": [19, 28], "160m": [19, 28], "seed1": [19, 28], "seed2": [19, 28], "seed3": [19, 28], "1b": [19, 28], "800m": 19, "8b": [19, 27, 28], "31m": [19, 28], "410m": [19, 28], "350m": 19, "9b": [19, 28], "70m": [19, 28], "19m": [19, 28], "2l512w": 19, "lr": [19, 22], "attn_only_1l512w_c4_cod": 19, "c4": [19, 25, 27], "attn_only_2l512w_c4_cod": 19, "attn_only_3l512w_c4_cod": 19, "attn_only_4l512w_c4_cod": 19, "gelu_1l512w_c4_cod": 19, "gelu_2l512w_c4_cod": 19, "gelu_3l512w_c4_cod": 19, "gelu_4l512w_c4_cod": 19, "solu_10l1280w_c4_cod": 19, "10l": [19, 27, 28], "solu_10l_v22_old": 19, "solu_12l1536w_c4_cod": 19, "12l": [19, 27, 28], "solu_12l_v23_old": 19, "solu_1l512w_c4_cod": 19, "solu_1l512w_wiki_finetun": 19, "wiki": [19, 25, 26, 27, 28], "finetun": 19, "solu_1l_v9_old": 19, "solu_2l512w_c4_cod": 19, "solu_2l_v10_old": 19, "solu_3l512w_c4_cod": 19, "solu_4l512w_c4_cod": 19, "solu_4l512w_wiki_finetun": 19, "solu_4l_v11_old": 19, "solu_6l768w_c4_cod": 19, "6l": [19, 27, 28], "solu_6l_v13_old": 19, "solu_8l1024w_c4_cod": 19, "8l": [19, 27, 28], "solu_8l_v21_old": 19, "qwen": [19, 28], "14b": [19, 28], "1_8b": 19, "qwen1": [19, 28], "5b": [19, 27, 28], "bigcod": 19, "santacod": [19, 28], "bigscienc": 19, "1b1": [19, 28], "1b7": [19, 28], "560m": [19, 28], "7b1": [19, 28], "distilgpt2": [19, 27], "distillgpt2": [19, 28], "distil": [19, 27], "facebook": 19, "xxl": 19, "30b": [19, 27, 28], "xxxl": 19, "xl": [19, 27, 28], "66b": [19, 27, 28], "xxxxl": 19, "gemma": [19, 28], "2b": [19, 28], "65b": [19, 28], "70b": [19, 28], "microsoft": 19, "phi": [19, 28], "1_5": [19, 28], "mistralai": 19, "8x7b": 19, "roneneldan": 19, "tinystori": 19, "1layer": 19, "21m": [19, 28], "28m": [19, 28], "2layer": 19, "33m": [19, 28], "3m": [19, 28], "8m": [19, 28], "instuct": 19, "stabilityai": 19, "stablelm": [19, 27, 28], "alpha": [19, 28], "x21": 19, "arwen": 19, "battlestar": 19, "x49": 19, "beren": 19, "caprica": 19, "x81": 19, "celebrimbor": 19, "darkmatt": 19, "x343": 19, "durin": 19, "eowyn": 19, "x777": 19, "expans": 19, "alias": 19, "non_hf_hosted_model_nam": 19, "offici": [19, 27], "convert_bloom_weight": 19, "convert_coder_weight": 19, "convert_mistral_weight": 19, "convert_mixtral_weight": 19, "convert_phi_weight": 19, "convert_qwen2_weight": 19, "convert_qwen_weight": 19, "get_checkpoint_label": [19, 27], "label_typ": 19, "get_num_params_of_pretrain": 19, "suffici": [19, 26], "get_pretrained_model_config": 19, "automodel": 19, "autoconfig": 19, "infrastructur": [19, 26, 27, 29], "ourselv": [20, 25, 27, 29], "previous_attention_mask": 20, "pos_so_far": 20, "append": [20, 26, 27], "prefix": 20, "append_attention_mask": 20, "new_token": 20, "freez": 20, "init_cach": 20, "unfreez": 20, "past_kei": 20, "jaxtyp": [20, 26, 27], "past_valu": 20, "new_kei": 20, "new_valu": 20, "init_cache_entri": 20, "structur": [21, 27], "generic_activation_patch": 21, "specialis": [21, 26], "introduc": [21, 26], "rome": [21, 26, 27], "baulab": 21, "shift": [21, 27], "corrupt": [21, 26, 27], "continu": [21, 26, 27], "iter": [21, 25, 26, 27], "localis": [21, 26, 27], "__from__": 21, "__to": 21, "__the": 21, "confid": [21, 26, 27], "intuit": [21, 26, 27], "diffus": [21, 26], "spread": [21, 26], "connect": [21, 26], "ultim": [21, 26], "engin": [21, 26, 27, 29], "least": [21, 27], "tend": [21, 27], "extrem": [21, 26, 27, 29], "eiffel": 21, "tower": 21, "pari": 21, "factual": [21, 26], "recal": [21, 26], "colosseum": 21, "anywher": 21, "corrupted_token": [21, 26, 27], "clean_cach": [21, 26, 27], "patching_metr": 21, "patch_sett": 21, "index_axis_nam": 21, "src_po": [21, 26], "dest_po": [21, 26, 27], "index_df": 21, "datafram": 21, "return_index_df": 21, "counterfactu": [21, 26, 27], "Then": 21, "index_to_act_nam": 21, "recov": [21, 26, 27], "diff": [21, 26], "corrupted_activ": 21, "chunk": 21, "fill": 21, "flatten": [21, 26, 27], "patched_output": 21, "get_act_patch_attn_head_all_pos_everi": 21, "patch_typ": 21, "get_act_patch_attn_head_by_pos_everi": 21, "get_act_patch_attn_head_k_all_po": 21, "corruptedactiv": 21, "patchedactiv": 21, "layer_head_vector_patch_sett": 21, "axisnam": 21, "get_act_patch_attn_head_k_by_po": 21, "layer_pos_head_vector_patch_sett": 21, "get_act_patch_attn_head_out_all_po": 21, "get_act_patch_attn_head_out_by_po": 21, "get_act_patch_attn_head_pattern_all_po": 21, "layer_head_pattern_patch_sett": 21, "get_act_patch_attn_head_pattern_by_po": 21, "layer_head_pos_pattern_patch_sett": 21, "get_act_patch_attn_head_pattern_dest_src_po": 21, "layer_head_dest_src_pos_pattern_patch_sett": 21, "get_act_patch_attn_head_q_all_po": 21, "get_act_patch_attn_head_q_by_po": 21, "get_act_patch_attn_head_v_all_po": 21, "get_act_patch_attn_head_v_by_po": 21, "get_act_patch_attn_out": 21, "layer_pos_patch_sett": 21, "get_act_patch_block_everi": 21, "get_act_patch_mlp_out": 21, "get_act_patch_resid_mid": 21, "get_act_patch_resid_pr": 21, "clean_activ": 21, "hookedtransformertrainconfig": 22, "num_epoch": 22, "001": 22, "momentum": 22, "max_grad_norm": 22, "weight_decai": 22, "optimizer_nam": 22, "adam": 22, "warmup_step": 22, "save_everi": 22, "save_dir": 22, "wandb": 22, "wandb_project_nam": 22, "print_everi": 22, "max_step": 22, "hyperparamet": [22, 25], "epoch": 22, "rate": [22, 27], "decai": 22, "warmup": 22, "wandb_project": 22, "termin": 22, "assist": 24, "get_device_for_block_index": 24, "target": 24, "move_to_and_update_config": 24, "vari": [25, 26], "throughout": [25, 27], "locallyoverridendefault": 25, "restor": 25, "overriden": 25, "input_slic": 25, "syntax": [25, 26, 27], "reduc": [25, 26, 27], "extra": 25, "leav": [25, 27], "elif": 25, "1d": 25, "sliceinput": 25, "valueerror": 25, "abov": [25, 26, 27], "max_ctx": 25, "int32": 25, "calc_fan_in_and_fan_out": 25, "fan": 25, "d_out": 25, "d_in": 25, "composition_scor": 25, "broadcast_dim": 25, "leading_dims_left_and_right": 25, "download_file_from_hf": 25, "repo_nam": 25, "file_nam": 25, "subfold": 25, "home": 25, "runner": 25, "force_is_torch": 25, "json": 25, "pth": 25, "extens": [25, 26], "layer_typ": [25, 26], "shorthand": 25, "feedback": [25, 26, 27, 29], "loop": [25, 26, 27, 29], "hack": [25, 27], "stuff": [25, 27], "readabl": 25, "digit": [25, 27], "word": [25, 26, 27], "k6": 25, "scale4ln1": 25, "appear": [25, 27], "distinguish": [25, 26], "hook_k": [25, 27], "hook_pr": [25, 27], "27": [25, 26, 27], "hook_norm": [25, 27], "pre5": 25, "get_attention_mask": 25, "leftmost": 25, "rightmost": 25, "consid": 25, "get_cumsum_along_dim": 25, "dataset_nam": 25, "explor": [25, 27], "000": [25, 27], "enorm": [25, 27], "100gb": 25, "2tb": 25, "effort": [25, 26], "dataload": 25, "fanci": 25, "data_dir": 25, "approx": [25, 26, 27], "co": 25, "ton": [25, 29], "divers": [25, 26, 27], "coloss": 25, "crawl": 25, "bigger": 25, "c4_code": 25, "friendli": 25, "22m": [25, 27], "5m": 25, "20220301": 25, "en": [25, 27], "get_devic": [25, 26, 27], "get_input_with_manually_prepended_bo": 25, "autotoken": 25, "get_nested_attr": 25, "obj": 25, "attr_str": 25, "retriev": 25, "nest": 25, "hierarchi": 25, "get_offset_position_id": 25, "offset": [25, 26, 27], "get_tokenizer_with_bo": 25, "Such": [25, 26], "llamatoken": 25, "get_tokens_with_bos_remov": 25, "init_kaiming_normal_": 25, "nonlinear": 25, "std": 25, "init_kaiming_uniform_": 25, "init_xavier_normal_": 25, "init_xavier_uniform_": 25, "is_lower_triangular": 25, "is_squar": 25, "keep_single_column": 25, "col_nam": 25, "lm_accuraci": 25, "seq_len": [25, 26, 27], "altern": 25, "override_or_use_default_valu": 25, "default_flag": 25, "print_gpu_mem": 25, "step_nam": 25, "repeat_along_head_dimens": 25, "clone_tensor": 25, "sample_logit": 25, "final_logit": [25, 26], "vocab_s": 25, "high": [25, 26, 27], "argmaxi": 25, "90": 25, "renormalis": 25, "mutual": 25, "neither": [25, 26], "input_token": 25, "todo": 25, "edg": 25, "randn": [25, 27], "uniqu": 25, "return_count": 25, "set_nested_attr": 25, "prepend_space_to_answ": 25, "eleph": 25, "endoftext": [25, 26, 27], "14": [25, 26, 27], "51": [25, 27], "0th": [25, 26], "59": [25, 27, 28], "ground": [25, 26], "1th": [25, 26], "41": [25, 27], "18": [25, 26, 27, 28], "tree": 25, "2th": [25, 26], "3th": [25, 26], "45": [25, 27], "car": 25, "4th": [25, 26], "13": [25, 26, 27], "92": [25, 26], "55": [25, 26, 27], "river": 25, "5th": [25, 26], "79": 25, "25": [25, 26, 27, 28], "street": 25, "6th": [25, 26], "77": 25, "21": [25, 26, 27], "7th": [25, 26], "75": 25, "hill": 25, "8th": [25, 26], "swing": 25, "9th": [25, 26], "46": [25, 27], "61": [25, 28], "park": [25, 26], "ever": 25, "improv": [25, 26, 27], "to_numpi": [25, 26, 27], "tokenize_and_concaten": 25, "max_length": 25, "column_nam": 25, "num_proc": 25, "eo": [25, 27], "reshap": [25, 26], "____": 25, "drop": [25, 27], "faster": [25, 26, 27], "parallelis": [25, 27], "chop": 25, "20": [25, 26, 27, 28], "privileg": 25, "earli": [25, 27], "cnn": [25, 27], "bos_token_id": 25, "swap": [25, 26], "regardless": 25, "runtim": [26, 27], "hardwar": [26, 27], "acceler": [26, 27], "tabl": [26, 27], "pane": [26, 27], "sidebar": [26, 27], "navig": [26, 27], "vscode": [26, 27], "outlin": 26, "tab": 26, "section": [26, 27], "dropdown": [26, 27], "arrow": [26, 27], "page": [26, 27], "ctrl": [26, 27], "repo": 26, "in_colab": [26, 27], "circuitsvi": [26, 27], "node": [26, 27], "curl": [26, 27], "fssl": [26, 27], "deb": [26, 27], "nodesourc": [26, 27], "setup_16": [26, 27], "sudo": [26, 27], "bash": [26, 27], "apt": [26, 27], "nodej": [26, 27], "noqa": [26, 27], "ipython": [26, 27], "get_ipython": [26, 27], "ip": [26, 27], "extension_manag": [26, 27], "autoreload": [26, 27], "functool": [26, 27], "plotli": [26, 27], "express": [26, 27], "px": [26, 27], "pio": [26, 27], "attention_head": 26, "fancy_einsum": [26, 27], "ifram": 26, "differenti": [26, 27], "simplic": 26, "imshow": [26, 27], "color_continuous_midpoint": [26, 27], "color_continuous_scal": [26, 27], "rdbu": [26, 27], "scatter": [26, 27], "xaxi": [26, 27], "yaxi": [26, 27], "caxi": [26, 27], "color": [26, 27], "principl": [26, 27, 29], "fun": [26, 27, 29], "ml": [26, 27, 29], "gap": [26, 27, 29], "feel": [26, 27, 29], "plai": [26, 27, 29], "flow": [26, 27, 29], "goal": [26, 27, 29], "toolkit": [26, 27], "stylist": 26, "slowli": 26, "convei": 26, "simpl": [26, 27], "tag": 26, "asid": 26, "flavour": 26, "weed": 26, "star": 26, "tagexampl": 26, "capabl": [26, 27], "interview": [26, 27], "kevin": [26, 27], "wang": 26, "twitter": 26, "thread": 26, "overview": 26, "bottl": [26, 27], "milk": [26, 27], "26": [26, 27], "Their": 26, "skimp": 26, "rigour": 26, "suggest": 26, "evid": 26, "our": [26, 27], "80m": [26, 27], "simplif": 26, "nbval_ignore_output": [26, 27], "stabl": 26, "example_prompt": 26, "example_answ": 26, "39": [26, 27], "lt": [26, 27], "gt": [26, 27], "09": [26, 27], "70": 26, "07": [26, 27], "15": [26, 27], "38": [26, 27], "67": 26, "35": [26, 27], "54": [26, 27], "11": [26, 27, 28], "84": [26, 27], "73": 26, "hi": [26, 27], "06": 26, "her": [26, 27], "74": 26, "52": [26, 27, 28], "49": [26, 27], "jesu": 26, "97": 26, "42": [26, 27], "him": 26, "subword": 26, "frequent": 26, "substr": [26, 27], "massiv": [26, 27], "headach": 26, "annoi": [26, 27], "total": [26, 27], "devot": 26, "sensibl": 26, "later": [26, 27], "wherev": 26, "flesh": 26, "prompt_format": 26, "jame": 26, "dan": 26, "sid": 26, "appl": 26, "martin": 26, "ami": 26, "drink": 26, "correct_token": 26, "insert": 26, "easiest": 26, "filler": 26, "newlin": 26, "intellig": 26, "complic": 26, "adjust": [26, 27], "aggreg": 26, "original_logit": 26, "upon": 26, "subject": [26, 27], "logits_to_ave_logit_diff": 26, "per_prompt": 26, "answer_logit": 26, "gather": 26, "answer_logit_diff": 26, "detach": [26, 27], "decim": [26, 27], "original_average_logit_diff": 26, "3370": 26, "2020": 26, "7090": 26, "7970": 26, "7200": 26, "2810": 26, "6010": 26, "7670": 26, "552": 26, "put": [26, 27], "33": [26, 27], "dive": 26, "spend": [26, 27], "engag": 26, "decent": [26, 27], "hypothes": 26, "cheat": [26, 27], "hypothesi": 26, "scienc": 26, "belief": 26, "trap": 26, "confus": [26, 27], "flounder": 26, "dogmat": 26, "Being": 26, "overconfid": 26, "unwil": 26, "realiti": 26, "contradict": 26, "flinch": 26, "disconfirm": 26, "imagin": 26, "focu": 26, "primit": 26, "nearbi": 26, "came": 26, "trigram": 26, "symmetri": 26, "earlier": [26, 27], "cancel": 26, "inhibit": 26, "spoiler": 26, "abl": [26, 27], "simplist": 26, "background": 26, "central": 26, "importantli": [26, 27], "perfectli": [26, 27], "final_residual_stream": 26, "motiv": 26, "eleg": 26, "particularli": 26, "aspect": 26, "nicer": 26, "inde": 26, "log_prob": 26, "log_softmax": 26, "logsumexp": 26, "isol": 26, "decid": 26, "pronoun": 26, "person": 26, "refin": 26, "happen": [26, 27], "rel": 26, "friendlier": 26, "almost": 26, "answer_residual_direct": 26, "logit_diff_direct": 26, "account": 26, "w_u_fold": 26, "layer_norm": 26, "unigram": [26, 27], "statist": [26, 27], "occur": [26, 27], "opposit": 26, "hook_normalis": 26, "sub_layer_typ": 26, "final_token_residual_stream": 26, "scaled_final_token_residual_stream": 26, "average_logit_diff": 26, "residual_stack_to_logit_diff": 26, "scaled_residual_stack": 26, "fascinatingli": 26, "utterli": 26, "unabl": 26, "hover": [26, 27], "n_pre": 26, "n_mid": 26, "n_post": 26, "middl": [26, 27], "accumulated_residu": 26, "logit_lens_logit_diff": 26, "arang": 26, "hover_nam": [26, 27], "terminologi": 26, "overload": 26, "kth": 26, "again": 26, "per_layer_residu": 26, "per_layer_logit_diff": 26, "independ": [26, 27, 29], "overal": 26, "l9h6": 26, "l9h9": 26, "l10h7": 26, "l11h10": 26, "harm": 26, "discuss": 26, "strongli": 26, "observ": [26, 27], "144": 26, "hand": [26, 27], "claim": 26, "surpris": 26, "7x": 26, "per_head_residu": 26, "per_head_logit_diff": 26, "rearrang": 26, "weren": 26, "alan": [26, 27], "coonei": [26, 27], "illustr": [26, 27], "mistak": 26, "mayb": [26, 27], "sai": [26, 27], "period": [26, 27], "summari": 26, "sole": 26, "17": [26, 27], "visualize_attention_pattern": 26, "local_cach": 26, "local_token": 26, "max_width": 26, "700": 26, "isinst": 26, "batch_index": 26, "combin": [26, 27], "attention_head_nam": 26, "show_cod": 26, "title_html": 26, "br": 26, "div": 26, "width": [26, 27], "simpli": 26, "top_positive_logit_attr_head": 26, "positive_html": 26, "top_negative_logit_attr_head": 26, "negative_html": 26, "conceptu": 26, "clearli": 26, "compos": [26, 27], "ideal": [26, 27], "david": [26, 27], "bau": [26, 27], "meng": [26, 27], "trace": [26, 27], "anim": 26, "piec": 26, "lai": 26, "pro": 26, "con": 26, "Or": 26, "bake": 26, "claus": 26, "tack": 26, "gaussian": 26, "nois": 26, "beforehand": 26, "19": [26, 27], "corrupted_prompt": [26, 27], "corrupted_logit": [26, 27], "corrupted_cach": 26, "corrupted_average_logit_diff": 26, "temporarili": [26, 27], "patch_residual_compon": 26, "corrupted_residual_compon": 26, "normalize_patched_logit_diff": 26, "patched_logit_diff": [26, 27], "wors": [26, 27], "patched_residual_stream_diff": 26, "hook_fn": 26, "patched_logit": [26, 27], "abus": 26, "prompt_position_label": 26, "tok": 26, "_": [26, 27], "enumer": [26, 27], "reus": 26, "23": [26, 27], "patched_attn_diff": 26, "patched_mlp_diff": 26, "patched_attn_logit": 26, "patched_attn_logit_diff": 26, "patched_mlp_logit": 26, "patched_mlp_logit_diff": 26, "late": [26, 27], "contrast": 26, "statement": 26, "mlp0": 26, "destroi": 26, "guess": 26, "frame": 26, "unprincipl": 26, "invers": [26, 27], "plausibli": 26, "dedic": 26, "overcom": 26, "love": 26, "someon": 26, "That": 26, "patch_head_vector": 26, "corrupted_head_vector": 26, "patched_head_z_diff": 26, "l8h6": 26, "l8h10": 26, "l7h9": 26, "l5h5": 26, "l6h9": 26, "l3h0": 26, "semi": 26, "disentangl": 26, "familiar": 26, "28": [26, 27, 28], "patched_head_v_diff": 26, "heatmap": 26, "29": [26, 27], "against": 26, "lesson": 26, "30": [26, 27, 28], "head_label": 26, "range_x": 26, "range_i": 26, "31": [26, 27], "patch_head_pattern": 26, "corrupted_head_pattern": 26, "patched_head_attn_diff": 26, "32": [26, 27, 28], "reconsolid": 26, "At": 26, "transit": 26, "extend": 26, "l7h3": 26, "specul": 26, "mysteri": [26, 27], "top_heads_by_output_patch": 26, "first_mid_lay": 26, "first_late_lay": 26, "early_head": 26, "mid_head": 26, "logical_and": 26, "late_head": 26, "diagram": 26, "l1h2": 26, "latest": 26, "definit": 26, "priori": 26, "stroke": 26, "didn": 26, "bracket": 26, "minor": 26, "serv": [26, 27], "particip": 26, "behav": 26, "l5h0": 26, "had": [26, 27], "wrote": [26, 27, 29], "whole": [26, 27], "overkil": 26, "simpler": 26, "repurpos": 26, "machineri": 26, "life": [26, 27], "built": 26, "34": [26, 27], "example_text": [26, 27], "seek": 26, "machin": [26, 27], "example_repeated_text": 26, "example_repeated_token": 26, "example_repeated_logit": 26, "example_repeated_cach": 26, "induction_head_label": 26, "81": 26, "65": 26, "800": 26, "accord": 26, "wildli": 26, "mark": [26, 27], "success": 26, "characteris": 26, "superfici": 26, "boost": [26, 27], "anti": 26, "suppress": [26, 27], "pick": [26, 27], "signal": 26, "hook_": 26, "hook_attn": 26, "token_po": 26, "previous": 26, "metadata": 26, "36": [26, 27, 28], "prev_token_scor": 26, "prev_token_hook": 26, "dim1": [26, 27], "dim2": [26, 27], "duplicate_token_scor": 26, "duplicate_token_hook": 26, "induction_scor": [26, 27], "induction_hook": 26, "manual_se": [26, 27], "original_token": 26, "randint": [26, 27], "20000": [26, 27], "repeated_token": [26, 27], "pattern_filt": 26, "act_nam": [26, 27], "endswith": [26, 27], "hook_pattern": [26, 27], "0390": 26, "0310": 26, "1890": 26, "1720": 26, "0680": 26, "1570": 26, "0210": 26, "4820": 26, "0030": 26, "1320": 26, "0050": 26, "0020": 26, "0090": 26, "0040": 26, "0010": 26, "instantli": 26, "37": [26, 27], "bit": [26, 27], "seen": [26, 27], "proof": 26, "mosaic": 26, "40": [26, 27, 28], "fascin": 26, "knock": 26, "naiv": [26, 27], "convers": 26, "flaw": 26, "knockout": 26, "send": 26, "redund": 26, "job": 26, "underestim": 26, "57": [26, 27], "99": [26, 27], "hook_z": [26, 27], "top_name_mov": 26, "top_name_mover_lay": 26, "top_name_mover_head": 26, "ablate_top_head_hook": 26, "ablated_logit": 26, "ablated_cach": 26, "2f": [26, 27], "l10h10": 26, "margin": 26, "obvious": 26, "per_head_ablated_residu": 26, "per_head_ablated_logit_diff": 26, "04": [26, 27], "uniformli": [26, 27], "042": 26, "5200": 26, "4700": 26, "8200": 26, "5100": 26, "2600": 26, "1800": 26, "4300": 26, "5700": 26, "3500": 26, "2900": 26, "6800": 26, "4900": 26, "8700": 26, "4200": 26, "reader": [26, 27], "becom": [26, 27], "gentler": 27, "tip": 27, "development_mod": 27, "in_github": 27, "getenv": 27, "github_act": 27, "render": 27, "argh": 27, "notebook_connect": 27, "cv": 27, "hello": 27, "auto": 27, "autograd": 27, "grad_mod": 27, "0x7f097bd3cd10": 27, "todai": [27, 29], "speak": [27, 29], "human": [27, 29], "palm": [27, 29], "nor": [27, 29], "offend": [27, 29], "jump": 27, "anthrop": [27, 29], "team": [27, 29], "got": [27, 29], "frustrat": [27, 29], "deepspe": [27, 29], "littl": [27, 29], "industri": [27, 29], "heavili": [27, 29], "credit": [27, 29], "nelson": [27, 29], "elhag": [27, 29], "chri": [27, 29], "olah": [27, 29], "model_description_text": 27, "hyper": 27, "1758": 27, "box": 27, "On": 27, "insid": 27, "kinda": 27, "gpt2_cache_no_batch_dim": 27, "gpt2_cach": 27, "gpt2_text": 27, "summar": 27, "supervis": 27, "taskspecif": 27, "gpt2_token": 27, "gpt2_logit": 27, "lock": 27, "grid": 27, "gpt2_str_token": 27, "neural": 27, "system": 27, "perspect": 27, "surgic": 27, "power": 27, "surround": 27, "current_activation_valu": 27, "new_activation_valu": 27, "substitut": 27, "relationship": 27, "underr": 27, "incredibli": 27, "janki": 27, "shamelessli": 27, "probepoint": 27, "qualiti": 27, "head_ablation_hook": 27, "layer_to_abl": 27, "head_index_to_abl": 27, "original_loss": 27, "ablated_loss": 27, "3f": 27, "999": 27, "453": 27, "stai": 27, "clean_prompt": 27, "clean_token": 27, "logits_to_logit_diff": 27, "correct_answ": 27, "incorrect_answ": 27, "correct_index": 27, "incorrect_index": 27, "clean_logit": 27, "clean_logit_diff": 27, "corrupted_logit_diff": 27, "276": 27, "738": 27, "residual_stream_patching_hook": 27, "clean_resid_pr": 27, "num_posit": 27, "ioi_patching_result": 27, "temp_hook_fn": 27, "ish": 27, "token_label": 27, "workflow": 27, "michael": 27, "jordan": 27, "surnam": 27, "terribl": 27, "halfwai": 27, "input_tensor": 27, "random_token": 27, "repeated_logit": 27, "correct_log_prob": 27, "loss_by_posit": 27, "manipul": 27, "hook_funct": 27, "induction_score_stor": 27, "induction_score_hook": 27, "induction_strip": 27, "pattern_hook_names_filt": 27, "highli": 27, "stripe": 27, "induction_head_lay": 27, "induction_head_index": 27, "single_random_sequ": 27, "repeated_random_sequ": 27, "visualize_pattern_hook": 27, "3d": 27, "four": 27, "300m": 27, "soon": 27, "distilgpt": 27, "distilgpt2_induction_score_stor": 27, "classic": 27, "openai": 27, "85m": [27, 28], "700m": 27, "22b": 27, "300b": 27, "180b": 27, "600": 27, "265": 27, "108m": 27, "bookscorpu": 27, "free": 27, "512": [27, 28], "tractabl": 27, "motif": 27, "80": [27, 28], "shuffl": 27, "scan": 27, "hope": 27, "40m": 27, "100m": 27, "200m": 27, "340m": [27, 28], "older": 27, "15b": 27, "13m": [27, 28], "digress": 27, "usefulli": 27, "variengien": 27, "websit": 27, "adapt": 27, "cleantransformerdemo": 27, "new_activ": 27, "old_activ": 27, "remind": 27, "50267": 27, "named_paramet": 27, "startswith": 27, "fallback": 27, "spam": 27, "dest_posit": 27, "brown": 27, "fox": 27, "lazi": 27, "dog": 27, "num": 27, "print_name_shape_hook_funct": 27, "not_in_late_block_filt": 27, "hook_q": 27, "hook_v": 27, "hook_attn_scor": 27, "hook_attn_out": 27, "hook_resid_mid": 27, "hook_post": 27, "hook_mlp_out": 27, "hook_resid_post": 27, "preconcept": 27, "pain": 27, "overhead": 27, "elementwis": 27, "consequ": 27, "rare": 27, "dramat": 27, "degre": 27, "punctuat": 27, "ass": 27, "randomredditor": 27, "unembed_bia": 27, "bias_valu": 27, "bias_indic": 27, "sort": 27, "repr": 27, "03": 27, "98": 27, "68": 27, "48": [27, 28], "47": 27, "72": [27, 28], "44": [27, 28], "82": 27, "\u30b5\u30fc\u30c6\u30a3": 27, "83": 27, "x18": 27, "x14": 27, "\u9f8d": 27, "x1b": 27, "x05": 27, "x00": 27, "x06": 27, "x07": 27, "x0c": 27, "x02": 27, "oreandonlin": 27, "x11": 27, "x10": 27, "favour": 27, "6x": 27, "john_bia": 27, "mary_bia": 27, "4f": 27, "exp": 27, "8995": 27, "6034": 27, "6550x": 27, "finit": 27, "invert": 27, "de": 27, "uncommon": 27, "iz": 27, "charact": 27, "example_text_str_token": 27, "example_text_token": 27, "50256": 27, "464": 27, "717": 27, "1517": 27, "345": 27, "761": 27, "284": 27, "3785": 27, "503": 27, "318": 27, "1635": 27, "4919": 27, "1243": 27, "389": 27, "11241": 27, "1143": 27, "4600": 27, "19849": 27, "1462": 27, "62": 27, "2536": 27, "482": 27, "641": 27, "63": 27, "30778": 27, "257": 27, "4731": 27, "656": 27, "262": 27, "16326": 27, "292": 27, "1351": 27, "286": 27, "850": 27, "37336": 27, "25666": 27, "290": 27, "523": 27, "8781": 27, "7301": 27, "644": 27, "2420": 27, "3073": 27, "588": 27, "1675": 27, "10176": 27, "428": 27, "1309": 27, "338": 27, "779": 27, "340": 27, "319": 27, "7322": 27, "signifi": 27, "example_multi_text": 27, "cat": 27, "sat": 27, "mat": 27, "example_multi_text_token": 27, "3797": 27, "3332": 27, "2603": 27, "1107": 27, "1327": 27, "th": 27, "cat_text": 27, "cat_logit": 27, "cat_prob": 27, "capital_the_token_index": 27, "ascii": 27, "squeez": 27, "annoy": 27, "arithmet": 27, "impress": 27, "2342": 27, "2017": 27, "21445": 27, "1000000": 27, "999999": 27, "214": 27, "000000": 27, "9999": 27, "tim": 27, "ne": 27, "el": 27, "messier": 27, "takeawai": 27, "unexpect": 27, "notic": 27, "trip": 27, "confusingli": 27, "forth": 27, "ioi_logits_with_bo": 27, "clair": 27, "mary_logit_with_bo": 27, "claire_logit_with_bo": 27, "ioi_logits_without_bo": 27, "mary_logit_without_bo": 27, "claire_logit_without_bo": 27, "754": 27, "782": 27, "air": 27, "understood": 27, "requisit": 27, "attention_scor": 27, "ab_factor": 27, "9105": 27, "linalg": 27, "eig": 27, "2877e": 27, "00": 27, "8626e": 27, "3121e": 27, "9038e": 27, "08": 27, "1527e": 27, "2877": 27, "3121": 27, "3126e": 27, "3963e": 27, "2029e": 27, "7690e": 27, "2164e": 27, "3126": 27, "3963": 27, "smallest": 27, "300": 27, "abc_factor": 27, "unfactor": 27, "160": 27, "0830": 27, "43": 27, "ab_unfactor": 27, "isclos": 27, "subspac": 27, "coincid": 27, "assert": 27, "negat": 27, "proxi": 27, "lambda_i": 27, "ov_circuit_all_head": 27, "ov_circuit_all_heads_eigenvalu": 27, "complex64": 27, "ov_copying_scor": 27, "zmax": 27, "zmin": 27, "l11h11": 27, "imag": 27, "imaginari": 27, "full_ov_circuit": 27, "full_ov_circuit_eigenvalu": 27, "full_ov_copying_scor": 27, "interestingli": 27, "correl": 27, "outlier": 27, "thank": 27, "ansh": 27, "radhakrishnan": 27, "establish": 27, "53": 27, "presid": 27, "barack": 27, "obama": 27, "caught": 27, "embarrass": 27, "scandal": 27, "nthe": 27, "financi": 27, "said": 27, "he": 27, "talk": 27, "wife": 27, "chelsea": 27, "she": 27, "woman": 27, "lightweight": 27, "bundl": 27, "squarethenadd": 27, "hook_squar": 27, "twolayermodel": 27, "layer1": 27, "layer2": 27, "hook_in": 27, "hook_mid": 27, "hook_out": 27, "x_in": 27, "x_mid": 27, "x_out": 27, "model_out": 27, "cache_object": 27, "780": 27, "784": 27, "56": [27, 28], "set_to_zero_hook": 27, "num_checkpoint": 27, "piecewis": 27, "schedul": 27, "crash": 27, "11b": [27, 28], "centr": 27, "hoc": 27, "count": 27, "checkpoint_label": 27, "log_i": 27, "marker": 27, "brief": 27, "suddenli": 27, "500": 27, "visibl": 27, "bump": 27, "curv": 27, "briefli": 27, "deliber": 27, "justic": 27, "chosen": 27, "60": [27, 28], "500m": 27, "58": 27, "arbitrarili": 27, "fast": 27, "checkpoint_indic": 27, "checkpointed_model": 27, "tokens_trained_on": 27, "model_for_this_checkpoint": 27, "tokens_seen_for_this_checkpoint": 27, "induction_loss_for_this_checkpoint": 27, "contextualis": 27, "strategi": 27, "95": 27, "log_x": 27, "302m": 28, "4096": 28, "708m": 28, "1280": 28, "5120": 28, "1600": 28, "6400": 28, "42m": 28, "2048": 28, "50272": 28, "8192": 28, "2560": 28, "10240": 28, "128": 28, "16384": 28, "20480": 28, "7168": 28, "28672": 28, "9216": 28, "36864": 28, "50400": 28, "6144": 28, "50432": 28, "96": 28, "24576": 28, "2m": 28, "50304": 28, "7m": 28, "805m": 28, "50688": 28, "50278": 28, "736": 28, "2944": 28, "101m": 28, "197m": 28, "1536": 28, "48262": 28, "4m": 28, "0m": 28, "50277": 28, "524k": 28, "50259": 28, "32000": 28, "11008": 28, "13824": 28, "32b": 28, "6656": 28, "17920": 28, "22016": 28, "78b": 28, "32016": 28, "25m": 28, "28996": 28, "393k": 28, "6m": 28, "14336": 28, "47b": 28, "250880": 28, "679m": 28, "0b": 28, "49280": 28, "151936": 28, "5504": 28, "152064": 28, "13696": 28, "308m": 28, "2816": 28, "6912": 28, "51200": 28, "256000": 28, "64000": 28, "39b": 28, "formerli": 29, "transfer": 29}, "objects": {"transformer_lens": [[9, 0, 0, "-", "ActivationCache"], [10, 0, 0, "-", "FactoredMatrix"], [11, 0, 0, "-", "HookedEncoder"], [12, 0, 0, "-", "HookedTransformer"], [13, 0, 0, "-", "HookedTransformerConfig"], [14, 0, 0, "-", "SVDInterpreter"], [15, 0, 0, "-", "components"], [16, 0, 0, "-", "evals"], [17, 0, 0, "-", "head_detector"], [18, 0, 0, "-", "hook_points"], [19, 0, 0, "-", "loading_from_pretrained"], [20, 0, 0, "-", "past_key_value_caching"], [21, 0, 0, "-", "patching"], [22, 0, 0, "-", "train"], [25, 0, 0, "-", "utils"]], "transformer_lens.ActivationCache": [[9, 1, 1, "", "ActivationCache"]], "transformer_lens.ActivationCache.ActivationCache": [[9, 2, 1, "", "accumulated_resid"], [9, 2, 1, "", "apply_ln_to_stack"], [9, 2, 1, "", "apply_slice_to_batch_dim"], [9, 2, 1, "", "compute_head_results"], [9, 2, 1, "", "decompose_resid"], [9, 2, 1, "", "get_full_resid_decomposition"], [9, 2, 1, "", "get_neuron_results"], [9, 2, 1, "", "items"], [9, 2, 1, "", "keys"], [9, 2, 1, "", "logit_attrs"], [9, 2, 1, "", "remove_batch_dim"], [9, 2, 1, "", "stack_activation"], [9, 2, 1, "", "stack_head_results"], [9, 2, 1, "", "stack_neuron_results"], [9, 2, 1, "", "to"], [9, 2, 1, "", "toggle_autodiff"], [9, 2, 1, "", "values"]], "transformer_lens.FactoredMatrix": [[10, 1, 1, "", "FactoredMatrix"]], "transformer_lens.FactoredMatrix.FactoredMatrix": [[10, 3, 1, "", "AB"], [10, 3, 1, "", "BA"], [10, 3, 1, "", "S"], [10, 3, 1, "", "T"], [10, 3, 1, "", "U"], [10, 3, 1, "", "Vh"], [10, 2, 1, "", "collapse_l"], [10, 2, 1, "", "collapse_r"], [10, 3, 1, "", "eigenvalues"], [10, 2, 1, "", "get_corner"], [10, 2, 1, "", "make_even"], [10, 3, 1, "", "ndim"], [10, 2, 1, "", "norm"], [10, 3, 1, "", "pair"], [10, 2, 1, "", "svd"], [10, 2, 1, "", "unsqueeze"]], "transformer_lens.HookedEncoder": [[11, 1, 1, "", "HookedEncoder"]], "transformer_lens.HookedEncoder.HookedEncoder": [[11, 3, 1, "", "OV"], [11, 3, 1, "", "QK"], [11, 3, 1, "", "W_E"], [11, 3, 1, "", "W_E_pos"], [11, 3, 1, "", "W_K"], [11, 3, 1, "", "W_O"], [11, 3, 1, "", "W_Q"], [11, 3, 1, "", "W_U"], [11, 3, 1, "", "W_V"], [11, 3, 1, "", "W_in"], [11, 3, 1, "", "W_out"], [11, 3, 1, "", "W_pos"], [11, 2, 1, "", "all_head_labels"], [11, 3, 1, "", "b_K"], [11, 3, 1, "", "b_O"], [11, 3, 1, "", "b_Q"], [11, 3, 1, "", "b_U"], [11, 3, 1, "", "b_V"], [11, 3, 1, "", "b_in"], [11, 3, 1, "", "b_out"], [11, 2, 1, "", "cpu"], [11, 2, 1, "", "cuda"], [11, 2, 1, "", "forward"], [11, 2, 1, "", "from_pretrained"], [11, 2, 1, "", "mps"], [11, 2, 1, "", "run_with_cache"], [11, 2, 1, "", "to"]], "transformer_lens.HookedTransformer": [[12, 1, 1, "", "HookedTransformer"], [12, 1, 1, "", "Output"]], "transformer_lens.HookedTransformer.HookedTransformer": [[12, 3, 1, "", "OV"], [12, 3, 1, "", "QK"], [12, 3, 1, "", "W_E"], [12, 3, 1, "", "W_E_pos"], [12, 3, 1, "", "W_K"], [12, 3, 1, "", "W_O"], [12, 3, 1, "", "W_Q"], [12, 3, 1, "", "W_U"], [12, 3, 1, "", "W_V"], [12, 3, 1, "", "W_gate"], [12, 3, 1, "", "W_in"], [12, 3, 1, "", "W_out"], [12, 3, 1, "", "W_pos"], [12, 2, 1, "", "__init__"], [12, 2, 1, "", "accumulated_bias"], [12, 2, 1, "", "all_composition_scores"], [12, 2, 1, "", "all_head_labels"], [12, 3, 1, "", "b_K"], [12, 3, 1, "", "b_O"], [12, 3, 1, "", "b_Q"], [12, 3, 1, "", "b_U"], [12, 3, 1, "", "b_V"], [12, 3, 1, "", "b_in"], [12, 3, 1, "", "b_out"], [12, 2, 1, "", "center_unembed"], [12, 2, 1, "", "center_writing_weights"], [12, 2, 1, "", "check_hooks_to_add"], [12, 2, 1, "", "cpu"], [12, 2, 1, "", "cuda"], [12, 2, 1, "", "fold_layer_norm"], [12, 2, 1, "", "fold_value_biases"], [12, 2, 1, "", "forward"], [12, 2, 1, "", "from_pretrained"], [12, 2, 1, "", "from_pretrained_no_processing"], [12, 2, 1, "", "generate"], [12, 2, 1, "", "get_token_position"], [12, 2, 1, "", "init_weights"], [12, 2, 1, "", "input_to_embed"], [12, 4, 1, "", "ln_final"], [12, 2, 1, "", "load_and_process_state_dict"], [12, 2, 1, "", "load_sample_training_dataset"], [12, 2, 1, "", "loss_fn"], [12, 2, 1, "", "move_model_modules_to_device"], [12, 2, 1, "", "mps"], [12, 2, 1, "", "process_weights_"], [12, 2, 1, "", "refactor_factored_attn_matrices"], [12, 2, 1, "", "run_with_cache"], [12, 2, 1, "", "sample_datapoint"], [12, 2, 1, "", "set_tokenizer"], [12, 2, 1, "", "set_use_attn_in"], [12, 2, 1, "", "set_use_attn_result"], [12, 2, 1, "", "set_use_hook_mlp_in"], [12, 2, 1, "", "set_use_split_qkv_input"], [12, 2, 1, "", "to"], [12, 2, 1, "", "to_single_str_token"], [12, 2, 1, "", "to_single_token"], [12, 2, 1, "", "to_str_tokens"], [12, 2, 1, "", "to_string"], [12, 2, 1, "", "to_tokens"], [12, 2, 1, "", "tokens_to_residual_directions"]], "transformer_lens.HookedTransformer.Output": [[12, 4, 1, "", "logits"], [12, 4, 1, "", "loss"]], "transformer_lens.HookedTransformerConfig": [[13, 1, 1, "", "HookedTransformerConfig"]], "transformer_lens.HookedTransformerConfig.HookedTransformerConfig": [[13, 4, 1, "", "act_fn"], [13, 4, 1, "", "attention_dir"], [13, 4, 1, "", "attn_only"], [13, 4, 1, "", "attn_types"], [13, 4, 1, "", "checkpoint_index"], [13, 4, 1, "", "checkpoint_label_type"], [13, 4, 1, "", "checkpoint_value"], [13, 4, 1, "", "d_head"], [13, 4, 1, "", "d_mlp"], [13, 4, 1, "", "d_model"], [13, 4, 1, "", "d_vocab"], [13, 4, 1, "", "d_vocab_out"], [13, 4, 1, "", "default_prepend_bos"], [13, 4, 1, "", "device"], [13, 4, 1, "", "dtype"], [13, 4, 1, "", "eps"], [13, 4, 1, "", "experts_per_token"], [13, 4, 1, "", "final_rms"], [13, 4, 1, "", "from_checkpoint"], [13, 2, 1, "", "from_dict"], [13, 4, 1, "", "gated_mlp"], [13, 4, 1, "", "init_mode"], [13, 4, 1, "", "init_weights"], [13, 4, 1, "", "initializer_range"], [13, 4, 1, "", "model_name"], [13, 4, 1, "", "n_ctx"], [13, 4, 1, "", "n_devices"], [13, 4, 1, "", "n_heads"], [13, 4, 1, "", "n_key_value_heads"], [13, 4, 1, "", "n_layers"], [13, 4, 1, "", "n_params"], [13, 4, 1, "", "normalization_type"], [13, 4, 1, "", "num_experts"], [13, 4, 1, "", "original_architecture"], [13, 4, 1, "", "parallel_attn_mlp"], [13, 4, 1, "", "positional_embedding_type"], [13, 4, 1, "", "post_embedding_ln"], [13, 4, 1, "", "rotary_adjacent_pairs"], [13, 4, 1, "", "rotary_base"], [13, 4, 1, "", "rotary_dim"], [13, 4, 1, "", "scale_attn_by_inverse_layer_idx"], [13, 4, 1, "", "seed"], [13, 2, 1, "", "set_seed_everywhere"], [13, 2, 1, "", "to_dict"], [13, 4, 1, "", "tokenizer_name"], [13, 4, 1, "", "tokenizer_prepends_bos"], [13, 4, 1, "", "trust_remote_code"], [13, 4, 1, "", "use_attn_in"], [13, 4, 1, "", "use_attn_result"], [13, 4, 1, "", "use_attn_scale"], [13, 4, 1, "", "use_hook_mlp_in"], [13, 4, 1, "", "use_hook_tokens"], [13, 4, 1, "", "use_local_attn"], [13, 4, 1, "", "use_split_qkv_input"], [13, 4, 1, "", "window_size"]], "transformer_lens.SVDInterpreter": [[14, 1, 1, "", "SVDInterpreter"]], "transformer_lens.SVDInterpreter.SVDInterpreter": [[14, 2, 1, "", "get_singular_vectors"]], "transformer_lens.components": [[15, 1, 1, "", "AbstractAttention"], [15, 1, 1, "", "Attention"], [15, 1, 1, "", "BertBlock"], [15, 1, 1, "", "BertEmbed"], [15, 1, 1, "", "BertMLMHead"], [15, 1, 1, "", "Embed"], [15, 1, 1, "", "GatedMLP"], [15, 1, 1, "", "GroupedQueryAttention"], [15, 1, 1, "", "LayerNorm"], [15, 1, 1, "", "LayerNormPre"], [15, 1, 1, "", "MLP"], [15, 1, 1, "", "MoE"], [15, 1, 1, "", "PosEmbed"], [15, 1, 1, "", "RMSNorm"], [15, 1, 1, "", "RMSNormPre"], [15, 1, 1, "", "TokenTypeEmbed"], [15, 1, 1, "", "TransformerBlock"], [15, 1, 1, "", "Unembed"]], "transformer_lens.components.AbstractAttention": [[15, 3, 1, "", "OV"], [15, 3, 1, "", "QK"], [15, 2, 1, "", "__init__"], [15, 4, 1, "", "alibi"], [15, 2, 1, "", "apply_causal_mask"], [15, 2, 1, "", "apply_rotary"], [15, 2, 1, "", "calculate_attention_scores"], [15, 2, 1, "", "calculate_qkv_matrices"], [15, 2, 1, "", "calculate_sin_cos_rotary"], [15, 2, 1, "", "calculate_z_scores"], [15, 2, 1, "", "create_alibi_bias"], [15, 2, 1, "", "create_alibi_multipliers"], [15, 2, 1, "", "create_alibi_slope"], [15, 2, 1, "", "forward"], [15, 2, 1, "", "rotate_every_two"]], "transformer_lens.components.Attention": [[15, 2, 1, "", "__init__"]], "transformer_lens.components.BertBlock": [[15, 2, 1, "", "forward"]], "transformer_lens.components.BertEmbed": [[15, 2, 1, "", "forward"]], "transformer_lens.components.BertMLMHead": [[15, 2, 1, "", "forward"]], "transformer_lens.components.Embed": [[15, 2, 1, "", "forward"]], "transformer_lens.components.GatedMLP": [[15, 4, 1, "", "act_fn"], [15, 2, 1, "", "forward"], [15, 4, 1, "", "ln"]], "transformer_lens.components.GroupedQueryAttention": [[15, 3, 1, "", "W_K"], [15, 3, 1, "", "W_V"], [15, 2, 1, "", "__init__"], [15, 3, 1, "", "b_K"], [15, 3, 1, "", "b_V"], [15, 2, 1, "", "calculate_attention_scores"], [15, 2, 1, "", "calculate_qkv_matrices"], [15, 2, 1, "", "calculate_z_scores"]], "transformer_lens.components.LayerNorm": [[15, 2, 1, "", "__init__"], [15, 2, 1, "", "forward"]], "transformer_lens.components.LayerNormPre": [[15, 2, 1, "", "__init__"], [15, 2, 1, "", "forward"]], "transformer_lens.components.MLP": [[15, 4, 1, "", "act_fn"], [15, 2, 1, "", "forward"], [15, 4, 1, "", "ln"]], "transformer_lens.components.MoE": [[15, 2, 1, "", "forward"]], "transformer_lens.components.PosEmbed": [[15, 2, 1, "", "forward"]], "transformer_lens.components.RMSNorm": [[15, 2, 1, "", "__init__"], [15, 2, 1, "", "forward"]], "transformer_lens.components.RMSNormPre": [[15, 2, 1, "", "__init__"], [15, 2, 1, "", "forward"]], "transformer_lens.components.TokenTypeEmbed": [[15, 2, 1, "", "forward"]], "transformer_lens.components.TransformerBlock": [[15, 2, 1, "", "forward"], [15, 4, 1, "", "ln1"], [15, 4, 1, "", "ln2"], [15, 4, 1, "", "mlp"]], "transformer_lens.components.Unembed": [[15, 2, 1, "", "forward"]], "transformer_lens.evals": [[16, 1, 1, "", "IOIDataset"], [16, 5, 1, "", "evaluate"], [16, 5, 1, "", "evaluate_on_dataset"], [16, 5, 1, "", "induction_loss"], [16, 5, 1, "", "ioi_eval"], [16, 5, 1, "", "make_code_data_loader"], [16, 5, 1, "", "make_owt_data_loader"], [16, 5, 1, "", "make_pile_data_loader"], [16, 5, 1, "", "make_wiki_data_loader"], [16, 5, 1, "", "sanity_check"]], "transformer_lens.evals.IOIDataset": [[16, 2, 1, "", "get_default_names"], [16, 2, 1, "", "get_default_nouns"], [16, 2, 1, "", "get_default_templates"], [16, 2, 1, "", "get_sample"]], "transformer_lens.head_detector": [[17, 5, 1, "", "compute_head_attention_similarity_score"], [17, 5, 1, "", "detect_head"], [17, 5, 1, "", "get_duplicate_token_head_detection_pattern"], [17, 5, 1, "", "get_induction_head_detection_pattern"], [17, 5, 1, "", "get_previous_token_head_detection_pattern"], [17, 5, 1, "", "get_supported_heads"]], "transformer_lens.hook_points": [[18, 1, 1, "", "HookPoint"], [18, 1, 1, "", "HookedRootModule"], [18, 1, 1, "", "LensHandle"]], "transformer_lens.hook_points.HookPoint": [[18, 2, 1, "", "add_hook"], [18, 2, 1, "", "add_perma_hook"], [18, 2, 1, "", "clear_context"], [18, 2, 1, "", "forward"], [18, 2, 1, "", "layer"], [18, 2, 1, "", "remove_hooks"]], "transformer_lens.hook_points.HookedRootModule": [[18, 2, 1, "", "add_caching_hooks"], [18, 2, 1, "", "add_hook"], [18, 2, 1, "", "add_perma_hook"], [18, 2, 1, "", "cache_all"], [18, 2, 1, "", "cache_some"], [18, 2, 1, "", "check_and_add_hook"], [18, 2, 1, "", "check_hooks_to_add"], [18, 2, 1, "", "clear_contexts"], [18, 2, 1, "", "get_caching_hooks"], [18, 2, 1, "", "hook_points"], [18, 2, 1, "", "hooks"], [18, 2, 1, "", "remove_all_hook_fns"], [18, 2, 1, "", "reset_hooks"], [18, 2, 1, "", "run_with_cache"], [18, 2, 1, "", "run_with_hooks"], [18, 2, 1, "", "setup"]], "transformer_lens.hook_points.LensHandle": [[18, 4, 1, "", "context_level"], [18, 4, 1, "", "hook"], [18, 4, 1, "", "is_permanent"]], "transformer_lens.loading_from_pretrained": [[19, 1, 1, "", "Config"], [19, 6, 1, "", "MODEL_ALIASES"], [19, 6, 1, "", "NON_HF_HOSTED_MODEL_NAMES"], [19, 6, 1, "", "OFFICIAL_MODEL_NAMES"], [19, 5, 1, "", "convert_bloom_weights"], [19, 5, 1, "", "convert_coder_weights"], [19, 5, 1, "", "convert_mistral_weights"], [19, 5, 1, "", "convert_mixtral_weights"], [19, 5, 1, "", "convert_phi_weights"], [19, 5, 1, "", "convert_qwen2_weights"], [19, 5, 1, "", "convert_qwen_weights"], [19, 5, 1, "", "get_checkpoint_labels"], [19, 5, 1, "", "get_num_params_of_pretrained"], [19, 5, 1, "", "get_pretrained_model_config"]], "transformer_lens.loading_from_pretrained.Config": [[19, 4, 1, "", "d_head"], [19, 4, 1, "", "d_mlp"], [19, 4, 1, "", "d_model"], [19, 4, 1, "", "d_vocab"], [19, 4, 1, "", "debug"], [19, 4, 1, "", "init_range"], [19, 4, 1, "", "layer_norm_eps"], [19, 4, 1, "", "n_ctx"], [19, 4, 1, "", "n_heads"], [19, 4, 1, "", "n_layers"]], "transformer_lens.past_key_value_caching": [[20, 1, 1, "", "HookedTransformerKeyValueCache"], [20, 1, 1, "", "HookedTransformerKeyValueCacheEntry"]], "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache": [[20, 2, 1, "", "append_attention_mask"], [20, 4, 1, "", "entries"], [20, 2, 1, "", "freeze"], [20, 4, 1, "", "frozen"], [20, 2, 1, "", "init_cache"], [20, 4, 1, "", "previous_attention_mask"], [20, 2, 1, "", "unfreeze"]], "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry": [[20, 2, 1, "", "append"], [20, 4, 1, "", "frozen"], [20, 2, 1, "", "init_cache_entry"], [20, 4, 1, "", "past_keys"], [20, 4, 1, "", "past_values"]], "transformer_lens.patching": [[21, 5, 1, "", "generic_activation_patch"], [21, 5, 1, "", "get_act_patch_attn_head_all_pos_every"], [21, 5, 1, "", "get_act_patch_attn_head_by_pos_every"], [21, 5, 1, "", "get_act_patch_attn_head_k_all_pos"], [21, 5, 1, "", "get_act_patch_attn_head_k_by_pos"], [21, 5, 1, "", "get_act_patch_attn_head_out_all_pos"], [21, 5, 1, "", "get_act_patch_attn_head_out_by_pos"], [21, 5, 1, "", "get_act_patch_attn_head_pattern_all_pos"], [21, 5, 1, "", "get_act_patch_attn_head_pattern_by_pos"], [21, 5, 1, "", "get_act_patch_attn_head_pattern_dest_src_pos"], [21, 5, 1, "", "get_act_patch_attn_head_q_all_pos"], [21, 5, 1, "", "get_act_patch_attn_head_q_by_pos"], [21, 5, 1, "", "get_act_patch_attn_head_v_all_pos"], [21, 5, 1, "", "get_act_patch_attn_head_v_by_pos"], [21, 5, 1, "", "get_act_patch_attn_out"], [21, 5, 1, "", "get_act_patch_block_every"], [21, 5, 1, "", "get_act_patch_mlp_out"], [21, 5, 1, "", "get_act_patch_resid_mid"], [21, 5, 1, "", "get_act_patch_resid_pre"], [21, 5, 1, "", "layer_head_dest_src_pos_pattern_patch_setter"], [21, 5, 1, "", "layer_head_pattern_patch_setter"], [21, 5, 1, "", "layer_head_pos_pattern_patch_setter"], [21, 5, 1, "", "layer_head_vector_patch_setter"], [21, 5, 1, "", "layer_pos_head_vector_patch_setter"], [21, 5, 1, "", "layer_pos_patch_setter"]], "transformer_lens.train": [[22, 1, 1, "", "HookedTransformerTrainConfig"], [22, 5, 1, "", "train"]], "transformer_lens.train.HookedTransformerTrainConfig": [[22, 4, 1, "", "batch_size"], [22, 4, 1, "", "device"], [22, 4, 1, "", "lr"], [22, 4, 1, "", "max_grad_norm"], [22, 4, 1, "", "max_steps"], [22, 4, 1, "", "momentum"], [22, 4, 1, "", "num_epochs"], [22, 4, 1, "", "optimizer_name"], [22, 4, 1, "", "print_every"], [22, 4, 1, "", "save_dir"], [22, 4, 1, "", "save_every"], [22, 4, 1, "", "seed"], [22, 4, 1, "", "wandb"], [22, 4, 1, "", "wandb_project_name"], [22, 4, 1, "", "warmup_steps"], [22, 4, 1, "", "weight_decay"]], "transformer_lens.utilities": [[24, 0, 0, "-", "devices"]], "transformer_lens.utilities.devices": [[24, 5, 1, "", "get_device_for_block_index"], [24, 5, 1, "", "move_to_and_update_config"]], "transformer_lens.utils": [[25, 1, 1, "", "LocallyOverridenDefaults"], [25, 1, 1, "", "Slice"], [25, 6, 1, "", "SliceInput"], [25, 5, 1, "", "calc_fan_in_and_fan_out"], [25, 5, 1, "", "composition_scores"], [25, 5, 1, "", "download_file_from_hf"], [25, 5, 1, "", "gelu_fast"], [25, 5, 1, "", "gelu_new"], [25, 5, 1, "", "get_act_name"], [25, 5, 1, "", "get_attention_mask"], [25, 5, 1, "", "get_corner"], [25, 5, 1, "", "get_cumsum_along_dim"], [25, 5, 1, "", "get_dataset"], [25, 5, 1, "", "get_device"], [25, 5, 1, "", "get_input_with_manually_prepended_bos"], [25, 5, 1, "", "get_nested_attr"], [25, 5, 1, "", "get_offset_position_ids"], [25, 5, 1, "", "get_tokenizer_with_bos"], [25, 5, 1, "", "get_tokens_with_bos_removed"], [25, 5, 1, "", "init_kaiming_normal_"], [25, 5, 1, "", "init_kaiming_uniform_"], [25, 5, 1, "", "init_xavier_normal_"], [25, 5, 1, "", "init_xavier_uniform_"], [25, 5, 1, "", "is_lower_triangular"], [25, 5, 1, "", "is_square"], [25, 5, 1, "", "keep_single_column"], [25, 5, 1, "", "lm_accuracy"], [25, 5, 1, "", "lm_cross_entropy_loss"], [25, 5, 1, "", "override_or_use_default_value"], [25, 5, 1, "", "print_gpu_mem"], [25, 5, 1, "", "remove_batch_dim"], [25, 5, 1, "", "repeat_along_head_dimension"], [25, 5, 1, "", "sample_logits"], [25, 5, 1, "", "set_nested_attr"], [25, 5, 1, "", "solu"], [25, 5, 1, "", "test_prompt"], [25, 5, 1, "", "to_numpy"], [25, 5, 1, "", "tokenize_and_concatenate"], [25, 5, 1, "", "transpose"]], "transformer_lens.utils.LocallyOverridenDefaults": [[25, 2, 1, "", "__init__"]], "transformer_lens.utils.Slice": [[25, 2, 1, "", "__init__"], [25, 2, 1, "", "apply"], [25, 2, 1, "", "indices"], [25, 4, 1, "", "slice"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:attribute", "5": "py:function", "6": "py:data"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"], "6": ["py", "data", "Python data"]}, "titleterms": {"citat": 0, "contribut": 1, "setup": [1, 26, 27], "devcontain": 1, "manual": 1, "test": 1, "run": [1, 27], "format": 1, "document": 1, "docstr": 1, "style": 1, "guid": 1, "section": 1, "order": 1, "support": 1, "sphinx": 1, "properti": [1, 28], "refer": 1, "other": [1, 27], "function": [1, 26], "class": [1, 27], "math": 1, "markup": 1, "galleri": 2, "get": [3, 4], "start": [3, 4, 6], "advic": 3, "read": [3, 26], "code": 3, "instal": 3, "mechanist": [4, 29], "interpret": [4, 27, 29], "special": 5, "case": 5, "mixtur": 5, "expert": 5, "error": 5, "rate": 5, "tutori": 6, "where": 6, "To": 6, "demo": [6, 26, 27], "transform": [7, 27], "len": [7, 26, 27], "api": 7, "content": 7, "transformer_len": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "submodul": [8, 23], "subpackag": 8, "activationcach": 9, "factoredmatrix": 10, "hookedencod": 11, "hookedtransform": 12, "hookedtransformerconfig": 13, "svdinterpret": 14, "compon": 15, "eval": 16, "head_detector": 17, "hook_point": 18, "loading_from_pretrain": 19, "past_key_value_cach": 20, "patch": [21, 26, 27], "train": [22, 27], "util": [23, 24, 25], "devic": 24, "exploratori": 26, "analysi": 26, "tip": 26, "thi": 26, "environ": 26, "ignor": 26, "import": [26, 27], "pytorch": 26, "plot": 26, "helper": 26, "introduct": [26, 27], "indirect": [26, 27], "object": [26, 27], "identif": [26, 27], "brainstorm": 26, "what": 26, "": 26, "actual": 26, "go": 26, "On": 26, "option": 26, "direct": 26, "logit": 26, "attribut": 26, "layer": 26, "head": [26, 27], "attent": 26, "activ": [26, 27], "residu": 26, "stream": 26, "decompos": 26, "consolid": 26, "understand": 26, "visual": 26, "pattern": 26, "compar": 26, "paper": 26, "bonu": 26, "explor": 26, "anomali": 26, "earli": 26, "ar": 26, "induct": [26, 27], "implic": 26, "backup": 26, "name": [26, 27], "mover": 26, "main": 27, "notebook": 27, "load": 27, "model": [27, 28, 29], "cach": 27, "all": 27, "hook": 27, "interven": 27, "task": 27, "access": 27, "avail": 27, "an": 27, "overview": 27, "open": 27, "sourc": 27, "librari": [27, 29], "some": 27, "friendli": 27, "i": 27, "ve": 27, "includ": 27, "resourc": 27, "architectur": 27, "paramet": 27, "fold": 27, "layernorm": 27, "For": 27, "curiou": 27, "featur": 27, "deal": 27, "token": 27, "gotcha": 27, "prepend_bo": 27, "factor": 27, "matrix": 27, "basic": 27, "exampl": 27, "medium": 27, "eigenvalu": 27, "copi": 27, "score": 27, "gener": [27, 29], "text": 27, "point": 27, "toi": 27, "pre": 27, "checkpoint": 27, "phase": 27, "transit": 27, "tabl": 28, "transformerlen": 29, "A": 29, "languag": 29}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx": 57}, "alltitles": {"Citation": [[0, "citation"]], "Contributing": [[1, "contributing"]], "Setup": [[1, "setup"], [26, "Setup"], [27, "Setup"]], "DevContainer": [[1, "devcontainer"]], "Manual Setup": [[1, "manual-setup"]], "Testing": [[1, "testing"]], "Running the tests": [[1, "running-the-tests"]], "Formatting": [[1, "formatting"]], "Documentation": [[1, "documentation"]], "Docstring Style Guide": [[1, "docstring-style-guide"]], "Sections and Order": [[1, "sections-and-order"]], "Supported Sphinx Properties": [[1, "supported-sphinx-properties"]], "References to Other Functions/Classes": [[1, "references-to-other-functions-classes"]], "Maths": [[1, "maths"]], "Markup": [[1, "markup"]], "Gallery": [[2, "gallery"]], "Getting Started": [[3, "getting-started"]], "Advice for Reading the Code": [[3, "advice-for-reading-the-code"]], "Installation": [[3, "installation"]], "Getting Started in Mechanistic Interpretability": [[4, "getting-started-in-mechanistic-interpretability"]], "Special Cases": [[5, "special-cases"]], "Mixture of Experts error rates": [[5, "mixture-of-experts-error-rates"]], "Tutorials": [[6, "tutorials"]], "Where To Start": [[6, "where-to-start"]], "Demos": [[6, "demos"]], "Transformer Lens API": [[7, "transformer-lens-api"]], "Contents": [[7, "contents"]], "transformer_lens": [[8, "transformer-lens"]], "Submodules": [[8, "submodules"], [23, "submodules"]], "Subpackages": [[8, "subpackages"]], "transformer_lens.ActivationCache": [[9, "module-transformer_lens.ActivationCache"]], "transformer_lens.FactoredMatrix": [[10, "module-transformer_lens.FactoredMatrix"]], "transformer_lens.HookedEncoder": [[11, "module-transformer_lens.HookedEncoder"]], "transformer_lens.HookedTransformer": [[12, "module-transformer_lens.HookedTransformer"]], "transformer_lens.HookedTransformerConfig": [[13, "module-transformer_lens.HookedTransformerConfig"]], "transformer_lens.SVDInterpreter": [[14, "module-transformer_lens.SVDInterpreter"]], "transformer_lens.components": [[15, "module-transformer_lens.components"]], "transformer_lens.evals": [[16, "module-transformer_lens.evals"]], "transformer_lens.head_detector": [[17, "module-transformer_lens.head_detector"]], "transformer_lens.hook_points": [[18, "module-transformer_lens.hook_points"]], "transformer_lens.loading_from_pretrained": [[19, "module-transformer_lens.loading_from_pretrained"]], "transformer_lens.past_key_value_caching": [[20, "module-transformer_lens.past_key_value_caching"]], "transformer_lens.patching": [[21, "module-transformer_lens.patching"]], "transformer_lens.train": [[22, "module-transformer_lens.train"]], "transformer_lens.utilities": [[23, "transformer-lens-utilities"]], "transformer_lens.utilities.devices": [[24, "module-transformer_lens.utilities.devices"]], "transformer_lens.utils": [[25, "module-transformer_lens.utils"]], "Exploratory Analysis Demo": [[26, "Exploratory-Analysis-Demo"]], "Tips for Reading This": [[26, "Tips-for-Reading-This"]], "Environment Setup (ignore)": [[26, "Environment-Setup-(ignore)"]], "Imports": [[26, "Imports"]], "PyTorch Setup": [[26, "PyTorch-Setup"]], "Plotting Helper Functions (ignore)": [[26, "Plotting-Helper-Functions-(ignore)"]], "Introduction": [[26, "Introduction"], [27, "Introduction"]], "Indirect Object Identification": [[26, "Indirect-Object-Identification"]], "Brainstorm What\u2019s Actually Going On (Optional)": [[26, "Brainstorm-What's-Actually-Going-On-(Optional)"]], "Direct Logit Attribution": [[26, "Direct-Logit-Attribution"]], "Logit Lens": [[26, "Logit-Lens"]], "Layer Attribution": [[26, "Layer-Attribution"]], "Head Attribution": [[26, "Head-Attribution"]], "Attention Analysis": [[26, "Attention-Analysis"]], "Activation Patching": [[26, "Activation-Patching"]], "Residual Stream": [[26, "Residual-Stream"]], "Layers": [[26, "Layers"]], "Heads": [[26, "Heads"]], "Decomposing Heads": [[26, "Decomposing-Heads"]], "Consolidating Understanding": [[26, "Consolidating-Understanding"]], "Visualizing Attention Patterns": [[26, "Visualizing-Attention-Patterns"]], "Comparing to the Paper": [[26, "Comparing-to-the-Paper"]], "Bonus: Exploring Anomalies": [[26, "Bonus:-Exploring-Anomalies"]], "Early Heads are Induction Heads(?!)": [[26, "Early-Heads-are-Induction-Heads(?!)"]], "Implications": [[26, "Implications"]], "Backup Name Mover Heads": [[26, "Backup-Name-Mover-Heads"]], "Transformer Lens Main Demo Notebook": [[27, "Transformer-Lens-Main-Demo-Notebook"]], "Loading and Running Models": [[27, "Loading-and-Running-Models"]], "Caching all Activations": [[27, "Caching-all-Activations"]], "Hooks: Intervening on Activations": [[27, "Hooks:-Intervening-on-Activations"]], "Activation Patching on the Indirect Object Identification Task": [[27, "Activation-Patching-on-the-Indirect-Object-Identification-Task"]], "Hooks: Accessing Activations": [[27, "Hooks:-Accessing-Activations"]], "Available Models": [[27, "Available-Models"]], "An overview of the important open source models in the library": [[27, "An-overview-of-the-important-open-source-models-in-the-library"]], "An overview of some interpretability-friendly models I\u2019ve trained and included": [[27, "An-overview-of-some-interpretability-friendly-models-I've-trained-and-included"]], "Other Resources:": [[27, "Other-Resources:"]], "Transformer architecture": [[27, "Transformer-architecture"]], "Parameter Names": [[27, "Parameter-Names"]], "Activation + Hook Names": [[27, "Activation-+-Hook-Names"]], "Folding LayerNorm (For the Curious)": [[27, "Folding-LayerNorm-(For-the-Curious)"]], "Features": [[27, "Features"]], "Dealing with tokens": [[27, "Dealing-with-tokens"]], "Gotcha: prepend_bos": [[27, "Gotcha:-prepend_bos"]], "Factored Matrix Class": [[27, "Factored-Matrix-Class"]], "Basic Examples": [[27, "Basic-Examples"]], "Medium Example: Eigenvalue Copying Scores": [[27, "Medium-Example:-Eigenvalue-Copying-Scores"]], "Generating Text": [[27, "Generating-Text"]], "Hook Points": [[27, "Hook-Points"]], "Toy Example": [[27, "Toy-Example"]], "Loading Pre-Trained Checkpoints": [[27, "Loading-Pre-Trained-Checkpoints"]], "Example: Induction Head Phase Transition": [[27, "Example:-Induction-Head-Phase-Transition"]], "Model Properties Table": [[28, "model-properties-table"]], "TransformerLens": [[29, "transformerlens"]], "A Library for Mechanistic Interpretability of Generative Language Models": [[29, "a-library-for-mechanistic-interpretability-of-generative-language-models"]]}, "indexentries": {"activationcache (class in transformer_lens.activationcache)": [[9, "transformer_lens.ActivationCache.ActivationCache"]], "accumulated_resid() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.accumulated_resid"]], "apply_ln_to_stack() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.apply_ln_to_stack"]], "apply_slice_to_batch_dim() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.apply_slice_to_batch_dim"]], "compute_head_results() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.compute_head_results"]], "decompose_resid() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.decompose_resid"]], "get_full_resid_decomposition() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.get_full_resid_decomposition"]], "get_neuron_results() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.get_neuron_results"]], "items() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.items"]], "keys() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.keys"]], "logit_attrs() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.logit_attrs"]], "module": [[9, "module-transformer_lens.ActivationCache"], [10, "module-transformer_lens.FactoredMatrix"], [11, "module-transformer_lens.HookedEncoder"], [12, "module-transformer_lens.HookedTransformer"], [13, "module-transformer_lens.HookedTransformerConfig"], [14, "module-transformer_lens.SVDInterpreter"], [15, "module-transformer_lens.components"], [16, "module-transformer_lens.evals"], [17, "module-transformer_lens.head_detector"], [18, "module-transformer_lens.hook_points"], [19, "module-transformer_lens.loading_from_pretrained"], [20, "module-transformer_lens.past_key_value_caching"], [21, "module-transformer_lens.patching"], [22, "module-transformer_lens.train"], [24, "module-transformer_lens.utilities.devices"], [25, "module-transformer_lens.utils"]], "remove_batch_dim() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.remove_batch_dim"]], "stack_activation() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.stack_activation"]], "stack_head_results() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.stack_head_results"]], "stack_neuron_results() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.stack_neuron_results"]], "to() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.to"]], "toggle_autodiff() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.toggle_autodiff"]], "transformer_lens.activationcache": [[9, "module-transformer_lens.ActivationCache"]], "values() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.values"]], "ab (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.AB"]], "ba (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.BA"]], "factoredmatrix (class in transformer_lens.factoredmatrix)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix"]], "s (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.S"]], "t (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.T"]], "u (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.U"]], "vh (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.Vh"]], "collapse_l() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.collapse_l"]], "collapse_r() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.collapse_r"]], "eigenvalues (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.eigenvalues"]], "get_corner() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.get_corner"]], "make_even() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.make_even"]], "ndim (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.ndim"]], "norm() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.norm"]], "pair (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.pair"]], "svd() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.svd"]], "transformer_lens.factoredmatrix": [[10, "module-transformer_lens.FactoredMatrix"]], "unsqueeze() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.unsqueeze"]], "hookedencoder (class in transformer_lens.hookedencoder)": [[11, "transformer_lens.HookedEncoder.HookedEncoder"]], "ov (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.OV"]], "qk (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.QK"]], "w_e (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_E"]], "w_e_pos (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_E_pos"]], "w_k (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_K"]], "w_o (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_O"]], "w_q (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_Q"]], "w_u (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_U"]], "w_v (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_V"]], "w_in (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_in"]], "w_out (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_out"]], "w_pos (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.W_pos"]], "all_head_labels() (transformer_lens.hookedencoder.hookedencoder method)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.all_head_labels"]], "b_k (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.b_K"]], "b_o (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.b_O"]], "b_q (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.b_Q"]], "b_u (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.b_U"]], "b_v (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.b_V"]], "b_in (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.b_in"]], "b_out (transformer_lens.hookedencoder.hookedencoder property)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.b_out"]], "cpu() (transformer_lens.hookedencoder.hookedencoder method)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.cpu"]], "cuda() (transformer_lens.hookedencoder.hookedencoder method)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.cuda"]], "forward() (transformer_lens.hookedencoder.hookedencoder method)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.forward"]], "from_pretrained() (transformer_lens.hookedencoder.hookedencoder class method)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.from_pretrained"]], "mps() (transformer_lens.hookedencoder.hookedencoder method)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.mps"]], "run_with_cache() (transformer_lens.hookedencoder.hookedencoder method)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.run_with_cache"]], "to() (transformer_lens.hookedencoder.hookedencoder method)": [[11, "transformer_lens.HookedEncoder.HookedEncoder.to"]], "transformer_lens.hookedencoder": [[11, "module-transformer_lens.HookedEncoder"]], "hookedtransformer (class in transformer_lens.hookedtransformer)": [[12, "transformer_lens.HookedTransformer.HookedTransformer"]], "ov (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.OV"]], "output (class in transformer_lens.hookedtransformer)": [[12, "transformer_lens.HookedTransformer.Output"]], "qk (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.QK"]], "w_e (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.W_E"]], "w_e_pos (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.W_E_pos"]], "w_k (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.W_K"]], "w_o (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.W_O"]], "w_q (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.W_Q"]], "w_u (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.W_U"]], "w_v (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.W_V"]], "w_gate (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.W_gate"]], "w_in (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.W_in"]], "w_out (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.W_out"]], "w_pos (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.W_pos"]], "__init__() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.__init__"]], "accumulated_bias() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.accumulated_bias"]], "all_composition_scores() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.all_composition_scores"]], "all_head_labels() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.all_head_labels"]], "b_k (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.b_K"]], "b_o (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.b_O"]], "b_q (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.b_Q"]], "b_u (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.b_U"]], "b_v (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.b_V"]], "b_in (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.b_in"]], "b_out (transformer_lens.hookedtransformer.hookedtransformer property)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.b_out"]], "center_unembed() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.center_unembed"]], "center_writing_weights() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.center_writing_weights"]], "check_hooks_to_add() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.check_hooks_to_add"]], "cpu() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.cpu"]], "cuda() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.cuda"]], "fold_layer_norm() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.fold_layer_norm"]], "fold_value_biases() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.fold_value_biases"]], "forward() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.forward"]], "from_pretrained() (transformer_lens.hookedtransformer.hookedtransformer class method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.from_pretrained"]], "from_pretrained_no_processing() (transformer_lens.hookedtransformer.hookedtransformer class method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.from_pretrained_no_processing"]], "generate() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.generate"]], "get_token_position() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.get_token_position"]], "init_weights() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.init_weights"]], "input_to_embed() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.input_to_embed"]], "ln_final (transformer_lens.hookedtransformer.hookedtransformer attribute)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.ln_final"]], "load_and_process_state_dict() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.load_and_process_state_dict"]], "load_sample_training_dataset() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.load_sample_training_dataset"]], "logits (transformer_lens.hookedtransformer.output attribute)": [[12, "transformer_lens.HookedTransformer.Output.logits"]], "loss (transformer_lens.hookedtransformer.output attribute)": [[12, "transformer_lens.HookedTransformer.Output.loss"]], "loss_fn() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.loss_fn"]], "move_model_modules_to_device() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.move_model_modules_to_device"]], "mps() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.mps"]], "process_weights_() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.process_weights_"]], "refactor_factored_attn_matrices() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.refactor_factored_attn_matrices"]], "run_with_cache() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.run_with_cache"]], "sample_datapoint() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.sample_datapoint"]], "set_tokenizer() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.set_tokenizer"]], "set_use_attn_in() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.set_use_attn_in"]], "set_use_attn_result() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.set_use_attn_result"]], "set_use_hook_mlp_in() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.set_use_hook_mlp_in"]], "set_use_split_qkv_input() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.set_use_split_qkv_input"]], "to() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.to"]], "to_single_str_token() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.to_single_str_token"]], "to_single_token() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.to_single_token"]], "to_str_tokens() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.to_str_tokens"]], "to_string() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.to_string"]], "to_tokens() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.to_tokens"]], "tokens_to_residual_directions() (transformer_lens.hookedtransformer.hookedtransformer method)": [[12, "transformer_lens.HookedTransformer.HookedTransformer.tokens_to_residual_directions"]], "transformer_lens.hookedtransformer": [[12, "module-transformer_lens.HookedTransformer"]], "hookedtransformerconfig (class in transformer_lens.hookedtransformerconfig)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig"]], "act_fn (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.act_fn"]], "attention_dir (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attention_dir"]], "attn_only (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_only"]], "attn_types (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_types"]], "checkpoint_index (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_index"]], "checkpoint_label_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_label_type"]], "checkpoint_value (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_value"]], "d_head (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_head"]], "d_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_mlp"]], "d_model (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_model"]], "d_vocab (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_vocab"]], "d_vocab_out (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_vocab_out"]], "default_prepend_bos (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.default_prepend_bos"]], "device (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.device"]], "dtype (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.dtype"]], "eps (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.eps"]], "experts_per_token (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.experts_per_token"]], "final_rms (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.final_rms"]], "from_checkpoint (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.from_checkpoint"]], "from_dict() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig class method)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.from_dict"]], "gated_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.gated_mlp"]], "init_mode (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.init_mode"]], "init_weights (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.init_weights"]], "initializer_range (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.initializer_range"]], "model_name (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.model_name"]], "n_ctx (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_ctx"]], "n_devices (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_devices"]], "n_heads (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_heads"]], "n_key_value_heads (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_key_value_heads"]], "n_layers (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_layers"]], "n_params (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_params"]], "normalization_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.normalization_type"]], "num_experts (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.num_experts"]], "original_architecture (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.original_architecture"]], "parallel_attn_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.parallel_attn_mlp"]], "positional_embedding_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.positional_embedding_type"]], "post_embedding_ln (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.post_embedding_ln"]], "rotary_adjacent_pairs (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_adjacent_pairs"]], "rotary_base (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_base"]], "rotary_dim (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_dim"]], "scale_attn_by_inverse_layer_idx (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.scale_attn_by_inverse_layer_idx"]], "seed (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.seed"]], "set_seed_everywhere() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.set_seed_everywhere"]], "to_dict() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.to_dict"]], "tokenizer_name (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.tokenizer_name"]], "tokenizer_prepends_bos (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.tokenizer_prepends_bos"]], "transformer_lens.hookedtransformerconfig": [[13, "module-transformer_lens.HookedTransformerConfig"]], "trust_remote_code (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.trust_remote_code"]], "use_attn_in (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_in"]], "use_attn_result (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_result"]], "use_attn_scale (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_scale"]], "use_hook_mlp_in (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_hook_mlp_in"]], "use_hook_tokens (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_hook_tokens"]], "use_local_attn (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_local_attn"]], "use_split_qkv_input (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_split_qkv_input"]], "window_size (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[13, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.window_size"]], "svdinterpreter (class in transformer_lens.svdinterpreter)": [[14, "transformer_lens.SVDInterpreter.SVDInterpreter"]], "get_singular_vectors() (transformer_lens.svdinterpreter.svdinterpreter method)": [[14, "transformer_lens.SVDInterpreter.SVDInterpreter.get_singular_vectors"]], "transformer_lens.svdinterpreter": [[14, "module-transformer_lens.SVDInterpreter"]], "abstractattention (class in transformer_lens.components)": [[15, "transformer_lens.components.AbstractAttention"]], "attention (class in transformer_lens.components)": [[15, "transformer_lens.components.Attention"]], "bertblock (class in transformer_lens.components)": [[15, "transformer_lens.components.BertBlock"]], "bertembed (class in transformer_lens.components)": [[15, "transformer_lens.components.BertEmbed"]], "bertmlmhead (class in transformer_lens.components)": [[15, "transformer_lens.components.BertMLMHead"]], "embed (class in transformer_lens.components)": [[15, "transformer_lens.components.Embed"]], "gatedmlp (class in transformer_lens.components)": [[15, "transformer_lens.components.GatedMLP"]], "groupedqueryattention (class in transformer_lens.components)": [[15, "transformer_lens.components.GroupedQueryAttention"]], "layernorm (class in transformer_lens.components)": [[15, "transformer_lens.components.LayerNorm"]], "layernormpre (class in transformer_lens.components)": [[15, "transformer_lens.components.LayerNormPre"]], "mlp (class in transformer_lens.components)": [[15, "transformer_lens.components.MLP"]], "moe (class in transformer_lens.components)": [[15, "transformer_lens.components.MoE"]], "ov (transformer_lens.components.abstractattention property)": [[15, "transformer_lens.components.AbstractAttention.OV"]], "posembed (class in transformer_lens.components)": [[15, "transformer_lens.components.PosEmbed"]], "qk (transformer_lens.components.abstractattention property)": [[15, "transformer_lens.components.AbstractAttention.QK"]], "rmsnorm (class in transformer_lens.components)": [[15, "transformer_lens.components.RMSNorm"]], "rmsnormpre (class in transformer_lens.components)": [[15, "transformer_lens.components.RMSNormPre"]], "tokentypeembed (class in transformer_lens.components)": [[15, "transformer_lens.components.TokenTypeEmbed"]], "transformerblock (class in transformer_lens.components)": [[15, "transformer_lens.components.TransformerBlock"]], "unembed (class in transformer_lens.components)": [[15, "transformer_lens.components.Unembed"]], "w_k (transformer_lens.components.groupedqueryattention property)": [[15, "transformer_lens.components.GroupedQueryAttention.W_K"]], "w_v (transformer_lens.components.groupedqueryattention property)": [[15, "transformer_lens.components.GroupedQueryAttention.W_V"]], "__init__() (transformer_lens.components.abstractattention method)": [[15, "transformer_lens.components.AbstractAttention.__init__"]], "__init__() (transformer_lens.components.attention method)": [[15, "transformer_lens.components.Attention.__init__"]], "__init__() (transformer_lens.components.groupedqueryattention method)": [[15, "transformer_lens.components.GroupedQueryAttention.__init__"]], "__init__() (transformer_lens.components.layernorm method)": [[15, "transformer_lens.components.LayerNorm.__init__"]], "__init__() (transformer_lens.components.layernormpre method)": [[15, "transformer_lens.components.LayerNormPre.__init__"]], "__init__() (transformer_lens.components.rmsnorm method)": [[15, "transformer_lens.components.RMSNorm.__init__"]], "__init__() (transformer_lens.components.rmsnormpre method)": [[15, "transformer_lens.components.RMSNormPre.__init__"]], "act_fn (transformer_lens.components.gatedmlp attribute)": [[15, "transformer_lens.components.GatedMLP.act_fn"]], "act_fn (transformer_lens.components.mlp attribute)": [[15, "transformer_lens.components.MLP.act_fn"]], "alibi (transformer_lens.components.abstractattention attribute)": [[15, "transformer_lens.components.AbstractAttention.alibi"]], "apply_causal_mask() (transformer_lens.components.abstractattention method)": [[15, "transformer_lens.components.AbstractAttention.apply_causal_mask"]], "apply_rotary() (transformer_lens.components.abstractattention method)": [[15, "transformer_lens.components.AbstractAttention.apply_rotary"]], "b_k (transformer_lens.components.groupedqueryattention property)": [[15, "transformer_lens.components.GroupedQueryAttention.b_K"]], "b_v (transformer_lens.components.groupedqueryattention property)": [[15, "transformer_lens.components.GroupedQueryAttention.b_V"]], "calculate_attention_scores() (transformer_lens.components.abstractattention method)": [[15, "transformer_lens.components.AbstractAttention.calculate_attention_scores"]], "calculate_attention_scores() (transformer_lens.components.groupedqueryattention method)": [[15, "transformer_lens.components.GroupedQueryAttention.calculate_attention_scores"]], "calculate_qkv_matrices() (transformer_lens.components.abstractattention method)": [[15, "transformer_lens.components.AbstractAttention.calculate_qkv_matrices"]], "calculate_qkv_matrices() (transformer_lens.components.groupedqueryattention method)": [[15, "transformer_lens.components.GroupedQueryAttention.calculate_qkv_matrices"]], "calculate_sin_cos_rotary() (transformer_lens.components.abstractattention method)": [[15, "transformer_lens.components.AbstractAttention.calculate_sin_cos_rotary"]], "calculate_z_scores() (transformer_lens.components.abstractattention method)": [[15, "transformer_lens.components.AbstractAttention.calculate_z_scores"]], "calculate_z_scores() (transformer_lens.components.groupedqueryattention method)": [[15, "transformer_lens.components.GroupedQueryAttention.calculate_z_scores"]], "create_alibi_bias() (transformer_lens.components.abstractattention static method)": [[15, "transformer_lens.components.AbstractAttention.create_alibi_bias"]], "create_alibi_multipliers() (transformer_lens.components.abstractattention static method)": [[15, "transformer_lens.components.AbstractAttention.create_alibi_multipliers"]], "create_alibi_slope() (transformer_lens.components.abstractattention static method)": [[15, "transformer_lens.components.AbstractAttention.create_alibi_slope"]], "forward() (transformer_lens.components.abstractattention method)": [[15, "transformer_lens.components.AbstractAttention.forward"]], "forward() (transformer_lens.components.bertblock method)": [[15, "transformer_lens.components.BertBlock.forward"]], "forward() (transformer_lens.components.bertembed method)": [[15, "transformer_lens.components.BertEmbed.forward"]], "forward() (transformer_lens.components.bertmlmhead method)": [[15, "transformer_lens.components.BertMLMHead.forward"]], "forward() (transformer_lens.components.embed method)": [[15, "transformer_lens.components.Embed.forward"]], "forward() (transformer_lens.components.gatedmlp method)": [[15, "transformer_lens.components.GatedMLP.forward"]], "forward() (transformer_lens.components.layernorm method)": [[15, "transformer_lens.components.LayerNorm.forward"]], "forward() (transformer_lens.components.layernormpre method)": [[15, "transformer_lens.components.LayerNormPre.forward"]], "forward() (transformer_lens.components.mlp method)": [[15, "transformer_lens.components.MLP.forward"]], "forward() (transformer_lens.components.moe method)": [[15, "transformer_lens.components.MoE.forward"]], "forward() (transformer_lens.components.posembed method)": [[15, "transformer_lens.components.PosEmbed.forward"]], "forward() (transformer_lens.components.rmsnorm method)": [[15, "transformer_lens.components.RMSNorm.forward"]], "forward() (transformer_lens.components.rmsnormpre method)": [[15, "transformer_lens.components.RMSNormPre.forward"]], "forward() (transformer_lens.components.tokentypeembed method)": [[15, "transformer_lens.components.TokenTypeEmbed.forward"]], "forward() (transformer_lens.components.transformerblock method)": [[15, "transformer_lens.components.TransformerBlock.forward"]], "forward() (transformer_lens.components.unembed method)": [[15, "transformer_lens.components.Unembed.forward"]], "ln (transformer_lens.components.gatedmlp attribute)": [[15, "transformer_lens.components.GatedMLP.ln"]], "ln (transformer_lens.components.mlp attribute)": [[15, "transformer_lens.components.MLP.ln"]], "ln1 (transformer_lens.components.transformerblock attribute)": [[15, "transformer_lens.components.TransformerBlock.ln1"]], "ln2 (transformer_lens.components.transformerblock attribute)": [[15, "transformer_lens.components.TransformerBlock.ln2"]], "mlp (transformer_lens.components.transformerblock attribute)": [[15, "transformer_lens.components.TransformerBlock.mlp"]], "rotate_every_two() (transformer_lens.components.abstractattention method)": [[15, "transformer_lens.components.AbstractAttention.rotate_every_two"]], "transformer_lens.components": [[15, "module-transformer_lens.components"]], "ioidataset (class in transformer_lens.evals)": [[16, "transformer_lens.evals.IOIDataset"]], "evaluate() (in module transformer_lens.evals)": [[16, "transformer_lens.evals.evaluate"]], "evaluate_on_dataset() (in module transformer_lens.evals)": [[16, "transformer_lens.evals.evaluate_on_dataset"]], "get_default_names() (transformer_lens.evals.ioidataset static method)": [[16, "transformer_lens.evals.IOIDataset.get_default_names"]], "get_default_nouns() (transformer_lens.evals.ioidataset static method)": [[16, "transformer_lens.evals.IOIDataset.get_default_nouns"]], "get_default_templates() (transformer_lens.evals.ioidataset static method)": [[16, "transformer_lens.evals.IOIDataset.get_default_templates"]], "get_sample() (transformer_lens.evals.ioidataset method)": [[16, "transformer_lens.evals.IOIDataset.get_sample"]], "induction_loss() (in module transformer_lens.evals)": [[16, "transformer_lens.evals.induction_loss"]], "ioi_eval() (in module transformer_lens.evals)": [[16, "transformer_lens.evals.ioi_eval"]], "make_code_data_loader() (in module transformer_lens.evals)": [[16, "transformer_lens.evals.make_code_data_loader"]], "make_owt_data_loader() (in module transformer_lens.evals)": [[16, "transformer_lens.evals.make_owt_data_loader"]], "make_pile_data_loader() (in module transformer_lens.evals)": [[16, "transformer_lens.evals.make_pile_data_loader"]], "make_wiki_data_loader() (in module transformer_lens.evals)": [[16, "transformer_lens.evals.make_wiki_data_loader"]], "sanity_check() (in module transformer_lens.evals)": [[16, "transformer_lens.evals.sanity_check"]], "transformer_lens.evals": [[16, "module-transformer_lens.evals"]], "compute_head_attention_similarity_score() (in module transformer_lens.head_detector)": [[17, "transformer_lens.head_detector.compute_head_attention_similarity_score"]], "detect_head() (in module transformer_lens.head_detector)": [[17, "transformer_lens.head_detector.detect_head"]], "get_duplicate_token_head_detection_pattern() (in module transformer_lens.head_detector)": [[17, "transformer_lens.head_detector.get_duplicate_token_head_detection_pattern"]], "get_induction_head_detection_pattern() (in module transformer_lens.head_detector)": [[17, "transformer_lens.head_detector.get_induction_head_detection_pattern"]], "get_previous_token_head_detection_pattern() (in module transformer_lens.head_detector)": [[17, "transformer_lens.head_detector.get_previous_token_head_detection_pattern"]], "get_supported_heads() (in module transformer_lens.head_detector)": [[17, "transformer_lens.head_detector.get_supported_heads"]], "transformer_lens.head_detector": [[17, "module-transformer_lens.head_detector"]], "hookpoint (class in transformer_lens.hook_points)": [[18, "transformer_lens.hook_points.HookPoint"]], "hookedrootmodule (class in transformer_lens.hook_points)": [[18, "transformer_lens.hook_points.HookedRootModule"]], "lenshandle (class in transformer_lens.hook_points)": [[18, "transformer_lens.hook_points.LensHandle"]], "add_caching_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[18, "transformer_lens.hook_points.HookedRootModule.add_caching_hooks"]], "add_hook() (transformer_lens.hook_points.hookpoint method)": [[18, "transformer_lens.hook_points.HookPoint.add_hook"]], "add_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[18, "transformer_lens.hook_points.HookedRootModule.add_hook"]], "add_perma_hook() (transformer_lens.hook_points.hookpoint method)": [[18, "transformer_lens.hook_points.HookPoint.add_perma_hook"]], "add_perma_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[18, "transformer_lens.hook_points.HookedRootModule.add_perma_hook"]], "cache_all() (transformer_lens.hook_points.hookedrootmodule method)": [[18, "transformer_lens.hook_points.HookedRootModule.cache_all"]], "cache_some() (transformer_lens.hook_points.hookedrootmodule method)": [[18, "transformer_lens.hook_points.HookedRootModule.cache_some"]], "check_and_add_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[18, "transformer_lens.hook_points.HookedRootModule.check_and_add_hook"]], "check_hooks_to_add() (transformer_lens.hook_points.hookedrootmodule method)": [[18, "transformer_lens.hook_points.HookedRootModule.check_hooks_to_add"]], "clear_context() (transformer_lens.hook_points.hookpoint method)": [[18, "transformer_lens.hook_points.HookPoint.clear_context"]], "clear_contexts() (transformer_lens.hook_points.hookedrootmodule method)": [[18, "transformer_lens.hook_points.HookedRootModule.clear_contexts"]], "context_level (transformer_lens.hook_points.lenshandle attribute)": [[18, "transformer_lens.hook_points.LensHandle.context_level"]], "forward() (transformer_lens.hook_points.hookpoint method)": [[18, "transformer_lens.hook_points.HookPoint.forward"]], "get_caching_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[18, "transformer_lens.hook_points.HookedRootModule.get_caching_hooks"]], "hook (transformer_lens.hook_points.lenshandle attribute)": [[18, "transformer_lens.hook_points.LensHandle.hook"]], "hook_points() (transformer_lens.hook_points.hookedrootmodule method)": [[18, "transformer_lens.hook_points.HookedRootModule.hook_points"]], "hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[18, "transformer_lens.hook_points.HookedRootModule.hooks"]], "is_permanent (transformer_lens.hook_points.lenshandle attribute)": [[18, "transformer_lens.hook_points.LensHandle.is_permanent"]], "layer() (transformer_lens.hook_points.hookpoint method)": [[18, "transformer_lens.hook_points.HookPoint.layer"]], "remove_all_hook_fns() (transformer_lens.hook_points.hookedrootmodule method)": [[18, "transformer_lens.hook_points.HookedRootModule.remove_all_hook_fns"]], "remove_hooks() (transformer_lens.hook_points.hookpoint method)": [[18, "transformer_lens.hook_points.HookPoint.remove_hooks"]], "reset_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[18, "transformer_lens.hook_points.HookedRootModule.reset_hooks"]], "run_with_cache() (transformer_lens.hook_points.hookedrootmodule method)": [[18, "transformer_lens.hook_points.HookedRootModule.run_with_cache"]], "run_with_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[18, "transformer_lens.hook_points.HookedRootModule.run_with_hooks"]], "setup() (transformer_lens.hook_points.hookedrootmodule method)": [[18, "transformer_lens.hook_points.HookedRootModule.setup"]], "transformer_lens.hook_points": [[18, "module-transformer_lens.hook_points"]], "config (class in transformer_lens.loading_from_pretrained)": [[19, "transformer_lens.loading_from_pretrained.Config"]], "model_aliases (in module transformer_lens.loading_from_pretrained)": [[19, "transformer_lens.loading_from_pretrained.MODEL_ALIASES"]], "non_hf_hosted_model_names (in module transformer_lens.loading_from_pretrained)": [[19, "transformer_lens.loading_from_pretrained.NON_HF_HOSTED_MODEL_NAMES"]], "official_model_names (in module transformer_lens.loading_from_pretrained)": [[19, "transformer_lens.loading_from_pretrained.OFFICIAL_MODEL_NAMES"]], "convert_bloom_weights() (in module transformer_lens.loading_from_pretrained)": [[19, "transformer_lens.loading_from_pretrained.convert_bloom_weights"]], "convert_coder_weights() (in module transformer_lens.loading_from_pretrained)": [[19, "transformer_lens.loading_from_pretrained.convert_coder_weights"]], "convert_mistral_weights() (in module transformer_lens.loading_from_pretrained)": [[19, "transformer_lens.loading_from_pretrained.convert_mistral_weights"]], "convert_mixtral_weights() (in module transformer_lens.loading_from_pretrained)": [[19, "transformer_lens.loading_from_pretrained.convert_mixtral_weights"]], "convert_phi_weights() (in module transformer_lens.loading_from_pretrained)": [[19, "transformer_lens.loading_from_pretrained.convert_phi_weights"]], "convert_qwen2_weights() (in module transformer_lens.loading_from_pretrained)": [[19, "transformer_lens.loading_from_pretrained.convert_qwen2_weights"]], "convert_qwen_weights() (in module transformer_lens.loading_from_pretrained)": [[19, "transformer_lens.loading_from_pretrained.convert_qwen_weights"]], "d_head (transformer_lens.loading_from_pretrained.config attribute)": [[19, "transformer_lens.loading_from_pretrained.Config.d_head"]], "d_mlp (transformer_lens.loading_from_pretrained.config attribute)": [[19, "transformer_lens.loading_from_pretrained.Config.d_mlp"]], "d_model (transformer_lens.loading_from_pretrained.config attribute)": [[19, "transformer_lens.loading_from_pretrained.Config.d_model"]], "d_vocab (transformer_lens.loading_from_pretrained.config attribute)": [[19, "transformer_lens.loading_from_pretrained.Config.d_vocab"]], "debug (transformer_lens.loading_from_pretrained.config attribute)": [[19, "transformer_lens.loading_from_pretrained.Config.debug"]], "get_checkpoint_labels() (in module transformer_lens.loading_from_pretrained)": [[19, "transformer_lens.loading_from_pretrained.get_checkpoint_labels"]], "get_num_params_of_pretrained() (in module transformer_lens.loading_from_pretrained)": [[19, "transformer_lens.loading_from_pretrained.get_num_params_of_pretrained"]], "get_pretrained_model_config() (in module transformer_lens.loading_from_pretrained)": [[19, "transformer_lens.loading_from_pretrained.get_pretrained_model_config"]], "init_range (transformer_lens.loading_from_pretrained.config attribute)": [[19, "transformer_lens.loading_from_pretrained.Config.init_range"]], "layer_norm_eps (transformer_lens.loading_from_pretrained.config attribute)": [[19, "transformer_lens.loading_from_pretrained.Config.layer_norm_eps"]], "n_ctx (transformer_lens.loading_from_pretrained.config attribute)": [[19, "transformer_lens.loading_from_pretrained.Config.n_ctx"]], "n_heads (transformer_lens.loading_from_pretrained.config attribute)": [[19, "transformer_lens.loading_from_pretrained.Config.n_heads"]], "n_layers (transformer_lens.loading_from_pretrained.config attribute)": [[19, "transformer_lens.loading_from_pretrained.Config.n_layers"]], "transformer_lens.loading_from_pretrained": [[19, "module-transformer_lens.loading_from_pretrained"]], "hookedtransformerkeyvaluecache (class in transformer_lens.past_key_value_caching)": [[20, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache"]], "hookedtransformerkeyvaluecacheentry (class in transformer_lens.past_key_value_caching)": [[20, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry"]], "append() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry method)": [[20, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.append"]], "append_attention_mask() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[20, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.append_attention_mask"]], "entries (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[20, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.entries"]], "freeze() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[20, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.freeze"]], "frozen (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[20, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.frozen"]], "frozen (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[20, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.frozen"]], "init_cache() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache class method)": [[20, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.init_cache"]], "init_cache_entry() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry class method)": [[20, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.init_cache_entry"]], "past_keys (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[20, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.past_keys"]], "past_values (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[20, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.past_values"]], "previous_attention_mask (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[20, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.previous_attention_mask"]], "transformer_lens.past_key_value_caching": [[20, "module-transformer_lens.past_key_value_caching"]], "unfreeze() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[20, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.unfreeze"]], "generic_activation_patch() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.generic_activation_patch"]], "get_act_patch_attn_head_all_pos_every() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_attn_head_all_pos_every"]], "get_act_patch_attn_head_by_pos_every() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_attn_head_by_pos_every"]], "get_act_patch_attn_head_k_all_pos() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_attn_head_k_all_pos"]], "get_act_patch_attn_head_k_by_pos() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_attn_head_k_by_pos"]], "get_act_patch_attn_head_out_all_pos() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_attn_head_out_all_pos"]], "get_act_patch_attn_head_out_by_pos() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_attn_head_out_by_pos"]], "get_act_patch_attn_head_pattern_all_pos() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_attn_head_pattern_all_pos"]], "get_act_patch_attn_head_pattern_by_pos() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_attn_head_pattern_by_pos"]], "get_act_patch_attn_head_pattern_dest_src_pos() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_attn_head_pattern_dest_src_pos"]], "get_act_patch_attn_head_q_all_pos() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_attn_head_q_all_pos"]], "get_act_patch_attn_head_q_by_pos() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_attn_head_q_by_pos"]], "get_act_patch_attn_head_v_all_pos() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_attn_head_v_all_pos"]], "get_act_patch_attn_head_v_by_pos() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_attn_head_v_by_pos"]], "get_act_patch_attn_out() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_attn_out"]], "get_act_patch_block_every() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_block_every"]], "get_act_patch_mlp_out() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_mlp_out"]], "get_act_patch_resid_mid() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_resid_mid"]], "get_act_patch_resid_pre() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.get_act_patch_resid_pre"]], "layer_head_dest_src_pos_pattern_patch_setter() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.layer_head_dest_src_pos_pattern_patch_setter"]], "layer_head_pattern_patch_setter() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.layer_head_pattern_patch_setter"]], "layer_head_pos_pattern_patch_setter() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.layer_head_pos_pattern_patch_setter"]], "layer_head_vector_patch_setter() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.layer_head_vector_patch_setter"]], "layer_pos_head_vector_patch_setter() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.layer_pos_head_vector_patch_setter"]], "layer_pos_patch_setter() (in module transformer_lens.patching)": [[21, "transformer_lens.patching.layer_pos_patch_setter"]], "transformer_lens.patching": [[21, "module-transformer_lens.patching"]], "hookedtransformertrainconfig (class in transformer_lens.train)": [[22, "transformer_lens.train.HookedTransformerTrainConfig"]], "batch_size (transformer_lens.train.hookedtransformertrainconfig attribute)": [[22, "transformer_lens.train.HookedTransformerTrainConfig.batch_size"]], "device (transformer_lens.train.hookedtransformertrainconfig attribute)": [[22, "transformer_lens.train.HookedTransformerTrainConfig.device"]], "lr (transformer_lens.train.hookedtransformertrainconfig attribute)": [[22, "transformer_lens.train.HookedTransformerTrainConfig.lr"]], "max_grad_norm (transformer_lens.train.hookedtransformertrainconfig attribute)": [[22, "transformer_lens.train.HookedTransformerTrainConfig.max_grad_norm"]], "max_steps (transformer_lens.train.hookedtransformertrainconfig attribute)": [[22, "transformer_lens.train.HookedTransformerTrainConfig.max_steps"]], "momentum (transformer_lens.train.hookedtransformertrainconfig attribute)": [[22, "transformer_lens.train.HookedTransformerTrainConfig.momentum"]], "num_epochs (transformer_lens.train.hookedtransformertrainconfig attribute)": [[22, "transformer_lens.train.HookedTransformerTrainConfig.num_epochs"]], "optimizer_name (transformer_lens.train.hookedtransformertrainconfig attribute)": [[22, "transformer_lens.train.HookedTransformerTrainConfig.optimizer_name"]], "print_every (transformer_lens.train.hookedtransformertrainconfig attribute)": [[22, "transformer_lens.train.HookedTransformerTrainConfig.print_every"]], "save_dir (transformer_lens.train.hookedtransformertrainconfig attribute)": [[22, "transformer_lens.train.HookedTransformerTrainConfig.save_dir"]], "save_every (transformer_lens.train.hookedtransformertrainconfig attribute)": [[22, "transformer_lens.train.HookedTransformerTrainConfig.save_every"]], "seed (transformer_lens.train.hookedtransformertrainconfig attribute)": [[22, "transformer_lens.train.HookedTransformerTrainConfig.seed"]], "train() (in module transformer_lens.train)": [[22, "transformer_lens.train.train"]], "transformer_lens.train": [[22, "module-transformer_lens.train"]], "wandb (transformer_lens.train.hookedtransformertrainconfig attribute)": [[22, "transformer_lens.train.HookedTransformerTrainConfig.wandb"]], "wandb_project_name (transformer_lens.train.hookedtransformertrainconfig attribute)": [[22, "transformer_lens.train.HookedTransformerTrainConfig.wandb_project_name"]], "warmup_steps (transformer_lens.train.hookedtransformertrainconfig attribute)": [[22, "transformer_lens.train.HookedTransformerTrainConfig.warmup_steps"]], "weight_decay (transformer_lens.train.hookedtransformertrainconfig attribute)": [[22, "transformer_lens.train.HookedTransformerTrainConfig.weight_decay"]], "get_device_for_block_index() (in module transformer_lens.utilities.devices)": [[24, "transformer_lens.utilities.devices.get_device_for_block_index"]], "move_to_and_update_config() (in module transformer_lens.utilities.devices)": [[24, "transformer_lens.utilities.devices.move_to_and_update_config"]], "transformer_lens.utilities.devices": [[24, "module-transformer_lens.utilities.devices"]], "locallyoverridendefaults (class in transformer_lens.utils)": [[25, "transformer_lens.utils.LocallyOverridenDefaults"]], "slice (class in transformer_lens.utils)": [[25, "transformer_lens.utils.Slice"]], "sliceinput (in module transformer_lens.utils)": [[25, "transformer_lens.utils.SliceInput"]], "__init__() (transformer_lens.utils.locallyoverridendefaults method)": [[25, "transformer_lens.utils.LocallyOverridenDefaults.__init__"]], "__init__() (transformer_lens.utils.slice method)": [[25, "transformer_lens.utils.Slice.__init__"]], "apply() (transformer_lens.utils.slice method)": [[25, "transformer_lens.utils.Slice.apply"]], "calc_fan_in_and_fan_out() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.calc_fan_in_and_fan_out"]], "composition_scores() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.composition_scores"]], "download_file_from_hf() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.download_file_from_hf"]], "gelu_fast() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.gelu_fast"]], "gelu_new() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.gelu_new"]], "get_act_name() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.get_act_name"]], "get_attention_mask() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.get_attention_mask"]], "get_corner() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.get_corner"]], "get_cumsum_along_dim() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.get_cumsum_along_dim"]], "get_dataset() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.get_dataset"]], "get_device() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.get_device"]], "get_input_with_manually_prepended_bos() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.get_input_with_manually_prepended_bos"]], "get_nested_attr() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.get_nested_attr"]], "get_offset_position_ids() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.get_offset_position_ids"]], "get_tokenizer_with_bos() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.get_tokenizer_with_bos"]], "get_tokens_with_bos_removed() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.get_tokens_with_bos_removed"]], "indices() (transformer_lens.utils.slice method)": [[25, "transformer_lens.utils.Slice.indices"]], "init_kaiming_normal_() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.init_kaiming_normal_"]], "init_kaiming_uniform_() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.init_kaiming_uniform_"]], "init_xavier_normal_() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.init_xavier_normal_"]], "init_xavier_uniform_() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.init_xavier_uniform_"]], "is_lower_triangular() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.is_lower_triangular"]], "is_square() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.is_square"]], "keep_single_column() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.keep_single_column"]], "lm_accuracy() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.lm_accuracy"]], "lm_cross_entropy_loss() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.lm_cross_entropy_loss"]], "override_or_use_default_value() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.override_or_use_default_value"]], "print_gpu_mem() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.print_gpu_mem"]], "remove_batch_dim() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.remove_batch_dim"]], "repeat_along_head_dimension() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.repeat_along_head_dimension"]], "sample_logits() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.sample_logits"]], "set_nested_attr() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.set_nested_attr"]], "slice (transformer_lens.utils.slice attribute)": [[25, "transformer_lens.utils.Slice.slice"]], "solu() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.solu"]], "test_prompt() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.test_prompt"]], "to_numpy() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.to_numpy"]], "tokenize_and_concatenate() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.tokenize_and_concatenate"]], "transformer_lens.utils": [[25, "module-transformer_lens.utils"]], "transpose() (in module transformer_lens.utils)": [[25, "transformer_lens.utils.transpose"]]}})