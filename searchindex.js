Search.setIndex({"docnames": ["content/citation", "content/contributing", "content/gallery", "content/getting_started", "content/getting_started_mech_interp", "content/news/release-2.0", "content/special_cases", "content/tutorials", "generated/code/modules", "generated/code/transformer_lens", "generated/code/transformer_lens.ActivationCache", "generated/code/transformer_lens.FactoredMatrix", "generated/code/transformer_lens.HookedEncoder", "generated/code/transformer_lens.HookedTransformer", "generated/code/transformer_lens.HookedTransformerConfig", "generated/code/transformer_lens.SVDInterpreter", "generated/code/transformer_lens.components", "generated/code/transformer_lens.components.abstract_attention", "generated/code/transformer_lens.components.attention", "generated/code/transformer_lens.components.bert_block", "generated/code/transformer_lens.components.bert_embed", "generated/code/transformer_lens.components.bert_mlm_head", "generated/code/transformer_lens.components.embed", "generated/code/transformer_lens.components.gated_mlp", "generated/code/transformer_lens.components.grouped_query_attention", "generated/code/transformer_lens.components.layer_norm", "generated/code/transformer_lens.components.layer_norm_pre", "generated/code/transformer_lens.components.mlp", "generated/code/transformer_lens.components.moe", "generated/code/transformer_lens.components.pos_embed", "generated/code/transformer_lens.components.rms_norm", "generated/code/transformer_lens.components.rms_norm_pre", "generated/code/transformer_lens.components.token_typed_embed", "generated/code/transformer_lens.components.transformer_block", "generated/code/transformer_lens.components.unembed", "generated/code/transformer_lens.evals", "generated/code/transformer_lens.head_detector", "generated/code/transformer_lens.hook_points", "generated/code/transformer_lens.loading_from_pretrained", "generated/code/transformer_lens.past_key_value_caching", "generated/code/transformer_lens.patching", "generated/code/transformer_lens.train", "generated/code/transformer_lens.utilities", "generated/code/transformer_lens.utilities.devices", "generated/code/transformer_lens.utils", "generated/demos/Exploratory_Analysis_Demo", "generated/demos/Main_Demo", "generated/model_properties_table", "index"], "filenames": ["content/citation.md", "content/contributing.md", "content/gallery.md", "content/getting_started.md", "content/getting_started_mech_interp.md", "content/news/release-2.0.md", "content/special_cases.md", "content/tutorials.md", "generated/code/modules.rst", "generated/code/transformer_lens.rst", "generated/code/transformer_lens.ActivationCache.rst", "generated/code/transformer_lens.FactoredMatrix.rst", "generated/code/transformer_lens.HookedEncoder.rst", "generated/code/transformer_lens.HookedTransformer.rst", "generated/code/transformer_lens.HookedTransformerConfig.rst", "generated/code/transformer_lens.SVDInterpreter.rst", "generated/code/transformer_lens.components.rst", "generated/code/transformer_lens.components.abstract_attention.rst", "generated/code/transformer_lens.components.attention.rst", "generated/code/transformer_lens.components.bert_block.rst", "generated/code/transformer_lens.components.bert_embed.rst", "generated/code/transformer_lens.components.bert_mlm_head.rst", "generated/code/transformer_lens.components.embed.rst", "generated/code/transformer_lens.components.gated_mlp.rst", "generated/code/transformer_lens.components.grouped_query_attention.rst", "generated/code/transformer_lens.components.layer_norm.rst", "generated/code/transformer_lens.components.layer_norm_pre.rst", "generated/code/transformer_lens.components.mlp.rst", "generated/code/transformer_lens.components.moe.rst", "generated/code/transformer_lens.components.pos_embed.rst", "generated/code/transformer_lens.components.rms_norm.rst", "generated/code/transformer_lens.components.rms_norm_pre.rst", "generated/code/transformer_lens.components.token_typed_embed.rst", "generated/code/transformer_lens.components.transformer_block.rst", "generated/code/transformer_lens.components.unembed.rst", "generated/code/transformer_lens.evals.rst", "generated/code/transformer_lens.head_detector.rst", "generated/code/transformer_lens.hook_points.rst", "generated/code/transformer_lens.loading_from_pretrained.rst", "generated/code/transformer_lens.past_key_value_caching.rst", "generated/code/transformer_lens.patching.rst", "generated/code/transformer_lens.train.rst", "generated/code/transformer_lens.utilities.rst", "generated/code/transformer_lens.utilities.devices.rst", "generated/code/transformer_lens.utils.rst", "generated/demos/Exploratory_Analysis_Demo.ipynb", "generated/demos/Main_Demo.ipynb", "generated/model_properties_table.md", "index.md"], "titles": ["Citation", "Contributing", "Gallery", "Getting Started", "Getting Started in Mechanistic Interpretability", "TransformerLens 2.0", "Special Cases", "Tutorials", "Transformer Lens API", "transformer_lens", "transformer_lens.ActivationCache", "transformer_lens.FactoredMatrix", "transformer_lens.HookedEncoder", "transformer_lens.HookedTransformer", "transformer_lens.HookedTransformerConfig", "transformer_lens.SVDInterpreter", "transformer_lens.components", "transformer_lens.components.abstract_attention", "transformer_lens.components.attention", "transformer_lens.components.bert_block", "transformer_lens.components.bert_embed", "transformer_lens.components.bert_mlm_head", "transformer_lens.components.embed", "transformer_lens.components.gated_mlp", "transformer_lens.components.grouped_query_attention", "transformer_lens.components.layer_norm", "transformer_lens.components.layer_norm_pre", "transformer_lens.components.mlp", "transformer_lens.components.moe", "transformer_lens.components.pos_embed", "transformer_lens.components.rms_norm", "transformer_lens.components.rms_norm_pre", "transformer_lens.components.token_typed_embed", "transformer_lens.components.transformer_block", "transformer_lens.components.unembed", "transformer_lens.evals", "transformer_lens.head_detector", "transformer_lens.hook_points", "transformer_lens.loading_from_pretrained", "transformer_lens.past_key_value_caching", "transformer_lens.patching", "transformer_lens.train", "transformer_lens.utilities", "transformer_lens.utilities.devices", "transformer_lens.utils", "Exploratory Analysis Demo", "Transformer Lens Main Demo Notebook", "Model Properties Table", "TransformerLens"], "terms": {"pleas": [0, 1, 3, 4, 5, 46], "cite": 0, "thi": [0, 1, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 48], "librari": [0, 2, 3, 4, 5, 7, 10, 35, 44, 45], "misc": 0, "nanda2022transformerlen": 0, "titl": [0, 1, 45, 46], "transformerlen": [0, 2, 3, 4, 7, 10, 13, 17, 38, 44, 45, 46], "author": [0, 45], "neel": [0, 2, 4, 7, 13, 15, 46], "nanda": [0, 2, 4, 13, 46], "joseph": [0, 5], "bloom": [0, 5, 17, 38, 47], "year": 0, "2022": [0, 44], "howpublish": 0, "url": [0, 3], "http": [0, 1, 3, 7, 10, 13, 14, 17, 24, 32, 35, 36, 40, 44, 45, 46], "github": [0, 1, 3, 7, 13], "com": [0, 3, 7, 10, 13, 17, 45, 46], "transformerlensorg": [0, 3, 7], "For": [1, 5, 10, 12, 13, 17, 32, 36, 44, 45], "one": [1, 3, 4, 5, 10, 12, 13, 14, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 36, 37, 38, 39, 40, 44, 45, 46, 48], "click": [1, 46], "your": [1, 3, 5, 7, 13, 14, 36, 37, 45, 46], "develop": [1, 5, 7, 45, 46], "environ": [1, 3], "project": [1, 5, 7, 10, 17, 24, 41, 45], "includ": [1, 4, 5, 7, 10, 12, 13, 14, 35, 36, 37, 45], "It": [1, 3, 5, 7, 10, 12, 13, 14, 17, 35, 37, 40, 44, 45, 46, 48], "can": [1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 18, 24, 35, 36, 37, 38, 39, 40, 44, 45, 46, 48], "us": [1, 2, 3, 5, 6, 7, 10, 12, 13, 14, 15, 17, 18, 24, 26, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48], "local": [1, 13, 14, 17, 18, 24, 38, 44, 46], "v": [1, 10, 12, 13, 14, 17, 24, 40, 45, 46], "code": [1, 4, 5, 10, 13, 14, 17, 35, 36, 37, 38, 44, 45, 46], "codespac": 1, "poetri": 1, "packag": 1, "manag": [1, 5, 10, 13, 37, 44], "instal": [1, 5, 45, 46], "follow": [1, 3, 5, 10, 13, 44, 46, 48], "also": [1, 5, 7, 10, 12, 13, 14, 15, 36, 37, 38, 43, 44, 45, 46], "virtual": 1, "config": [1, 13, 14, 17, 18, 24, 38, 40, 41], "virtualenv": 1, "true": [1, 10, 12, 13, 14, 35, 36, 37, 38, 40, 43, 44, 45, 46], "dev": 1, "doc": [1, 5, 8, 10, 13, 46], "jupyt": 1, "If": [1, 3, 5, 8, 10, 12, 13, 14, 25, 30, 32, 36, 37, 38, 40, 43, 44, 45, 46], "ad": [1, 7, 13, 14, 17, 37, 45, 46], "featur": [1, 3, 5, 7, 12, 15, 17, 40, 44, 45, 48], "add": [1, 5, 13, 14, 17, 37, 39, 44, 45, 46, 48], "unit": [1, 5], "you": [1, 3, 4, 5, 7, 10, 12, 13, 14, 15, 35, 36, 37, 38, 44, 45, 46, 48], "need": [1, 3, 5, 10, 13, 14, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37, 44, 45, 46, 48], "model": [1, 2, 3, 6, 7, 10, 12, 13, 14, 15, 17, 18, 20, 24, 35, 36, 37, 38, 40, 41, 43, 44, 45], "ones": [1, 12, 13, 36, 45], "ar": [1, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 17, 19, 24, 35, 36, 37, 38, 39, 40, 44, 46, 48], "cach": [1, 10, 13, 14, 33, 36, 37, 39, 40, 44, 45, 48], "action": [1, 2, 45], "so": [1, 5, 7, 10, 11, 12, 13, 14, 15, 35, 37, 38, 39, 40, 44, 45, 46], "quickli": [1, 5, 7], "cd": [1, 45, 46], "These": [1, 45, 46], "gpt2": [1, 13, 14, 15, 17, 18, 24, 35, 38, 45, 46, 47], "attn": [1, 10, 12, 13, 14, 17, 38, 40, 44, 45, 46, 47], "onli": [1, 2, 5, 10, 11, 12, 13, 14, 17, 18, 24, 26, 33, 36, 37, 38, 44, 45, 46, 47], "1l": [1, 38, 45, 46, 47], "2l": [1, 13, 38, 46, 47], "3l": [1, 38, 46, 47], "4l": [1, 38, 46, 47], "tini": [1, 10, 13, 38, 44, 45, 46, 47], "stori": [1, 10, 13, 38, 40, 44, 45, 47], "1m": [1, 10, 13, 38, 44, 47], "note": [1, 3, 5, 10, 11, 12, 13, 14, 17, 24, 35, 37, 38, 44, 45, 46], "i": [1, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 21, 24, 26, 32, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 48], "quit": [1, 5], "slow": [1, 46], "we": [1, 2, 5, 8, 10, 13, 14, 36, 39, 40, 44, 45, 46, 48], "have": [1, 3, 5, 10, 12, 13, 17, 18, 24, 36, 40, 44, 45, 46, 48], "cpu": [1, 10, 12, 13, 14, 17, 38, 45, 46], "smaller": [1, 5, 46], "like": [1, 3, 4, 5, 7, 12, 13, 20, 35, 36, 40, 44, 45, 46, 48], "prefer": 1, "possibl": [1, 5, 12, 13, 36, 40, 44, 45, 46, 48], "via": [1, 2, 3, 4, 5, 12, 13, 40, 45], "make": [1, 3, 5, 7, 11, 12, 13, 36, 37, 45, 46, 48], "accept": [1, 3, 5, 12, 13, 37, 45], "notebook": [1, 3, 7, 45, 48], "all": [1, 4, 5, 10, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 44, 45], "suit": 1, "mention": [1, 5, 46], "pycln": 1, "isort": 1, "black": [1, 46], "pull": [1, 5], "request": [1, 5], "check": [1, 3, 5, 7, 13, 15, 17, 35, 36, 37, 44, 45, 46], "file": [1, 5, 44], "line": [1, 5, 45, 46], "length": [1, 10, 12, 13, 14, 17, 25, 26, 29, 30, 31, 44, 45, 46], "set": [1, 2, 5, 10, 12, 13, 14, 17, 35, 36, 37, 40, 41, 44, 45, 46], "100": [1, 35, 45, 46], "pyproject": 1, "toml": 1, "instead": [1, 6, 10, 13, 14, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37, 45, 46], "default": [1, 6, 10, 13, 14, 15, 17, 18, 24, 29, 33, 35, 36, 37, 38, 40, 44, 45, 46], "88": [1, 46], "sure": [1, 3, 5, 13, 44, 45, 46], "thorough": 1, "ani": [1, 3, 10, 12, 13, 14, 17, 18, 24, 37, 44, 45, 46, 48], "should": [1, 5, 7, 10, 12, 13, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 36, 37, 41, 44, 45, 46], "do": [1, 3, 4, 5, 7, 10, 12, 13, 17, 35, 37, 40, 44, 45, 46, 48], "directli": [1, 5, 12, 14, 44, 45, 46], "automat": [1, 5, 7, 13, 14, 44, 45, 46], "gener": [1, 5, 7, 13, 17, 33, 35, 39, 40, 44, 45], "api": [1, 5, 37, 45], "when": [1, 3, 5, 7, 10, 11, 12, 13, 14, 24, 33, 35, 37, 38, 39, 40, 44, 45, 46], "merg": [1, 5, 13], "main": [1, 3, 5, 6, 7, 10, 37, 45], "thei": [1, 4, 5, 13, 14, 17, 35, 40, 44, 45, 46, 48], "pytest": 1, "doctest": 1, "want": [1, 5, 7, 10, 13, 15, 35, 36, 37, 39, 44, 45, 46], "view": [1, 2], "chang": [1, 2, 3, 5, 13, 14, 37, 38, 40, 44, 45, 46], "hot": [1, 45, 46], "reload": [1, 45, 46], "give": [1, 5, 10, 13, 14, 35, 38, 40, 44, 45, 46], "real": [1, 7, 44, 45, 46, 48], "time": [1, 5, 7, 8, 10, 13, 36, 37, 44, 45, 46], "edit": [1, 7, 13, 40, 45, 46, 48], "googl": [1, 7, 38, 45, 46], "python": [1, 2, 14, 35, 38, 44, 46, 47], "write": [1, 2, 3, 5, 13, 44, 45, 46, 48], "some": [1, 3, 5, 10, 13, 15, 17, 35, 37, 40, 44, 45], "from": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 24, 32, 35, 36, 38, 40, 44, 45, 46, 48], "restructuredtext": 1, "rest": [1, 5, 10, 13, 14, 35, 38, 44, 46], "In": [1, 2, 5, 6, 10, 12, 13, 23, 35, 37, 45, 46], "case": [1, 2, 5, 10, 13, 14, 35, 36, 37, 38, 40, 44, 45, 47], "A": [1, 2, 4, 5, 10, 11, 12, 13, 17, 24, 32, 33, 35, 37, 39, 40, 44, 45, 46], "descript": 1, "what": [1, 3, 5, 7, 10, 13, 36, 40, 46, 48], "doe": [1, 5, 10, 12, 13, 14, 36, 37, 40, 44, 45, 46], "much": [1, 5, 10, 13, 35, 36, 40, 44, 45, 46], "detail": [1, 5, 10, 13, 14, 17, 24, 33, 38, 40, 44, 45, 46], "necessari": [1, 5, 46], "fulli": [1, 40, 45], "understand": [1, 10, 13, 36, 46], "warn": [1, 10, 13, 36, 37, 44], "user": [1, 2, 5, 14, 44, 46], "e": [1, 5, 10, 12, 13, 17, 36, 37, 38, 44, 45, 46, 47], "g": [1, 5, 10, 12, 13, 36, 37, 44, 46], "common": [1, 5, 7, 10, 13, 14, 17, 44, 45, 46], "pitfal": 1, "exampl": [1, 2, 10, 12, 13, 15, 17, 32, 35, 37, 44, 45], "here": [1, 2, 3, 5, 13, 14, 17, 18, 24, 35, 36, 44, 45, 46], "print": [1, 10, 35, 41, 44, 45, 46], "1": [1, 3, 4, 5, 10, 12, 13, 14, 17, 18, 19, 24, 32, 36, 37, 38, 39, 44, 45, 46, 47], "2": [1, 3, 4, 10, 12, 13, 14, 17, 35, 36, 38, 44, 45, 46, 47, 48], "3": [1, 6, 10, 11, 12, 13, 17, 35, 38, 40, 44, 45, 46, 47, 48], "arg": [1, 24, 37], "param_without_type_signatur": 1, "each": [1, 5, 10, 11, 12, 13, 14, 17, 36, 37, 38, 39, 40, 44, 45, 46], "indent": 1, "onc": [1, 3, 5, 13, 44, 45, 46], "more": [1, 5, 7, 10, 11, 13, 14, 17, 32, 36, 40, 44, 45, 46, 48], "param_2": 1, "anoth": [1, 5, 45, 46], "paramet": [1, 5, 7, 10, 12, 13, 14, 15, 17, 18, 24, 25, 26, 29, 33, 35, 36, 37, 38, 40, 43, 44, 45], "return": [1, 5, 10, 11, 12, 13, 17, 24, 29, 33, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46], "without": [1, 3, 5, 10, 13, 30, 31, 44, 45, 46], "type": [1, 6, 7, 10, 12, 13, 14, 15, 20, 24, 29, 32, 33, 36, 37, 38, 40, 41, 43, 44, 45, 46], "signatur": [1, 12, 13, 46], "rais": [1, 13, 36, 38, 44, 46], "inform": [1, 13, 14, 32, 37, 38, 45, 46], "about": [1, 5, 7, 10, 13, 35, 37, 40, 44, 45, 46, 48], "error": [1, 10, 13, 36, 38, 46], "mai": [1, 5, 10, 12, 13, 14, 17, 44, 45, 46], "part": [1, 5, 10, 13, 26, 40, 45, 46, 48], "codebas": [1, 46], "cross": [1, 10, 13, 44, 45, 46], "referenc": [1, 5], "omit": [1, 36, 46], "full": [1, 4, 5, 10, 12, 13, 14, 17, 44, 46], "path": [1, 4, 44], "same": [1, 3, 5, 10, 11, 13, 14, 17, 36, 37, 39, 40, 44, 45, 46], "mod": 1, "transformer_len": [1, 3, 5, 8, 45, 46], "modul": [1, 5, 8, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 44, 46], "const": 1, "loading_from_pretrain": [1, 8, 9, 13, 46], "official_model_nam": [1, 13, 38], "hookedtransform": [1, 3, 5, 6, 7, 8, 9, 10, 12, 14, 15, 35, 36, 38, 40, 41, 43, 44, 45, 46], "meth": [1, 10], "from_pretrain": [1, 3, 6, 10, 12, 13, 15, 35, 38, 44, 45, 46], "attr": 1, "cfg": [1, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 43, 44, 45, 46], "latex": 1, "re": [1, 3, 4, 7, 10, 13, 14, 36, 45, 46], "place": [1, 5, 7, 12, 13, 44, 45, 46], "string": [1, 12, 13, 14, 35, 36, 37, 38, 44, 45, 46], "backward": [1, 37, 45, 46], "slash": 1, "must": [1, 10, 12, 13, 14, 17, 36, 37, 44, 45, 46], "repeat": [1, 13, 35, 39, 44, 45, 46], "inlin": 1, "displai": [1, 45, 46], "mode": [1, 10, 13, 14, 17, 26, 44, 45, 46], "b": [1, 11, 12, 13, 32, 35, 38, 40, 44, 46, 47], "2ab": 1, "nowrap": 1, "begin": [1, 3, 5, 13, 35, 36, 44, 45, 46], "eqnarrai": 1, "y": [1, 10, 13, 36, 45, 46], "ax": [1, 13, 40, 46], "bx": 1, "c": [1, 38, 44, 46, 47], "f": [1, 45, 46], "x": [1, 5, 10, 13, 17, 23, 25, 26, 27, 28, 30, 31, 36, 37, 38, 44, 45, 46], "2xy": 1, "end": [1, 5, 7, 13, 37, 40, 44, 45, 46], "ital": 1, "text": [1, 7, 10, 13, 14, 17, 33, 35, 37, 38, 39, 44, 45], "bold": 1, "list": [1, 3, 4, 10, 12, 13, 14, 35, 36, 37, 39, 40, 44, 45, 46], "item": [1, 5, 10, 44, 45, 46], "number": [1, 5, 10, 13, 14, 15, 17, 35, 38, 40, 41, 43, 44, 45, 46], "quot": 1, "level": [1, 37, 45, 46, 48], "extern": [1, 45], "link": [1, 13, 35], "domain": 1, "invalid": 1, "research": [2, 3, 4, 5, 7, 45, 46, 48], "done": [2, 4, 5, 6, 10, 13, 14, 17, 37, 45, 46], "involv": [2, 5, 45, 46], "progress": [2, 5, 13, 46], "measur": [2, 35, 36, 40, 44, 45], "grokk": [2, 7], "mechanist": [2, 3, 7, 40, 45, 46], "interpret": [2, 3, 7, 10, 13, 15, 36, 40, 44, 45], "iclr": 2, "spotlight": 2, "2023": 2, "lawrenc": 2, "chan": 2, "tom": [2, 45], "lieberum": 2, "jess": 2, "smith": 2, "jacob": 2, "steinhardt": 2, "find": [2, 5, 7, 10, 11, 13, 40, 45, 46], "neuron": [2, 7, 10, 13, 45, 46], "haystack": 2, "studi": [2, 4, 40, 45, 46], "spars": [2, 5], "probe": 2, "gurne": 2, "matthew": 2, "pauli": 2, "katherin": 2, "harvei": 2, "dmitrii": 2, "troitskii": 2, "dimitri": 2, "bertsima": 2, "toward": [2, 17, 40, 45], "autom": 2, "circuit": [2, 12, 13, 17, 35, 36, 40, 44, 45, 46], "discoveri": 2, "arthur": [2, 46], "conmi": [2, 46], "augustin": 2, "n": [2, 17, 41, 44, 45, 46], "mavor": 2, "parker": 2, "aengu": 2, "lynch": 2, "stefan": 2, "heimersheim": 2, "adri\u00e0": 2, "garriga": 2, "alonso": 2, "actual": [2, 5, 13, 36, 37, 46], "othello": [2, 7, 38, 47], "gpt": [2, 3, 4, 7, 10, 12, 13, 14, 17, 18, 24, 35, 38, 44, 45, 46, 47, 48], "ha": [2, 3, 4, 5, 10, 11, 12, 13, 17, 24, 35, 38, 39, 40, 44, 45, 46], "linear": [2, 7, 12, 13, 17, 38, 45, 46], "emerg": [2, 7], "world": [2, 5, 7, 46, 48], "represent": [2, 7], "docstr": 2, "4": [2, 3, 5, 14, 17, 35, 44, 45, 46, 47], "layer": [2, 6, 10, 12, 13, 14, 15, 17, 18, 20, 24, 25, 26, 36, 37, 38, 39, 40, 43, 44, 46], "attent": [2, 7, 10, 12, 13, 14, 16, 17, 19, 24, 29, 33, 36, 40, 44, 46], "transform": [2, 3, 4, 7, 10, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 38, 39, 40, 44, 45], "jett": 2, "janiak": 2, "toi": [2, 13], "univers": 2, "icml": 2, "bilal": 2, "chughtai": 2, "n2g": 2, "scalabl": 2, "approach": [2, 5, 10, 45, 46], "quantifi": [2, 36], "larg": [2, 5, 7, 14, 17, 38, 44, 46, 47, 48], "languag": [2, 12, 13, 35, 41, 44, 45, 46], "workshop": 2, "rtml": 2, "alex": [2, 46], "foot": [2, 13, 46], "esben": 2, "kran": 2, "ioanni": 2, "konsta": 2, "fazl": 2, "barez": 2, "elicit": 2, "latent": 2, "predict": [2, 7, 10, 12, 13, 21, 35, 36, 44, 45, 46], "tune": [2, 12, 38, 44, 46, 47], "len": [2, 10, 38], "nora": 2, "belros": 2, "zach": 2, "furman": 2, "logan": 2, "danni": 2, "halawi": 2, "igor": 2, "ostrovski": 2, "lev": 2, "mckinnei": 2, "stella": 2, "biderman": 2, "contribut": [2, 5, 10, 13, 45], "being": [2, 5, 10, 12, 13, 14, 36, 37, 40, 44, 45, 46], "induct": [2, 4, 35, 36, 38], "head": [2, 4, 7, 10, 12, 13, 14, 15, 17, 21, 24, 35, 36, 38, 40, 44], "phase": 2, "replic": [2, 4, 13, 15, 35, 45, 46], "partial": [2, 45, 46], "context": [2, 10, 13, 37, 40, 44, 45, 46], "learn": [2, 3, 7, 14, 41, 44, 45, 46, 48], "connor": 2, "kissan": 2, "decis": [2, 3], "script": [2, 7], "train": [2, 7, 8, 9, 10, 12, 13, 14, 35, 38, 44, 45, 48], "which": [2, 3, 5, 6, 7, 10, 12, 13, 14, 35, 36, 37, 38, 39, 40, 44, 45, 46], "intermedi": [2, 10, 13, 37, 46], "activ": [2, 3, 4, 5, 7, 10, 12, 13, 14, 15, 37, 40, 44, 48], "perform": [2, 6, 7, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 35, 37, 44, 45, 46], "attribut": [2, 4, 7, 10, 17, 40, 44, 46], "ablat": [2, 45, 46], "up": [2, 3, 4, 5, 10, 13, 14, 37, 40, 41, 44, 45, 46], "initi": [2, 5, 8, 13, 14, 24, 37, 43, 44, 45, 46], "work": [2, 3, 4, 5, 7, 10, 12, 13, 17, 37, 38, 44, 45, 46, 48], "found": [2, 3, 5, 6, 13, 14, 45, 46], "demo": [3, 5, 15, 38, 47], "how": [3, 5, 7, 10, 13, 36, 40, 41, 45, 46, 48], "basic": [3, 7, 13, 35, 44, 45], "To": [3, 4, 5, 10, 13, 14, 17, 37, 38, 45, 46], "see": [3, 5, 7, 10, 12, 13, 14, 17, 24, 32, 33, 36, 38, 40, 44, 45, 46, 48], "exploratori": [3, 7, 36, 44, 46, 48], "analysi": [3, 7, 10, 13, 36, 44, 46, 48], "practic": [3, 4, 7, 45, 46], "look": [3, 4, 5, 7, 8, 10, 13, 17, 36, 40, 45, 46], "out": [3, 5, 7, 10, 13, 15, 40, 44, 45, 46], "my": [3, 5, 7, 13, 14, 44, 45, 46, 48], "analys": [3, 7, 10, 13, 46], "indirect": [3, 4, 7, 35], "object": [3, 4, 5, 7, 10, 11, 12, 13, 14, 15, 35, 37, 38, 39, 41, 44], "identif": [3, 4, 7, 35], "record": [3, 7, 46], "myself": [3, 5, 7, 46], "veri": [3, 4, 5, 7, 10, 14, 15, 35, 44, 45, 46, 48], "young": [3, 4, 46], "small": [3, 4, 5, 6, 7, 10, 13, 35, 38, 44, 45, 46, 47, 48], "field": [3, 4, 5, 13, 44, 46, 48], "lot": [3, 4, 5, 7, 10, 11, 39, 40, 44, 45, 46, 48], "open": [3, 4, 5, 13, 35, 48], "problem": [3, 4, 5, 46, 48], "would": [3, 4, 5, 12, 17, 32, 45, 46, 48], "help": [3, 4, 5, 14, 40, 45, 46], "try": [3, 4, 10, 13, 36, 45, 46], "concret": [3, 4, 45, 46], "figur": [3, 40, 45, 46], "where": [3, 5, 6, 10, 11, 12, 13, 14, 17, 36, 37, 38, 40, 41, 44, 45, 46], "skill": [3, 46], "kei": [3, 4, 5, 10, 12, 13, 14, 17, 18, 24, 33, 35, 36, 39, 40, 44, 45, 46], "resourc": [3, 4, 5], "new": [3, 7, 10, 13, 37, 38, 39, 44, 45, 46], "tutori": [3, 4, 5, 45, 46], "scratch": [3, 4, 45], "an": [3, 4, 7, 10, 11, 12, 13, 14, 17, 35, 36, 37, 38, 39, 40, 41, 44, 45, 48], "accompani": [3, 4, 7, 46], "templat": [3, 35], "yourself": [3, 13, 45, 46], "One": [3, 5, 13, 45, 46, 48], "signific": [3, 37, 45, 46], "design": [3, 5, 10, 45, 46, 48], "made": [3, 5, 35, 45, 46], "wa": [3, 5, 6, 10, 12, 13, 14, 35, 40, 45, 46], "singl": [3, 5, 10, 12, 13, 17, 32, 33, 39, 40, 44, 45, 46], "implement": [3, 5, 12, 13, 17, 40, 44, 45, 46], "could": [3, 5, 45, 46], "support": [3, 5, 7, 12, 13, 14, 36, 37, 44, 45, 46], "rang": [3, 4, 5, 13, 15, 36, 40, 44, 45, 46], "subtli": [3, 17], "differ": [3, 5, 6, 10, 12, 13, 14, 17, 35, 36, 37, 40, 44, 45, 46], "style": [3, 5, 10, 12, 13, 14, 18, 36, 45, 46, 48], "upsid": 3, "just": [3, 4, 5, 10, 13, 14, 35, 40, 44, 45, 46], "arbitrari": [3, 13, 45, 46], "name": [3, 5, 10, 13, 14, 35, 36, 37, 38, 40, 41, 44], "But": [3, 10, 13, 40, 44, 45, 46], "downsid": 3, "py": [3, 5, 12], "compon": [3, 8, 9, 10, 12, 13, 14, 44, 45, 46], "difficult": [3, 10], "recommend": [3, 8, 10, 13, 14, 15, 37, 45, 46], "clean": [3, 40, 44, 45, 46], "minim": [3, 5, 46], "intern": [3, 5, 10, 13, 40, 45, 46, 48], "architectur": [3, 12, 45], "significantli": [3, 12, 13, 35, 40, 45, 46], "clearer": 3, "better": [3, 13, 14, 35, 36, 38, 45, 46], "document": [3, 13, 44, 46], "pip": [3, 5, 45, 46], "git": 3, "import": [3, 5, 10, 13, 15, 35, 39, 40, 44, 48], "known": [3, 48], "easytransform": [3, 46, 48], "break": [3, 5, 10, 45, 46], "been": [3, 5, 10, 13, 44, 46], "sinc": [3, 5, 10, 13, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37, 45, 46], "renam": [3, 5], "old": [3, 5, 38, 46], "version": [3, 7, 13, 35, 37, 45, 46], "legaci": [3, 36], "run": [3, 5, 6, 10, 13, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37, 38, 39, 40, 41, 45, 48], "v1": 3, "avail": [3, 5, 7, 10, 13, 14, 36, 38], "requir": [3, 5, 12, 13, 40, 44], "luckili": 3, "provid": [3, 10, 12, 13, 25, 30, 32, 37, 43, 44], "wai": [3, 5, 6, 10, 13, 14, 37, 44, 45, 46], "those": [3, 5, 6, 13, 37, 44, 45], "configur": [3, 5, 14, 41, 43], "environment": 3, "variabl": [3, 12], "simpli": [3, 5, 45], "token": [3, 7, 10, 12, 13, 14, 15, 17, 18, 20, 21, 22, 24, 29, 32, 33, 35, 36, 38, 40, 44, 45], "hf_token": 3, "agreement": 3, "issu": [3, 5, 13, 45, 46], "attempt": [3, 5, 13], "ue": 3, "befor": [3, 10, 12, 13, 14, 17, 18, 19, 37, 44, 45, 46], "relat": [3, 13, 17, 45, 46], "consol": 3, "output": [3, 5, 7, 10, 12, 13, 14, 17, 36, 37, 40, 44, 45, 46], "point": [3, 5, 10, 12, 13, 14, 15, 37, 44, 45, 48], "As": [3, 13, 44, 45, 46], "23": [3, 45, 46], "24": [3, 13, 44, 45, 46, 47], "current": [3, 5, 10, 12, 13, 14, 17, 18, 24, 36, 45, 46], "co": [3, 44], "mistralai": [3, 38], "mixtral": [3, 5, 6, 38, 47], "8x7b": [3, 38], "v0": [3, 38, 47], "mistral": [3, 14, 17, 35, 38, 47], "7b": [3, 5, 7, 38, 46, 47], "instruct": [3, 38, 46, 47], "mean": [4, 5, 10, 13, 14, 15, 17, 18, 24, 30, 31, 36, 37, 44, 45, 46], "": [4, 5, 7, 10, 11, 12, 13, 14, 15, 17, 35, 36, 37, 38, 40, 43, 44, 46, 48], "both": [4, 5, 10, 13, 17, 36, 37, 39, 45, 46], "low": [4, 11, 13, 17, 44, 46], "hang": [4, 46], "fruit": [4, 46], "bar": [4, 13], "entri": [4, 17, 39, 40, 46], "The": [4, 5, 7, 10, 11, 12, 13, 14, 15, 17, 18, 21, 23, 24, 29, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48], "standard": [4, 6, 13, 14, 45, 46], "answer": [4, 10, 40, 44, 45, 46], "why": [4, 5, 10, 17, 44, 45, 46], "yet": [4, 5, 12, 13, 45, 46, 48], "aren": [4, 38, 46], "t": [4, 5, 10, 11, 12, 13, 14, 15, 17, 35, 38, 44, 45, 46, 48], "enough": [4, 5, 10, 45, 46], "peopl": [4, 5, 46], "guid": [4, 46], "arena": 4, "callum": [4, 46], "mcdougal": [4, 46], "comprehens": [4, 46], "introduct": 4, "mech": [4, 45], "interp": [4, 45], "written": [4, 5, 7, 45], "snippet": 4, "copi": [4, 12, 45], "come": [4, 5, 13, 14, 40, 45, 46], "exercis": [4, 45], "solut": [4, 5, 45, 46], "notabl": [4, 13, 37, 45, 46], "video": [4, 7, 45, 46], "me": [4, 5, 38, 46, 48], "good": [4, 5, 7, 10, 35, 44, 45, 46, 48], "cover": [4, 13, 46], "foundat": [4, 46], "concept": [4, 45, 46], "wild": [4, 10, 45, 46], "techniqu": [4, 7, 13, 40, 45, 46], "direct": [4, 5, 10, 13, 15, 37, 40, 46], "logit": [4, 5, 6, 7, 10, 12, 13, 21, 35, 40, 44, 46], "patch": [4, 5, 7, 8, 9], "paper": [4, 7, 10, 13, 14, 17, 32, 35, 40, 46], "read": [4, 5, 7, 10, 13, 46], "200": [4, 46], "explain": [4, 7, 45, 46], "jargon": 4, "unfamiliar": [4, 45], "term": [4, 10, 13, 45], "go": [4, 5, 7, 40, 46], "across": [4, 5, 10, 12, 13, 15, 38, 40, 43, 45, 46], "youtub": 4, "channel": 4, "content": [4, 35, 45, 46], "walkthrough": [4, 45, 46], "am": 5, "happi": 5, "announc": 5, "now": [5, 7, 13, 14, 45, 46], "releas": 5, "recent": 5, "primari": 5, "motiv": [5, 45], "behind": [5, 17, 45], "jump": [5, 46], "transit": [5, 45], "strictli": [5, 10, 46], "describ": [5, 14, 44, 45], "At": [5, 45], "last": [5, 10, 13, 44, 46], "minut": 5, "did": [5, 10, 44, 45, 46], "remov": [5, 10, 11, 13, 17, 37, 44, 45, 46, 48], "hookedsa": 5, "had": [5, 45, 46], "saelen": 5, "bundl": [5, 46], "major": 5, "hand": [5, 45, 46], "modif": 5, "affect": [5, 13, 40, 45], "bryce": 5, "meyer": 5, "softwar": 5, "engin": [5, 40, 45, 46, 48], "littl": [5, 46, 48], "under": [5, 10, 13, 24], "15": [5, 45, 46], "profession": [5, 7], "experi": [5, 7, 14, 45, 46, 48], "wide": 5, "expertis": 5, "embed": [5, 7, 10, 12, 13, 14, 17, 20, 21, 29, 33, 45, 46], "comput": [5, 10, 11, 13, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 36, 37, 39, 40, 44, 45, 46, 48], "coupl": 5, "gotten": [5, 13], "ml": [5, 45, 46, 48], "especi": [5, 13, 45, 46], "ai": [5, 14, 17, 38, 44, 46], "safeti": 5, "nine": 5, "march": 5, "chat": [5, 38, 46, 47], "bit": [5, 14, 45, 46], "he": [5, 46], "ask": 5, "might": [5, 10, 12, 45], "interest": [5, 7, 12, 13, 45, 46], "take": [5, 7, 10, 13, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37, 40, 44, 45, 46, 48], "role": 5, "maintain": 5, "basi": [5, 12, 13], "april": 5, "far": [5, 13, 44, 45, 46], "pretti": [5, 10, 13, 44, 45, 46], "mani": [5, 13, 24, 39, 40, 41, 45, 46], "kind": [5, 10, 45, 46], "address": 5, "everi": [5, 10, 12, 13, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37, 40, 41, 44, 45, 46], "await": 5, "repli": 5, "total": [5, 45, 46], "around": [5, 6, 10, 12, 13, 37, 40, 43, 45, 46], "30": [5, 45, 46, 47], "20": [5, 44, 45, 46, 47], "pr": 5, "were": [5, 10, 13, 14, 35, 44, 45, 46, 48], "limit": [5, 12, 13, 45], "llama": [5, 7, 14, 38, 47], "quantiz": [5, 14], "hookedsaetransform": 5, "brand": 5, "class": [5, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 44], "splice": 5, "autoencod": 5, "two": [5, 6, 11, 12, 32, 36, 38, 40, 44, 45, 46], "goal": [5, 45, 46, 48], "posit": [5, 7, 10, 12, 13, 14, 17, 20, 29, 33, 35, 36, 37, 38, 40, 44, 45, 46], "while": [5, 12, 13, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37, 45, 46], "remain": [5, 10, 13, 37, 46], "power": [5, 46], "who": 5, "push": 5, "second": [5, 13, 35, 45, 46], "base": [5, 7, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 43, 44, 45, 46, 47], "easier": [5, 13, 35, 45, 46, 48], "futur": 5, "llm": 5, "continu": [5, 40, 45, 46], "acceler": [5, 45, 46], "feel": [5, 45, 46, 48], "massiv": [5, 45, 46], "amount": [5, 10, 14, 45], "momentum": [5, 41], "moment": [5, 17, 18, 24], "hope": [5, 46], "carri": 5, "over": [5, 10, 13, 40, 44, 45, 46], "background": [5, 45], "know": [5, 7, 10, 12, 45, 46], "talk": [5, 46], "ensur": [5, 13, 45], "meet": 5, "person": [5, 45], "spoken": 5, "dozen": 5, "commun": 5, "happen": [5, 45, 46], "appoint": 5, "curiou": 5, "hear": 5, "anyon": [5, 35], "tool": [5, 7, 46, 48], "absolut": [5, 6, 12, 13, 14, 17, 29, 36, 44, 45, 46], "beginn": 5, "complet": [5, 10, 17, 45, 46], "expert": [5, 14], "Not": [5, 17, 18, 24, 26], "idea": [5, 13, 17, 40, 45, 46, 48], "evolv": 5, "biggest": [5, 10], "previous": [5, 45], "offici": [5, 38, 46], "instanc": [5, 12, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 36, 37, 45], "compat": [5, 13, 38], "through": [5, 13, 45, 46], "forward": [5, 10, 12, 13, 14, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 39, 46], "start": [5, 10, 13, 17, 40, 44, 45, 46], "todai": [5, 46, 48], "assur": 5, "abl": [5, 45, 46], "upgrad": 5, "worri": 5, "There": [5, 6, 10, 12, 36, 38, 44, 45, 46, 48], "right": [5, 12, 13, 17, 18, 40, 44, 45, 46], "move_model": [5, 10], "activationcach": [5, 8, 9, 12, 13, 36, 40, 44, 45, 46], "function": [5, 10, 12, 13, 14, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 36, 37, 38, 40, 41, 43, 44, 46, 48], "cache_al": [5, 37], "hook_point": [5, 8, 9, 13, 46], "keep": [5, 10, 13, 37, 45, 46, 48], "thing": [5, 11, 13, 14, 17, 40, 45, 46, 48], "simpl": [5, 45, 46], "howev": [5, 10, 13, 24, 35, 45, 46], "them": [5, 10, 13, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37, 40, 44, 45, 46], "adapt": [5, 46], "awai": [5, 13, 45], "along": [5, 13, 17, 44, 45, 46], "anyth": [5, 35, 45], "mark": [5, 45, 46], "whenev": [5, 37], "someth": [5, 13, 35, 45], "becom": [5, 45, 46], "promin": 5, "sort": [5, 46], "slip": 5, "scenario": 5, "situat": 5, "handl": [5, 13, 37], "persist": [5, 37], "allow": [5, 13, 36, 40, 44, 45, 46], "reli": 5, "interrupt": 5, "still": [5, 37, 45], "encourag": [5, 17, 44], "everyon": 5, "period": [5, 45, 46], "ey": 5, "don": [5, 10, 12, 13, 14, 15, 35, 44, 45, 46, 48], "imagin": [5, 45], "often": [5, 10, 13, 14, 38, 44, 45, 46], "save": [5, 10, 13, 14, 36, 41, 44, 45, 46], "troubl": [5, 10], "move": [5, 10, 12, 13, 40, 45, 46], "three": [5, 13, 40, 44, 45], "timefram": 5, "plan": 5, "state": [5, 10, 13, 37, 45, 46, 48], "tracker": 5, "categor": 5, "easi": [5, 10, 13, 44, 45, 46, 48], "date": [5, 13], "below": [5, 12, 13, 45], "draft": 5, "our": [5, 45, 46], "priorit": 5, "feedback": [5, 44, 45, 46, 48], "surfac": 5, "other": [5, 10, 12, 13, 17, 18, 24, 36, 37, 38, 40, 45], "improv": [5, 44, 45, 46], "achiev": [5, 10, 46], "diagnos": 5, "variou": [5, 14, 37, 45, 46], "area": 5, "memori": [5, 10, 11, 12, 13, 14, 45, 46], "leak": 5, "occur": [5, 45, 46], "seem": [5, 13, 14, 35, 38, 45, 46], "refer": [5, 10, 13, 18, 37, 45, 46], "properli": [5, 35, 45], "thu": 5, "caus": 5, "garbag": 5, "collect": 5, "correctli": [5, 13], "identifi": [5, 7, 13, 40, 45, 46], "proper": 5, "overal": [5, 45], "deal": [5, 13, 17, 44, 45], "larger": [5, 10, 35, 45, 46], "task": [5, 7, 12, 13, 14, 35, 40, 41, 45], "explor": [5, 44, 46], "abil": [5, 10, 40, 45], "batch": [5, 10, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 41, 44, 45, 46], "process": [5, 13, 14, 38, 44, 45, 46], "alreadi": [5, 10, 13, 44, 45, 46], "share": 5, "well": [5, 7, 13, 15, 37, 40, 44, 45, 46], "togeth": [5, 13, 44, 45, 46], "separ": [5, 12, 13, 14, 37, 44, 45, 46], "volunt": 5, "said": [5, 46], "submiss": 5, "discuss": [5, 45], "think": [5, 13, 35, 44, 45, 46], "few": [5, 10, 12, 45, 46], "week": 5, "confus": [5, 45, 46], "among": 5, "calcul": [5, 10, 11, 12, 13, 14, 17, 24, 36, 44, 45, 46], "match": [5, 10, 13, 36, 45], "huggingfac": [5, 12, 13, 14, 35, 38, 44, 46, 48], "solv": [5, 37, 45, 46, 48], "systemat": 5, "submit": 5, "show": [5, 7, 13, 15, 36, 45, 46, 48], "order": [5, 17, 40, 44, 45], "allevi": 5, "build": [5, 37, 46, 48], "spit": 5, "tabl": [5, 45, 46], "u": [5, 11, 13, 40, 44, 45, 46], "snapshot": 5, "store": [5, 10, 13, 14, 24, 37, 39, 40, 41, 45, 46], "repo": [5, 45], "regener": 5, "cumul": [5, 13, 44], "valu": [5, 7, 10, 11, 12, 13, 14, 17, 24, 33, 36, 38, 39, 40, 44, 45, 46, 48], "creat": [5, 7, 10, 13, 17, 37, 45, 46], "robust": [5, 10, 45], "big": [5, 36, 38, 44, 45, 46], "famili": [5, 14, 46], "hard": [5, 13, 45, 46], "even": [5, 7, 11, 13, 14, 17, 35, 38, 45, 46, 48], "smallest": [5, 46], "thought": [5, 10, 45, 46], "thrown": 5, "topic": [5, 7], "best": [5, 7, 13, 45, 46], "guess": [5, 45], "reason": [5, 17, 18, 24, 45, 46], "untrain": 5, "eg": [5, 10, 13, 35, 40, 44, 45, 46], "randomli": [5, 13, 14, 46], "weight": [5, 7, 12, 13, 14, 17, 24, 26, 41, 44, 45, 46, 48], "verifi": [5, 7, 45, 46], "load": [5, 10, 12, 13, 14, 35, 38, 44, 45, 48], "result": [5, 10, 12, 13, 14, 20, 36, 38, 40, 44, 45, 46, 48], "accur": 5, "sens": [5, 11, 37, 45, 46], "consist": [5, 13, 45, 46], "sampl": [5, 13, 35, 44], "size": [5, 10, 13, 14, 17, 35, 41, 44, 45, 46], "against": [5, 45], "bite": 5, "success": [5, 45], "turn": [5, 10, 13, 44, 45, 46], "effici": [5, 11, 17, 44, 46], "proof": [5, 45], "put": [5, 45, 46], "strong": 5, "opinion": 5, "most": [5, 10, 13, 37, 44, 45, 46, 48], "roundtabl": 5, "wrapper": [5, 10, 12, 13, 40, 43, 46], "plugin": 5, "addit": [5, 7, 12, 13, 45], "outsid": 5, "publish": 5, "themselv": [5, 13], "final": [5, 6, 10, 12, 13, 14, 17, 44, 45, 46], "overhaul": 5, "composit": [5, 13, 45, 46], "util": [5, 8, 9, 10, 11, 13, 36, 37, 38, 41, 45, 46], "isol": [5, 45], "rapidli": 5, "itself": [5, 36, 44, 45], "none": [5, 10, 12, 13, 14, 15, 17, 18, 19, 20, 24, 25, 29, 30, 33, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46], "pain": [5, 46], "rel": [5, 45], "grow": 5, "exponenti": 5, "whole": [5, 45, 46], "explod": 5, "section": [5, 45, 46], "relev": [5, 13, 14, 17, 40, 44, 45, 46], "skip": [5, 13, 45, 46], "setup": [5, 13, 37, 40], "act": [5, 37, 40, 44, 45, 46], "vast": 5, "due": [5, 6, 13, 46], "potenti": 5, "mismatch": [5, 36], "between": [5, 10, 13, 17, 36, 40, 44, 45, 46, 48], "meant": 5, "repres": [5, 11, 12, 14, 32, 36, 40, 44, 45, 46], "updat": [5, 7, 13, 39, 40, 43, 45, 46], "readi": 5, "sent": 5, "justifi": 5, "bug": [5, 7, 10, 14, 44, 46], "fix": [5, 37, 45, 46], "exist": [5, 36, 45, 46], "split": [5, 13, 17, 38, 44, 45, 46], "group": [5, 14, 17, 24], "call": [5, 10, 12, 13, 14, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 37, 38, 44, 45, 46], "again": [5, 45], "piec": [5, 45], "tradition": 5, "everyth": [5, 37, 40, 44, 46], "That": [5, 45], "mock": 5, "spi": 5, "control": [5, 14, 40, 45, 46], "input": [5, 10, 12, 13, 14, 24, 29, 32, 37, 38, 39, 40, 44, 45, 46], "side": [5, 11, 13], "effect": [5, 10, 13, 40, 45, 46], "certain": [5, 14, 40], "logic": 5, "entir": [5, 10, 13, 40, 45], "rule": 5, "incredibli": [5, 46], "cannot": [5, 13, 44, 46], "origin": [5, 14, 15, 17, 45, 46], "pass": [5, 10, 13, 14, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 44, 46], "bunch": [5, 10, 12, 13, 37, 45, 46], "Being": [5, 45], "live": [5, 12, 13, 45, 46], "ci": 5, "report": 5, "great": [5, 7, 46, 48], "get": [5, 7, 10, 12, 13, 14, 15, 17, 35, 36, 37, 40, 43, 45, 46, 48], "review": 5, "meaning": [5, 14, 40], "than": [5, 6, 10, 13, 14, 17, 19, 35, 36, 37, 40, 44, 45, 46], "ever": [5, 44], "substanti": 5, "let": [5, 14, 44, 45, 46, 48], "shift": [5, 40, 46], "favor": 5, "individu": [5, 7, 10, 13, 17, 45], "3000": 5, "18": [5, 44, 45, 46, 47], "distinct": 5, "either": [5, 13, 36, 37, 38, 40, 45, 46], "interdepend": 5, "least": [5, 40, 46], "depend": [5, 10, 13, 46], "its": [5, 10, 13, 17, 37, 45, 46, 48], "own": [5, 7, 45, 46], "realli": [5, 35, 36, 44, 45, 46], "anywher": [5, 40], "els": [5, 13, 14, 17, 38, 44, 45, 46], "mlp": [5, 10, 12, 13, 14, 16, 19, 23, 33, 40, 44, 45, 46], "exactli": [5, 13, 38, 45, 46], "thank": [5, 46], "excit": 5, "standpoint": 5, "perspect": [5, 46], "comparison": [5, 36], "worth": [5, 7, 10, 45, 46], "enabl": [5, 10, 13, 45, 46, 48], "huge": 5, "impact": [5, 10], "bring": 5, "realiti": [5, 45], "semver": 5, "older": [5, 46], "log": [5, 13, 41, 44, 45, 46], "data": [5, 6, 7, 13, 35, 44, 45, 46], "expos": [5, 13, 48], "properti": [5, 11, 12, 13, 17, 24, 44, 45, 46], "minor": [5, 45], "bump": [5, 46], "whatsoev": 5, "With": [5, 17, 46], "fact": [5, 13, 45, 46, 48], "discov": 5, "earlier": [5, 45, 46], "extent": 5, "probabl": [5, 7, 13, 35, 36, 40, 44, 45, 46], "regardless": [5, 44], "stand": 5, "reliabl": 5, "17": [5, 45, 46], "possibli": 5, "easiest": [5, 45], "fresh": 5, "consum": [5, 10, 11], "top": [6, 13, 44, 45, 46], "k": [6, 10, 11, 12, 13, 15, 17, 24, 40, 44, 45, 46], "gate": [6, 13, 23], "hidden": [6, 14, 46], "amplifi": 6, "greatli": [6, 46, 48], "select": [6, 10, 44, 45, 46], "lead": [6, 7, 12, 37, 44, 46], "higher": [6, 13, 45], "normal": [6, 10, 13, 14, 26, 44, 45, 46, 48], "varianc": [6, 45], "test": [6, 7, 13, 35, 36, 44, 45, 46], "half": [6, 11, 12, 13, 17, 35, 46], "precis": [6, 36, 40, 45, 46], "deviat": [6, 14, 46], "compar": [6, 35, 46, 48], "2e": 6, "mitig": 6, "disabl": [6, 13, 36, 37, 45], "preprocess": [6, 12, 45], "option": [6, 10, 12, 13, 14, 15, 17, 18, 19, 20, 24, 25, 29, 30, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44], "from_pretrained_no_process": [6, 13], "increas": [6, 40, 45, 46], "colab": [7, 45, 46, 48], "blob": 7, "ipynb": 7, "causal": [7, 12, 14, 40, 45, 46], "intervent": [7, 40, 45, 46], "matter": [7, 13, 40, 45, 46], "produc": [7, 13, 40, 45], "incomplet": 7, "gradient": [7, 10, 37, 41, 46], "approxim": [7, 45, 46], "bad": [7, 13], "residu": [7, 10, 12, 13, 14, 17, 33, 34, 40, 46], "stream": [7, 10, 12, 13, 14, 33, 40, 44, 46], "after": [7, 10, 13, 14, 19, 26, 37, 41, 45, 46, 48], "demonstr": [7, 15, 45, 46], "focus": [7, 45, 46], "less": [7, 13, 17, 45], "rigor": [7, 45, 46], "grasp": 7, "steal": 7, "liber": [7, 37], "phenomenon": 7, "memoris": 7, "minimis": 7, "loss": [7, 10, 13, 35, 37, 40, 41, 44, 45, 46], "longer": 7, "generalis": [7, 45, 46], "sharp": [7, 46], "decreas": [7, 17, 44, 45], "modular": [7, 44], "grok": 7, "light": 7, "explan": [7, 40, 45], "ll": [7, 13, 36, 45, 46], "pair": [7, 11, 13, 17, 36, 44, 45, 46], "seri": [7, 10, 46], "detector": [7, 36], "detect": [7, 36, 45, 46], "sever": [7, 10, 13, 44, 45, 46], "custom": [7, 13, 14, 20, 35, 37, 44, 45, 46], "algorithm": [7, 11, 14, 46, 48], "interact": [7, 45, 46], "neuroscop": [7, 46], "hacki": [7, 44], "web": [7, 46], "visualis": [7, 45], "front": 7, "visual": [7, 12, 46], "dynam": [7, 14, 46], "convert": [7, 12, 13, 38, 44, 45, 46], "meta": [7, 13, 38, 44, 45, 46, 47], "until": [7, 10, 13, 37, 45, 46], "multi": [7, 10, 44, 46], "gpu": [7, 10, 11, 12, 13, 45, 46], "access": [7, 10, 14, 37, 44, 45], "No": [7, 46], "previou": [7, 10, 13, 33, 36, 45, 46], "port": 7, "excel": [7, 10, 45, 46, 48], "sequenc": [7, 12, 13, 14, 17, 32, 35, 36, 37, 40, 44, 45, 46], "investig": [7, 10, 13, 36, 45, 46], "svd": [7, 11, 13, 15, 46], "conjectur": 7, "post": [7, 10, 15, 23, 45, 46], "singular": [7, 11, 13, 15, 46], "decomposit": [7, 10, 11, 13, 45, 46], "matric": [7, 11, 12, 13, 15, 17, 18, 24, 45, 46], "surprisingli": 7, "reproduc": [7, 14, 36], "further": [7, 10, 13, 44, 45, 46], "tracr": 7, "cool": 7, "deepmind": 7, "compil": 7, "program": [7, 46, 48], "rasp": 7, "jax": 7, "form": [7, 10, 11, 13, 40, 45, 46], "pytorch": [7, 13, 14, 35, 37, 46], "brows": 8, "first": [8, 10, 13, 14, 35, 38, 40, 44, 45, 46], "submodul": 8, "factoredmatrix": [8, 9, 12, 17, 44, 46], "hookedencod": [8, 9, 43], "hookedtransformerconfig": [8, 9, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 43], "svdinterpret": [8, 9], "eval": [8, 9, 46], "head_detector": [8, 9], "past_key_value_cach": [8, 9], "subpackag": 8, "core": [10, 13, 45, 46, 48], "varieti": [10, 46], "helper": [10, 13, 17, 35, 37, 40, 44, 46], "skim": 10, "method": [10, 12, 13, 14, 37, 38, 39, 44, 45, 46], "back": [10, 14, 17, 18, 24, 46], "cache_dict": 10, "dict": [10, 12, 13, 14, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 44], "str": [10, 12, 13, 14, 17, 18, 24, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46], "tensor": [10, 11, 12, 13, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 44, 45, 46], "has_batch_dim": 10, "bool": [10, 12, 13, 14, 35, 36, 37, 38, 39, 40, 41, 44], "run_with_cach": [10, 12, 13, 37, 45, 46], "particular": [10, 15, 36, 45, 46], "behaviour": [10, 13, 45, 46], "modal": 10, "step": [10, 13, 14, 38, 41, 44, 45, 46], "respons": [10, 14, 45], "prompt": [10, 13, 17, 35, 40, 44, 45, 46], "chicken": 10, "road": [10, 44], "specif": [10, 12, 13, 17, 36, 40, 45, 46], "sublay": 10, "commonli": 10, "fall": 10, "categori": [10, 45], "dla": 10, "pretrain": [10, 12, 13, 14, 35, 38, 44, 45, 46], "_logit": 10, "residual_stream": 10, "label": [10, 13, 14, 17, 18, 24, 38, 45, 46], "decompose_resid": [10, 45], "return_label": [10, 45], "0": [10, 12, 13, 14, 15, 17, 29, 32, 36, 38, 41, 44, 45, 46, 47], "emb": [10, 16, 20, 29, 32, 44, 46], "pos_emb": [10, 14, 16, 46], "0_attn_out": 10, "proceed": 10, "space": [10, 12, 13, 44, 45, 46], "logit_attr": 10, "shape": [10, 12, 13, 17, 18, 24, 32, 33, 40, 44, 45, 46], "torch": [10, 12, 13, 14, 17, 24, 29, 33, 37, 38, 40, 43, 44, 45, 46], "10": [10, 13, 15, 44, 45, 46, 47], "7": [10, 35, 45, 46, 47], "most_important_component_idx": 10, "argmax": [10, 45], "3_attn_out": 10, "dig": [10, 45, 46, 48], "granular": 10, "get_full_resid_decomposit": 10, "stack": [10, 12, 13, 40, 44, 45, 46], "equal": [10, 14], "struggl": 10, "construct": [10, 12], "joke": 10, "trivial": 10, "accumulated_resid": [10, 45], "footgun": [10, 37], "sourc": [10, 13, 14, 17, 35, 40, 48], "track": [10, 45], "index": [10, 12, 13, 14, 15, 17, 18, 24, 38, 40, 43, 44, 45, 46], "dimens": [10, 13, 14, 17, 24, 25, 30, 37, 40, 44, 45, 46], "vector": [10, 11, 13, 15, 17, 40, 45, 46], "q": [10, 12, 13, 17, 24, 40], "z": [10, 13, 24, 36, 40, 45, 46], "po": [10, 12, 13, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 40, 44, 45, 46], "head_index": [10, 13, 15, 17, 18, 24, 25, 26, 40, 45, 46], "d_head": [10, 12, 13, 14, 17, 18, 24, 38, 39, 44, 45, 46, 47], "pattern": [10, 12, 13, 17, 18, 24, 36, 40, 46], "softmax": [10, 13, 17, 18, 24, 26, 44, 46], "attn_scor": [10, 17, 18], "pre": [10, 13, 14, 17, 18, 23, 24, 26, 31, 36, 44], "query_po": [10, 17, 18, 24, 45], "key_po": [10, 17, 18, 24, 45], "d_model": [10, 12, 13, 14, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 33, 34, 38, 44, 45, 46, 47], "mid": [10, 45], "solu_ln": [10, 14], "layernorm": [10, 12, 13, 14, 19, 25, 26, 30, 44, 45], "d_mlp": [10, 12, 13, 14, 26, 38, 44, 46, 47], "resid_pr": [10, 14, 19, 33, 40, 45, 46], "resid_mid": [10, 40], "resid_post": [10, 14, 45], "attn_out": [10, 13, 14, 40, 45], "mlp_out": [10, 13, 14, 23, 40, 45], "ln": [10, 13, 14, 23, 27, 45, 46], "lnpre": [10, 14], "scale": [10, 13, 14, 17, 18, 24, 44, 45, 46], "sometim": [10, 35, 45], "miss": [10, 45], "becaus": [10, 11, 12, 13, 14, 17, 35, 44, 45, 46, 48], "appli": [10, 13, 14, 17, 19, 37, 40, 44, 45, 46], "remove_batch_dim": [10, 37, 44, 46], "batch_siz": [10, 12, 32, 35, 37, 39, 41, 45, 46], "annot": [10, 46], "layers_cov": 10, "queri": [10, 12, 13, 14, 17, 18, 24, 36, 40, 46], "batch_and_pos_dim": 10, "ve": [10, 13, 17, 35, 37, 45, 48], "slice": [10, 37, 44, 45], "dictionari": [10, 12, 13, 14, 36, 37, 38, 44, 46], "whether": [10, 12, 13, 14, 17, 32, 35, 37, 38, 40, 41, 44, 45, 46], "int": [10, 11, 12, 13, 14, 15, 17, 18, 20, 22, 24, 25, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46], "incl_mid": [10, 45], "fals": [10, 12, 13, 14, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46], "apply_ln": [10, 45], "pos_slic": [10, 37, 45], "union": [10, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 43, 44, 45], "tupl": [10, 11, 12, 13, 17, 24, 36, 37, 40, 44, 46], "ndarrai": [10, 13, 37, 44], "mlp_input": [10, 13], "float": [10, 11, 12, 13, 14, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 38, 39, 40, 41, 44, 45, 46], "accumul": [10, 13, 45], "sub": [10, 46], "www": 10, "lesswrong": 10, "ackrb8wdpdan6v6ru": 10, "believ": [10, 35, 45], "vocabulari": [10, 14, 45, 46], "rememb": 10, "norm": [10, 11, 13, 14, 20, 25, 26, 30, 31, 38, 41, 45, 46], "decod": 10, "therefor": [10, 13, 44], "multipli": [10, 13, 17, 18, 36, 45, 46], "unembed": [10, 12, 13, 45, 46], "matrix": [10, 11, 12, 13, 14, 15, 17, 24, 36, 44, 45], "w_u": [10, 12, 13, 45, 46], "broken": [10, 37, 44, 45, 46], "down": [10, 13, 17, 18, 24, 45, 46], "einop": [10, 45, 46], "einsum": [10, 45, 46], "panda": [10, 40], "pd": [10, 40], "devic": [10, 12, 13, 14, 15, 17, 35, 37, 38, 39, 41, 42, 45, 46], "answer_token": [10, 45], "to_single_token": [10, 13, 45, 46], "2975": 10, "accum_resid": 10, "last_token_accum": 10, "9": [10, 44, 45, 46, 47], "64": [10, 38, 44, 46, 47], "50257": [10, 38, 46, 47], "layers_unembed": 10, "d_vocab": [10, 12, 13, 14, 15, 38, 40, 44, 46, 47], "rank": [10, 11, 13, 17, 44, 45, 46], "correct": [10, 40, 43, 44, 45, 46], "sorted_indic": 10, "argsort": 10, "dim": [10, 13, 44, 45, 46], "descend": [10, 46], "rank_answ": 10, "nonzero": 10, "as_tupl": 10, "0_pre": 10, "4442": 10, "1_pre": [10, 45], "382": 10, "2_pre": 10, "982": 10, "3_pre": 10, "1160": 10, "4_pre": 10, "408": 10, "5_pre": 10, "145": 10, "6_pre": 10, "78": 10, "7_pre": 10, "387": 10, "final_post": 10, "6": [10, 13, 38, 44, 45, 46, 47], "dtype": [10, 12, 13, 14, 17, 38, 43, 45, 46], "int64": [10, 44], "exclud": [10, 36], "n_layer": [10, 12, 13, 14, 38, 40, 43, 45, 46, 47], "immedi": [10, 18, 44, 45, 46], "indic": [10, 12, 32, 37, 40, 44, 45, 46], "taken": [10, 13, 46], "l": [10, 12, 13, 45, 46], "noth": [10, 12, 13, 37, 44, 45, 46], "essenti": [10, 13, 45, 46, 48], "rather": [10, 13, 14, 19, 40, 44, 45, 46], "graph": [10, 45, 46], "apply_ln_to_stack": [10, 13, 44, 45], "residual_stack": [10, 45], "num_compon": 10, "batch_slic": 10, "batch_and_pos_dims_out": 10, "treat": [10, 13, 14, 45, 46], "factor": [10, 11, 13, 14, 45], "simul": [10, 13, 45, 46], "global": [10, 17, 18, 24, 37, 44, 45, 46], "element": [10, 13, 17, 36, 40, 44, 46], "unchang": [10, 12, 13, 44, 45, 46], "whose": [10, 12, 13, 35, 44, 45], "trail": [10, 11, 44], "assum": [10, 12, 13, 14, 25, 30, 32, 37, 40, 41, 44, 45], "hook_scal": [10, 44, 45, 46], "unemb": [10, 13, 14, 16, 45, 46], "map": [10, 12, 13, 17, 36, 37, 45, 46], "ie": [10, 12, 13, 14, 17, 38, 40, 44, 45, 46], "ln2": [10, 33, 44, 46], "ln1": [10, 14, 33, 44, 46], "ln_final": [10, 13, 45, 46], "apply_slice_to_batch_dim": 10, "compute_head_result": 10, "sum": [10, 11, 13, 14, 20, 36, 44, 45, 46], "plu": 10, "b_o": [10, 12, 13, 46], "intend": [10, 14, 44], "use_attn_result": [10, 13, 14], "forget": 10, "liter": [10, 12, 13, 15, 36, 37, 40], "incl_emb": 10, "decompos": 10, "incl": 10, "expand_neuron": 10, "bias": [10, 12, 13, 14, 41, 45], "expand": [10, 13, 24], "get_neuron_result": 10, "neuron_slic": 10, "num_neuron": 10, "subset": [10, 14, 35, 45, 46], "specifi": [10, 12, 13, 14, 24, 35, 36, 37, 43, 44, 46], "expens": [10, 11], "cheap": 10, "hook_emb": [10, 44, 46], "hook_pos_emb": [10, 46], "block": [10, 13, 14, 17, 18, 19, 24, 33, 40, 44, 45, 46], "hook_resid_pr": [10, 46], "incorrect_token": [10, 45], "typic": [10, 12, 13, 32, 36, 45, 46], "revers": [10, 11, 40, 44, 45, 46, 48], "dot": [10, 13, 17, 18, 44], "product": [10, 11, 12, 17, 18, 46], "incorrect": [10, 13, 40, 45, 46], "arxiv": [10, 13, 14, 17, 24, 32, 35], "org": [10, 13, 14, 17, 24, 32, 35, 46, 48], "ab": [10, 11, 13, 24, 36, 45, 46], "2211": [10, 35], "00593": [10, 35], "john": [10, 45, 46], "mari": [10, 45, 46], "went": [10, 45, 46], "shop": [10, 45, 46], "gave": [10, 35, 45, 46], "bag": [10, 45], "choos": [10, 45, 46], "final_ln": 10, "residual_stack_item": 10, "dure": [10, 24, 37, 39, 46, 48], "stack_activ": 10, "activation_nam": [10, 40, 45], "sublayer_typ": 10, "flexibl": 10, "given": [10, 11, 12, 13, 15, 36, 37, 38, 40, 43, 44, 45, 46], "get_act_nam": [10, 44, 45, 46], "infer": [10, 13, 26, 40, 45, 46], "incl_remaind": 10, "stack_head_result": [10, 45], "axi": [10, 17, 40, 44, 45, 46], "n_head": [10, 12, 13, 14, 17, 24, 38, 39, 40, 44, 45, 46, 47], "notat": [10, 45], "l0h0": 10, "stack_neuron_result": 10, "l0n0": 10, "super": [10, 13, 44, 46], "short": [10, 44, 45, 46, 48], "mostli": [10, 45, 46], "finish": [10, 13, 44, 45, 46], "oper": [10, 45, 46], "slower": 10, "unless": [10, 13, 14, 35, 46], "deprec": 10, "toggle_autodiff": 10, "toggl": [10, 13], "autodiff": [10, 46], "set_grad_en": [10, 45, 46], "danger": 10, "off": [10, 13, 35, 44, 45, 46], "realis": [10, 45], "downstream": 10, "delet": [10, 44, 45], "stick": [10, 45], "mess": [10, 13, 44, 46], "inference_mod": 10, "decor": 10, "similar": [10, 12, 13, 19, 24, 36, 45, 46], "requires_grad": 10, "eigenvalu": 11, "ldim": [11, 46], "mdim": [11, 46], "rdim": [11, 46], "leading_dim": [11, 44], "ba": 11, "vh": [11, 13], "collapse_l": 11, "collaps": [11, 45, 46], "left": [11, 13, 17, 44, 45, 46, 48], "orthogon": [11, 13], "self": [11, 12, 13, 17, 44, 46], "collapse_r": 11, "analog": [11, 45, 46], "apart": [11, 44, 45, 46], "zero": [11, 13, 17, 36, 44, 45, 46], "bav": 11, "kv": 11, "abav": 11, "kav": 11, "av": 11, "eigenvector": [11, 46], "get_corn": [11, 44, 45], "make_even": 11, "sqrt": [11, 13, 14, 44], "diag": 11, "equival": [11, 13, 17, 45, 46], "factoris": [11, 13, 17, 46], "row": [11, 13, 40], "col": 11, "ndim": 11, "frobeniu": [11, 46], "squar": [11, 30, 31, 44, 46], "m": [11, 17, 44, 45, 46], "st": 11, "transpos": [11, 44], "obviou": [11, 13, 45], "unsqueez": [11, 44], "hook": [12, 13, 14, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 45], "encod": [12, 17, 44, 46], "contain": [12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 44, 45, 46], "bert": [12, 19, 20, 21, 32, 38, 46, 47], "move_to_devic": [12, 13], "kwarg": [12, 13, 38, 44, 45, 46], "hookedrootmodul": [12, 13, 37, 46], "hookpoint": [12, 13, 37, 45, 46], "inherit": [12, 46], "mvp": 12, "mask": [12, 13, 17, 21, 29, 33, 44, 45], "mlm": [12, 21], "next": [12, 13, 44, 45, 46], "sentenc": [12, 13, 21, 32, 36, 45, 46], "nsp": 12, "dropout": 12, "inconsist": [12, 15], "fine": [12, 46], "fold": [12, 13, 17, 26, 38, 45], "ov": [12, 13, 15, 17, 45, 46], "o": [12, 46], "qk": [12, 13, 17, 45], "w_e": [12, 13, 46], "conveni": [12, 13, 14, 37, 44, 46], "w_e_po": [12, 13], "n_ctx": [12, 13, 14, 17, 38, 46, 47], "concaten": [12, 13, 44, 45, 46], "w_po": [12, 13, 46], "overcomplet": [12, 13], "w_k": [12, 13, 14, 17, 24, 46], "w_o": [12, 13, 17, 18, 45, 46], "w_q": [12, 13, 17, 24, 46], "w_v": [12, 13, 17, 24, 46], "w_in": [12, 13, 15, 23, 46], "w_out": [12, 13, 15, 23, 46], "all_head_label": [12, 13], "format": [12, 13, 37, 45, 46], "h": [12, 13, 45, 46], "b_k": [12, 13, 17, 24, 46], "b_q": [12, 13, 46], "b_u": [12, 13, 45, 46], "bia": [12, 13, 14, 17, 30, 31, 45, 46], "b_v": [12, 13, 17, 24, 46], "b_in": [12, 13, 23, 46], "b_out": [12, 13, 23, 46], "buffer": [12, 13], "modifi": [12, 13], "cuda": [12, 13, 14, 35, 38], "associ": [12, 13, 37], "optim": [12, 13, 41, 45], "return_typ": [12, 13, 37, 45, 46], "token_type_id": [12, 20, 32], "one_zero_attention_mask": 12, "binari": [12, 32], "id": [12, 13, 32], "belong": [12, 32], "cl": [12, 32, 46], "sep": [12, 32], "sequence_length": [12, 32, 36, 44], "attend": [12, 14, 17, 18, 24, 44, 45, 46], "ignor": [12, 13, 14, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37, 44, 46], "primarili": 12, "pad": [12, 13, 17, 29, 33, 44, 45, 46], "shorter": [12, 13, 46], "classmethod": [12, 13, 14, 39, 44], "model_nam": [12, 13, 14, 38, 46], "checkpoint_index": [12, 13, 14, 38, 46], "checkpoint_valu": [12, 13, 14, 38, 46], "hf_model": [12, 13], "float32": [12, 13, 14, 17, 38, 45], "from_pretrained_kwarg": [12, 13], "bertformaskedlm": 12, "unlik": [12, 13, 40, 46], "mp": [12, 13], "model_arg": [12, 13, 37], "return_cache_object": [12, 13], "otherwis": [12, 13, 35, 36, 44], "device_or_dtyp": [12, 13, 43], "print_detail": [12, 13, 43, 44], "cast": [12, 13], "non_block": [12, 13], "memory_format": [12, 13], "channels_last": [12, 13], "Its": [12, 13], "complex": [12, 13, 14, 45, 46], "integr": [12, 13, 38], "tri": [12, 13, 45, 46, 48], "asynchron": [12, 13], "respect": [12, 13, 37, 44, 46], "host": [12, 13, 38], "pin": [12, 13], "desir": [12, 13], "4d": [12, 13], "keyword": [12, 13, 37, 46], "argument": [12, 13, 14, 37, 38, 44, 46], "xdoctest": [12, 13], "ignore_w": [12, 13], "non": [12, 13, 14, 17, 35, 44, 45, 46], "determinist": [12, 13, 44, 45], "nn": [12, 13, 37, 46], "1913": [12, 13], "3420": [12, 13], "5113": [12, 13], "2325": [12, 13], "doubl": [12, 13], "in_featur": [12, 13], "out_featur": [12, 13], "float64": [12, 13], "env": [12, 13], "torch_doctest_cuda1": [12, 13], "gpu1": [12, 13], "1914": [12, 13], "5112": [12, 13], "2324": [12, 13], "float16": [12, 13], "cdoubl": [12, 13], "3741": [12, 13], "j": [12, 13, 14, 17, 38, 45, 46, 47], "2382": [12, 13], "5593": [12, 13], "4443": [12, 13], "complex128": [12, 13], "6122": [12, 13], "1150": [12, 13], "fairli": [13, 45, 46], "extract": [13, 46], "harder": [13, 40, 45], "aim": [13, 45, 48], "simplifi": [13, 45, 46], "attach": [13, 46], "within": [13, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 36, 37, 40, 44, 45, 46], "inspect": [13, 45], "alter": 13, "facilit": 13, "deeper": 13, "pretrainedtokenizerbas": 13, "default_padding_sid": 13, "50": [13, 41, 46], "initialis": [13, 14], "although": [13, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37], "instanti": [13, 14, 46], "__init__": [13, 17, 18, 24, 25, 26, 30, 31, 37, 44, 46], "test_prompt": [13, 44, 45, 46], "w_gate": [13, 23], "tokenizer_nam": [13, 14], "explicitli": [13, 14, 17, 35, 38, 40, 46], "n_devic": [13, 14, 38, 43], "greater": [13, 36], "multipl": [13, 36, 43, 44, 46], "accumulated_bia": 13, "include_mlp_bias": 13, "layers_accumulated_ov": 13, "all_composition_scor": [13, 44], "score": [13, 17, 18, 24, 36, 40, 45], "l1": 13, "h1": 13, "l2": 13, "h2": [13, 45], "upper": [13, 17], "triangular": [13, 36, 44, 46], "third": [13, 46], "pub": [13, 44], "2021": 13, "framework": [13, 17, 45, 46], "html": [13, 44, 45], "20abov": 13, "20diagram": 13, "20show": 13, "20q": 13, "2d": [13, 44], "2c": 13, "20k": [13, 44], "20and": 13, "20v": 13, "2dcomposit": 13, "metric": [13, 36, 40, 45, 46], "center_unemb": [13, 45], "state_dict": 13, "center": [13, 14, 26, 30, 31, 45, 46], "subtract": [13, 36, 45], "translat": [13, 45, 46], "invari": 13, "prob": [13, 44, 45, 46], "slightli": [13, 44, 45], "misl": 13, "center_writing_weight": [13, 45, 46], "fold_layer_norm": [13, 38], "check_hooks_to_add": [13, 37], "hook_point_nam": [13, 37], "dir": [13, 37], "fwd": [13, 37], "is_perman": [13, 37], "prepend": [13, 14, 35, 37, 38, 44, 46], "overrid": [13, 14, 37, 38, 44], "fold_bias": 13, "center_weight": 13, "rm": [13, 30, 31], "neighbour": 13, "further_com": [13, 14], "md": [13, 14], "fold_value_bias": 13, "alwai": [13, 14, 40, 45, 46], "constant": [13, 14, 17, 45, 46], "doesn": [13, 35, 44, 45, 46], "formal": 13, "b_o_new": 13, "b_o_origin": 13, "sum_head": 13, "b_v_head": 13, "w_o_head": 13, "loss_per_token": 13, "prepend_bo": [13, 14, 35, 38, 44, 45], "use_default_valu": 13, "padding_sid": [13, 44, 45], "start_at_lay": 13, "shortformer_pos_emb": [13, 17, 33], "attention_mask": [13, 17, 29, 33, 39, 44], "stop_at_lay": 13, "past_kv_cach": [13, 29], "hookedtransformerkeyvaluecach": [13, 33, 39], "flag": [13, 14, 35, 37, 40, 44, 45, 46], "entropi": [13, 44, 45, 46], "per": [13, 40, 44, 45, 46], "averag": [13, 35, 45, 46], "scalar": [13, 17, 37, 46], "default_prepend_bo": [13, 14, 35, 38, 44, 46], "bo": [13, 14, 36, 38, 44, 45, 46], "impli": 13, "usag": [13, 45], "accordingli": [13, 14, 17, 38, 45, 46], "lose": [13, 14, 38], "empir": [13, 14, 38, 40, 46], "inclus": 13, "neg": [13, 44, 45, 46], "shortform": [13, 14, 17, 33, 38], "positional_embedding_typ": [13, 14, 17], "stop": 13, "exclus": [13, 44], "etc": [13, 40, 45, 46, 48], "frozen": [13, 39], "pai": [13, 17, 45], "okai": 13, "twice": [13, 35, 45, 46], "accident": [13, 37], "fold_ln": [13, 38, 45, 46], "refactor_factored_attn_matric": [13, 45], "automodelforcausallm": 13, "autoregress": [13, 41], "neo": [13, 17, 18, 24, 38, 46, 47], "gptj": [13, 38], "opt": [13, 38, 46, 47], "solu": [13, 14, 38, 44, 46, 47], "checkpoint": [13, 14, 38, 41], "neelnanda": [13, 38], "stanford": [13, 14, 17, 18, 24, 38, 46, 47], "crfm": [13, 38, 46], "load_and_process_state_dict": 13, "alia": [13, 37, 38, 44, 46], "subsequ": [13, 38, 45, 46], "regular": [13, 17, 24], "batchnorm": [13, 45, 46], "mathemat": [13, 17, 45, 46], "w_": 13, "b_": 13, "w": 13, "layernormpr": [13, 26, 31], "eff": 13, "ext": 13, "wise": [13, 36], "computation": [13, 46], "wish": 13, "defin": [13, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37, 44, 45, 46], "x_1": [13, 46], "x_0": [13, 46], "x_2": [13, 46], "frac": [13, 46], "x_3": 13, "cdot": 13, "x_4": 13, "preced": [13, 44, 45, 46], "never": [13, 46], "w_write": 13, "keepdim": 13, "fed": [13, 36], "1000": [13, 35, 44, 46], "recreat": 13, "onto": [13, 38, 45], "By": [13, 35, 37, 38, 40, 44, 45, 46], "mix": [13, 44, 45, 46], "linearli": 13, "technic": [13, 45, 46], "deriv": [13, 46], "broadcast_b_v": 13, "broadcast": 13, "And": [13, 40, 45, 46], "destination_posit": [13, 46], "source_posit": [13, 46], "source_": 13, "destin": [13, 14, 40, 46], "behavior": [13, 14, 38, 45], "cache_dir": [13, 44], "torch_dtyp": 13, "bfloat16": 13, "boolean": [13, 37, 40, 44, 45, 46], "max_new_token": [13, 46], "stop_at_eo": 13, "eos_token_id": [13, 44], "do_sampl": 13, "top_k": [13, 44, 45, 46], "top_p": [13, 44], "temperatur": [13, 44, 46], "freq_penalti": [13, 44], "use_past_kv_cach": 13, "verbos": 13, "pos_plus_new_token": 13, "eos_token": 13, "reach": [13, 46], "avoid": [13, 14, 39, 44, 45, 46], "fiddl": 13, "rag": 13, "eot": 13, "throw": 13, "enter": [13, 45, 46, 48], "messi": [13, 46], "maximum": [13, 14, 17, 41, 46], "stable_lm": 13, "distribut": [13, 43, 44, 45, 46], "greedi": [13, 44], "search": [13, 36, 45, 46], "max": [13, 45], "mass": 13, "random": [13, 14, 35, 41, 45, 46], "temp": [13, 44], "inf": 13, "uniform": [13, 44], "frequenc": [13, 44, 45], "penalti": [13, 44], "penalis": 13, "speed": [13, 45], "applic": [13, 44], "whatev": [13, 45], "tqdm": [13, 46], "get_token_posit": [13, 45, 46], "single_token": [13, 46], "present": 13, "gotcha": [13, 15, 45], "Be": 13, "care": [13, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37, 45, 46], "weird": [13, 14, 45, 46], "carefulli": [13, 45], "correspond": [13, 24, 36, 40, 44, 45, 46], "dummi": [13, 37, 46], "init_weight": [13, 14], "empti": [13, 37], "bulk": 13, "seed": [13, 14, 41, 46], "determin": [13, 17, 40, 43, 44, 45, 46], "NOT": [13, 37, 44, 46], "scheme": 13, "tell": [13, 35, 45, 46], "round": [13, 35, 45, 46], "18182": 13, "fan_in": [13, 44], "tha": 13, "kaim": [13, 44], "despit": [13, 46], "xavier": [13, 44], "fan_out": 13, "transformerencod": 13, "exact": 13, "72253": 13, "mup": [13, 14], "haven": 13, "2203": 13, "03466": 13, "input_to_emb": 13, "special": [13, 46], "redwood": [13, 45, 46], "load_sample_training_dataset": 13, "dataset": [13, 35, 41, 44, 46], "10k": [13, 35, 44], "get_dataset": [13, 44], "appropri": [13, 46], "info": [13, 14, 40, 44, 46], "download": [13, 44, 46], "locat": [13, 40, 45], "pt": 13, "openwebtext": [13, 35, 44], "karma": [13, 35], "reddit": [13, 35], "pile": [13, 35, 38, 44, 46, 47], "imperfectli": 13, "suppli": 13, "valid": [13, 35, 45], "loss_fn": [13, 46], "per_token": [13, 44, 46], "lm_cross_entropy_loss": [13, 44], "move_model_modules_to_devic": 13, "process_weights_": 13, "cleaner": 13, "experiment": 13, "argu": [13, 46], "somewhat": [13, 45, 46], "w_qk": [13, 17, 46], "w_ov": [13, 17, 46], "hopefulli": [13, 48], "column": [13, 40, 44], "rotat": [13, 14, 17, 46], "nth": 13, "formula": 13, "r": 13, "refactor": 13, "diagon": [13, 45, 46], "asymmetri": 13, "fiddli": 13, "preserv": [13, 45, 46], "too": [13, 40, 45], "bilinear": [13, 46], "dimension": [13, 14], "coordin": 13, "sample_datapoint": 13, "implicitli": [13, 40, 46], "hasn": 13, "manual": [13, 44, 46], "replac": [13, 14, 40, 45, 46, 48], "choic": [13, 45], "truncat": [13, 35, 44, 46], "set_token": [13, 14], "pretrainedtoken": 13, "set_use_attn_in": 13, "use_attn_in": [13, 14], "set_use_attn_result": 13, "easili": [13, 44, 45, 46], "burn": 13, "set_use_hook_mlp_in": 13, "use_hook_mlp_in": [13, 14], "set_use_split_qkv_input": 13, "use_split_qkv_input": [13, 14], "to_single_str_token": 13, "int_token": 13, "uncertain": 13, "to_token": [13, 44, 45, 46], "to_str_token": [13, 15, 45, 46], "weirdli": [13, 45, 46], "gotcha2": 13, "letter": [13, 46], "capit": [13, 45, 46], "shoot": [13, 46], "gotcha3": 13, "exce": 13, "str_token": [13, 45], "to_str": [13, 45, 46], "numpi": [13, 14, 44, 45], "arrai": [13, 15, 44], "long": [13, 46], "window": [13, 14, 44], "tokens_to_residual_direct": [13, 45], "mislead": [13, 45], "integ": [13, 44, 45, 46], "residual_direct": 13, "namedtupl": 13, "dataclass": [14, 37], "act_fn": [14, 23, 27, 47], "ep": 14, "1e": [14, 38], "05": [14, 38], "use_attn_scal": 14, "use_local_attn": 14, "original_architectur": 14, "from_checkpoint": 14, "checkpoint_label_typ": [14, 46], "window_s": [14, 17, 18, 24], "attn_typ": [14, 17, 18, 24], "init_mod": 14, "normalization_typ": 14, "attention_dir": 14, "attn_onli": [14, 47], "initializer_rang": 14, "scale_attn_by_inverse_layer_idx": 14, "final_rm": 14, "d_vocab_out": [14, 34], "parallel_attn_mlp": 14, "rotary_dim": [14, 17], "n_param": [14, 47], "use_hook_token": 14, "gated_mlp": [14, 16], "tokenizer_prepends_bo": 14, "n_key_value_head": [14, 24, 47], "post_embedding_ln": 14, "rotary_bas": 14, "10000": [14, 17, 46], "trust_remote_cod": 14, "rotary_adjacent_pair": 14, "load_in_4bit": 14, "num_expert": 14, "experts_per_token": 14, "AND": 14, "feedforward": 14, "network": [14, 45, 46], "vocab": 14, "lowercas": 14, "relu": [14, 44, 47], "gelu": [14, 23, 38, 46, 47], "silu": [14, 47], "gelu_new": [14, 44], "gelu_fast": [14, 44], "epsilon": 14, "5": [14, 17, 35, 36, 38, 40, 44, 45, 46, 47], "THEN": 14, "intens": 14, "distanc": [14, 17, 45], "weight_init_mod": 14, "xavier_uniform": 14, "xavier_norm": 14, "kaiming_uniform": 14, "kaiming_norm": 14, "pipelin": 14, "parallel": [14, 44, 45], "aka": 14, "unidirect": 14, "bidirect": [14, 46], "8": [14, 17, 35, 36, 45, 46, 47], "gain": [14, 44], "layer_id": [14, 17, 18, 24], "numer": [14, 15, 17, 18, 24, 46], "stabil": [14, 17, 18, 24, 46], "fp16": 14, "rotari": [14, 17], "blog": [14, 17], "eleuth": [14, 17, 44, 46], "res_stream": 14, "sinusoid": 14, "rmsnorm": [14, 30], "dumb": 14, "mainli": 14, "curs": 14, "law": 14, "pdf": [14, 17, 32, 35], "2001": 14, "08361": 14, "Will": [14, 40], "interven": [14, 37, 40, 45], "add_bos_token": [14, 44], "bitsandbyt": 14, "moe": [14, 16], "from_dict": 14, "config_dict": 14, "set_seed_everywher": 14, "to_dict": 14, "unwrap": [14, 44], "duplic": [14, 36, 45, 46], "get_singular_vector": 15, "vector_typ": 15, "layer_index": [15, 45], "num_vector": 15, "plot": [15, 46], "pysvelt": [15, 46], "instabl": 15, "d": [15, 35, 36, 38, 45, 47], "medium": [15, 38, 47], "svd_interpret": 15, "22": [15, 35, 44, 45, 46], "all_token": 15, "np": [15, 44, 45], "def": [15, 45, 46], "plot_matrix": 15, "filter": [15, 37, 38, 44, 46], "topk": [15, 45], "topktabl": 15, "obj_typ": 15, "abstract_attent": 16, "bert_block": 16, "bert_emb": 16, "bert_mlm_head": 16, "grouped_query_attent": 16, "layer_norm": [16, 45], "layer_norm_pr": 16, "rms_norm": 16, "rms_norm_pr": 16, "token_typed_emb": 16, "transformer_block": 16, "abstractattent": [17, 18, 24], "abc": [17, 46], "pure": 17, "glossari": 17, "sorri": 17, "underli": [17, 40, 45, 46], "destination_residu": 17, "destination_po": 17, "source_po": [17, 46], "abstract": [17, 45, 46], "groupedqueryattent": [17, 24], "enforc": 17, "child": 17, "better_abc": 17, "abstract_attribut": 17, "stackoverflow": 17, "question": [17, 45, 46], "23831510": 17, "256": [17, 18, 24, 46, 47], "alibi": 17, "apply_causal_mask": 17, "pos_plus_past_kv_pos_offset": 17, "past_kv_pos_offset": [17, 29, 44], "offset_po": [17, 29, 33, 44], "apply_rotari": 17, "calculate_attention_scor": [17, 24], "calculate_qkv_matric": [17, 24], "query_input": [17, 24], "key_input": [17, 24], "value_input": [17, 24], "calculate_sin_cos_rotari": 17, "sine": 17, "cosin": 17, "wave": 17, "inexplic": 17, "adjac": [17, 45], "neox": [17, 38, 46, 47], "clue": [17, 45], "resolv": 17, "calculate_z_scor": [17, 24], "static": [17, 35], "create_alibi_bia": 17, "head_idx": 17, "2108": 17, "12409": 17, "broad": [17, 45], "proport": [17, 44], "distant": 17, "0000": [17, 45], "0625": 17, "1250": 17, "1875": 17, "0039": 17, "0078": 17, "0117": 17, "create_alibi_multipli": 17, "geometr": 17, "ratio": [17, 44, 45, 46], "16": [17, 44, 45, 46, 47], "5000": 17, "2500": [17, 45], "0312": 17, "0156": 17, "7071": 17, "3536": 17, "1768": 17, "0884": 17, "0442": 17, "0221": 17, "0110": 17, "0055": 17, "create_alibi_slop": 17, "slope": 17, "triangl": 17, "lower": [17, 35, 36, 44, 45, 46], "bottom": [17, 46], "corner": 17, "kv_head_index": [17, 24], "past_kv_cache_entri": [17, 33], "hookedtransformerkeyvaluecacheentri": [17, 33, 39], "additive_attention_mask": [17, 19], "irrelev": [17, 45, 46], "past": [17, 39, 45], "rotate_every_two": 17, "x0": 17, "x1": 17, "param": [18, 41, 44, 46], "convent": [18, 44, 45, 46], "mistal": [18, 24], "bertblock": 19, "transformerblock": [19, 33], "except": [19, 45, 46], "overridden": [19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37, 44], "subclass": [19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37], "recip": [19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37], "afterward": [19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37], "former": [19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37], "regist": [19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37], "latter": [19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37, 46], "silent": [19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 37], "bertemb": 20, "input_id": 20, "bertmlmhead": [21, 22], "purpos": [21, 35, 45, 46], "resid": 21, "gatedmlp": 23, "equat": 23, "pre_linear": 23, "callabl": [23, 27, 37, 40], "2305": 24, "13245": 24, "hood": 24, "_w_k": 24, "_w_v": 24, "getter": 24, "similarli": 24, "kept": 24, "repeat_interleav": 24, "unexpand": 24, "expan": 24, "n_query_head": 24, "gpa": 24, "normalis": [26, 45], "posemb": 29, "root": [30, 31, 46], "rmsnormpr": 31, "tokentypeemb": 32, "1810": 32, "04805": 32, "block_index": 33, "positional_embeddings_typ": 33, "_description_": 33, "_type_": [33, 37], "evalu": [35, 37, 45, 46], "rough": [35, 46], "cheapli": 35, "roughli": [35, 45, 46], "baselin": 35, "ioidataset": 35, "noun": 35, "num_sampl": 35, "symmetr": 35, "ioi_ev": 35, "476": 35, "met": 35, "alic": 35, "bob": 35, "charli": 35, "ball": [35, 45], "book": 35, "397": 35, "get_default_nam": 35, "get_default_noun": 35, "get_default_templ": 35, "get_sampl": 35, "evaluate_on_dataset": 35, "data_load": 35, "induction_loss": [35, 46], "subseq_len": 35, "384": [35, 46], "io": [35, 36, 45, 46], "accuraci": [35, 36, 44], "make_code_data_load": 35, "codeparrot": [35, 44], "dump": 35, "presum": [35, 45], "natur": [35, 45, 46], "make_owt_data_load": 35, "corpu": [35, 44], "make_pile_data_load": 35, "eleutherai": [35, 38], "english": [35, 46, 48], "academ": 35, "internet": [35, 46], "make_wiki_data_load": 35, "wikitext": 35, "wikipedia": [35, 44, 46], "articl": [35, 44, 45, 46], "expect": [35, 36, 45, 46], "bother": 35, "quarantin": 35, "nowadai": 35, "leakag": 35, "though": [35, 44, 45, 46], "sanity_check": 35, "feed": [35, 44, 46], "paragraph": [35, 46], "zoom": [35, 40, 45], "quick": [35, 36, 46], "saniti": [35, 45], "ok": [35, 45, 46], "gone": [35, 45, 46], "wrong": [35, 37, 45], "compute_head_attention_similarity_scor": 36, "attention_pattern": [36, 46], "detection_pattern": 36, "exclude_bo": 36, "exclude_current_token": 36, "error_measur": 36, "mul": 36, "exclude_bcurrent_token": 36, "detect_head": 36, "seq": [36, 44], "previous_token_head": 36, "duplicate_token_head": 36, "induction_head": 36, "headnam": 36, "divid": [36, 44, 45], "straightforward": [36, 45], "fraction": 36, "alloc": 36, "prohibit": 36, "cours": [36, 45], "raw": [36, 45], "interv": 36, "perfect": [36, 45], "examin": 36, "switch": 36, "advantag": 36, "closer": 36, "head_nam": 36, "ntensor": 36, "ioi": [36, 45, 46], "spacifi": 36, "analyz": 36, "paid": [36, 45, 46], "get_duplicate_token_head_detection_pattern": 36, "dynalist": 36, "n2zwtnoyhru1s4vnfsaq519j": 36, "2ukvedzonghl5uhugvhroxeo": 36, "get_induction_head_detection_pattern": 36, "_tfvup5csv5orithmqwj0gsi": 36, "get_previous_token_head_detection_pattern": 36, "0o5vohe9xezn8ertywkh7ioc": 36, "get_supported_head": 36, "hookfunct": 37, "_hookfunctionprotocol": 37, "inspir": [37, 46, 48], "garcon": [37, 46, 48], "ident": [37, 44, 45, 46], "wrap": [37, 46], "add_hook": [37, 45], "bwd": 37, "fn": 37, "hook_nam": 37, "add_perma_hook": [37, 46], "clear_context": 37, "remove_hook": 37, "including_perman": 37, "interfac": [37, 46, 48], "nice": [37, 45], "run_with_hook": [37, 45, 46], "temporari": [37, 44, 46], "debug": [37, 38, 41], "intent": 37, "reset_hook": [37, 46], "goe": [37, 45, 46], "reset_hooks_end": [37, 45], "add_caching_hook": 37, "names_filt": [37, 45], "incl_bwd": 37, "namesfilt": 37, "lambda": [37, 45, 46], "cache_som": 37, "check_and_add_hook": 37, "get_caching_hook": 37, "fwd_hook": [37, 45, 46], "bwd_hook": 37, "hook_dict": 37, "exit": [37, 44], "clear": [37, 46], "reset": 37, "my_hook": 37, "hooked_loss": 37, "mod_dict": 37, "remove_all_hook_fn": 37, "model_kwarg": 37, "degrad": 37, "lenshandl": 37, "removablehandl": 37, "context_level": 37, "hold": 37, "perman": 37, "hug": 38, "face": 38, "hub": [38, 44], "768": [38, 45, 46, 47], "layer_norm_ep": 38, "init_rang": 38, "02": 38, "1024": [38, 44, 46, 47], "3072": [38, 46, 47], "12": [38, 45, 46, 47], "model_alias": 38, "01": 38, "yi": [38, 47], "34b": [38, 47], "6b": [38, 46, 47], "arthurconmi": 38, "redwood_attn_2l": [38, 47], "baidicoot": 38, "codellama": [38, 47], "hf": 38, "codellamallama": [38, 47], "3b": [38, 46, 47], "125m": [38, 46, 47], "20b": [38, 46, 47], "pythia": [38, 47], "4b": [38, 47], "dedup": [38, 47], "12b": [38, 47], "13b": [38, 46, 47], "14m": [38, 47], "160m": [38, 47], "seed1": [38, 47], "seed2": [38, 47], "seed3": [38, 47], "1b": [38, 47], "800m": 38, "8b": [38, 46, 47], "31m": [38, 47], "410m": [38, 47], "350m": 38, "9b": [38, 47], "70m": [38, 47], "19m": [38, 47], "2l512w": 38, "lr": [38, 41], "attn_only_1l512w_c4_cod": 38, "c4": [38, 44, 46], "attn_only_2l512w_c4_cod": 38, "attn_only_3l512w_c4_cod": 38, "attn_only_4l512w_c4_cod": 38, "gelu_1l512w_c4_cod": 38, "gelu_2l512w_c4_cod": 38, "gelu_3l512w_c4_cod": 38, "gelu_4l512w_c4_cod": 38, "solu_10l1280w_c4_cod": 38, "10l": [38, 46, 47], "solu_10l_v22_old": 38, "solu_12l1536w_c4_cod": 38, "12l": [38, 46, 47], "solu_12l_v23_old": 38, "solu_1l512w_c4_cod": 38, "solu_1l512w_wiki_finetun": 38, "wiki": [38, 44, 45, 46, 47], "finetun": 38, "solu_1l_v9_old": 38, "solu_2l512w_c4_cod": 38, "solu_2l_v10_old": 38, "solu_3l512w_c4_cod": 38, "solu_4l512w_c4_cod": 38, "solu_4l512w_wiki_finetun": 38, "solu_4l_v11_old": 38, "solu_6l768w_c4_cod": 38, "6l": [38, 46, 47], "solu_6l_v13_old": 38, "solu_8l1024w_c4_cod": 38, "8l": [38, 46, 47], "solu_8l_v21_old": 38, "qwen": [38, 47], "14b": [38, 47], "1_8b": 38, "qwen1": [38, 47], "5b": [38, 46, 47], "forev": 38, "mgpt": [38, 47], "bigcod": 38, "santacod": [38, 47], "bigscienc": 38, "1b1": [38, 47], "1b7": [38, 47], "560m": [38, 47], "7b1": [38, 47], "distilgpt2": [38, 46], "distillgpt2": [38, 47], "distil": [38, 46], "facebook": 38, "xxl": 38, "30b": [38, 46, 47], "xxxl": 38, "xl": [38, 46, 47], "66b": [38, 46, 47], "xxxxl": 38, "gemma": [38, 47], "2b": [38, 47], "65b": [38, 47], "70b": [38, 47], "microsoft": 38, "phi": [38, 47], "mini": 38, "4k": 38, "1_5": [38, 47], "roneneldan": 38, "tinystori": 38, "1layer": 38, "21m": [38, 47], "28m": [38, 47], "2layer": 38, "33m": [38, 47], "3m": [38, 47], "8m": [38, 47], "instuct": 38, "stabilityai": 38, "stablelm": [38, 46, 47], "alpha": [38, 47], "x21": 38, "arwen": 38, "battlestar": 38, "x49": 38, "beren": 38, "caprica": 38, "x81": 38, "celebrimbor": 38, "darkmatt": 38, "x343": 38, "durin": 38, "eowyn": 38, "x777": 38, "expans": 38, "alias": 38, "non_hf_hosted_model_nam": 38, "convert_bloom_weight": 38, "convert_coder_weight": 38, "convert_mistral_weight": 38, "convert_mixtral_weight": 38, "convert_phi3_weight": 38, "convert_phi_weight": 38, "convert_qwen2_weight": 38, "convert_qwen_weight": 38, "get_checkpoint_label": [38, 46], "label_typ": 38, "get_num_params_of_pretrain": 38, "suffici": [38, 45], "get_pretrained_model_config": 38, "hf_cfg": 38, "automodel": 38, "autoconfig": 38, "infrastructur": [38, 45, 46, 48], "ourselv": [39, 44, 46, 48], "previous_attention_mask": 39, "pos_so_far": 39, "append": [39, 45, 46], "prefix": 39, "append_attention_mask": 39, "new_token": 39, "freez": 39, "init_cach": 39, "unfreez": 39, "past_kei": 39, "jaxtyp": [39, 45, 46], "past_valu": 39, "new_kei": 39, "new_valu": 39, "init_cache_entri": 39, "structur": [40, 46], "generic_activation_patch": 40, "specialis": [40, 45], "introduc": [40, 45], "rome": [40, 45, 46], "baulab": 40, "corrupt": [40, 45, 46], "iter": [40, 44, 45, 46], "localis": [40, 45, 46], "__from__": 40, "__to": 40, "__the": 40, "confid": [40, 45, 46], "intuit": [40, 45, 46], "diffus": [40, 45], "spread": [40, 45], "connect": [40, 45], "ultim": [40, 45], "tend": [40, 46], "extrem": [40, 45, 46, 48], "eiffel": 40, "tower": 40, "pari": 40, "factual": [40, 45], "recal": [40, 45], "colosseum": 40, "corrupted_token": [40, 45, 46], "clean_cach": [40, 45, 46], "patching_metr": 40, "patch_sett": 40, "index_axis_nam": 40, "src_po": [40, 45], "dest_po": [40, 45, 46], "index_df": 40, "datafram": 40, "return_index_df": 40, "counterfactu": [40, 45, 46], "Then": 40, "index_to_act_nam": 40, "recov": [40, 45, 46], "diff": [40, 45], "corrupted_activ": 40, "chunk": 40, "fill": 40, "flatten": [40, 45, 46], "patched_output": 40, "get_act_patch_attn_head_all_pos_everi": 40, "patch_typ": 40, "get_act_patch_attn_head_by_pos_everi": 40, "get_act_patch_attn_head_k_all_po": 40, "corruptedactiv": 40, "patchedactiv": 40, "layer_head_vector_patch_sett": 40, "axisnam": 40, "get_act_patch_attn_head_k_by_po": 40, "layer_pos_head_vector_patch_sett": 40, "get_act_patch_attn_head_out_all_po": 40, "get_act_patch_attn_head_out_by_po": 40, "get_act_patch_attn_head_pattern_all_po": 40, "layer_head_pattern_patch_sett": 40, "get_act_patch_attn_head_pattern_by_po": 40, "layer_head_pos_pattern_patch_sett": 40, "get_act_patch_attn_head_pattern_dest_src_po": 40, "layer_head_dest_src_pos_pattern_patch_sett": 40, "get_act_patch_attn_head_q_all_po": 40, "get_act_patch_attn_head_q_by_po": 40, "get_act_patch_attn_head_v_all_po": 40, "get_act_patch_attn_head_v_by_po": 40, "get_act_patch_attn_out": 40, "layer_pos_patch_sett": 40, "get_act_patch_block_everi": 40, "get_act_patch_mlp_out": 40, "get_act_patch_resid_mid": 40, "get_act_patch_resid_pr": 40, "clean_activ": 40, "hookedtransformertrainconfig": 41, "num_epoch": 41, "001": 41, "max_grad_norm": 41, "weight_decai": 41, "optimizer_nam": 41, "adam": 41, "warmup_step": 41, "save_everi": 41, "save_dir": 41, "wandb": 41, "wandb_project_nam": 41, "print_everi": 41, "max_step": 41, "hyperparamet": [41, 44], "epoch": 41, "rate": [41, 46], "decai": 41, "warmup": 41, "wandb_project": 41, "termin": 41, "assist": 43, "get_device_for_block_index": 43, "target": 43, "move_to_and_update_config": 43, "vari": [44, 45], "throughout": [44, 46], "locallyoverridendefault": 44, "restor": 44, "overriden": 44, "input_slic": 44, "syntax": [44, 45, 46], "reduc": [44, 45, 46], "extra": 44, "leav": [44, 46], "elif": 44, "1d": 44, "sliceinput": 44, "valueerror": 44, "abov": [44, 45, 46], "max_ctx": 44, "int32": 44, "slice_input": 44, "calc_fan_in_and_fan_out": 44, "fan": 44, "d_out": 44, "d_in": 44, "composition_scor": 44, "broadcast_dim": 44, "leading_dims_left_and_right": 44, "download_file_from_hf": 44, "repo_nam": 44, "file_nam": 44, "subfold": 44, "home": 44, "runner": 44, "force_is_torch": 44, "json": 44, "pth": 44, "extens": [44, 45], "layer_typ": [44, 45], "shorthand": 44, "loop": [44, 45, 46, 48], "hack": [44, 46], "stuff": [44, 46], "readabl": 44, "digit": [44, 46], "word": [44, 45, 46], "k6": 44, "scale4ln1": 44, "appear": [44, 46], "distinguish": [44, 45], "hook_k": [44, 46], "hook_pr": [44, 46], "27": [44, 45, 46], "hook_norm": [44, 46], "pre5": 44, "get_attention_mask": 44, "leftmost": 44, "rightmost": 44, "consid": 44, "get_cumsum_along_dim": 44, "dataset_nam": 44, "000": [44, 46], "enorm": [44, 46], "100gb": 44, "2tb": 44, "effort": [44, 45], "dataload": 44, "fanci": 44, "data_dir": 44, "approx": [44, 45, 46], "ton": [44, 48], "divers": [44, 45, 46], "coloss": 44, "crawl": 44, "bigger": 44, "c4_code": 44, "friendli": 44, "22m": [44, 46], "5m": 44, "20220301": 44, "en": [44, 46], "get_devic": [44, 45, 46], "get_input_with_manually_prepended_bo": 44, "autotoken": 44, "get_nested_attr": 44, "obj": 44, "attr_str": 44, "retriev": 44, "nest": 44, "hierarchi": 44, "get_offset_position_id": 44, "offset": [44, 45, 46], "get_tokenizer_with_bo": 44, "Such": [44, 45], "llamatoken": 44, "get_tokens_with_bos_remov": 44, "init_kaiming_normal_": 44, "nonlinear": 44, "std": 44, "init_kaiming_uniform_": 44, "init_xavier_normal_": 44, "init_xavier_uniform_": 44, "is_lower_triangular": 44, "is_squar": 44, "keep_single_column": 44, "col_nam": 44, "lm_accuraci": 44, "seq_len": [44, 45, 46], "altern": 44, "override_or_use_default_valu": 44, "default_flag": 44, "print_gpu_mem": 44, "step_nam": 44, "repeat_along_head_dimens": 44, "clone_tensor": 44, "sample_logit": 44, "final_logit": [44, 45], "vocab_s": 44, "high": [44, 45, 46], "argmaxi": 44, "90": 44, "renormalis": 44, "mutual": 44, "neither": [44, 45], "input_token": 44, "todo": 44, "edg": 44, "randn": [44, 46], "uniqu": 44, "return_count": 44, "set_nested_attr": 44, "prepend_space_to_answ": 44, "eleph": 44, "endoftext": [44, 45, 46], "14": [44, 45, 46], "51": [44, 46], "0th": [44, 45], "59": [44, 46, 47], "ground": [44, 45], "1th": [44, 45], "41": [44, 46], "tree": 44, "2th": [44, 45], "3th": [44, 45], "45": [44, 46], "car": 44, "4th": [44, 45], "13": [44, 45, 46], "92": [44, 45], "55": [44, 45, 46], "river": 44, "5th": [44, 45], "79": 44, "25": [44, 45, 46, 47], "street": 44, "6th": [44, 45], "77": 44, "21": [44, 45, 46], "7th": [44, 45], "75": 44, "hill": 44, "8th": [44, 45], "swing": 44, "9th": [44, 45], "46": [44, 46], "61": [44, 47], "park": [44, 45], "to_numpi": [44, 45, 46], "tokenize_and_concaten": 44, "max_length": 44, "column_nam": 44, "num_proc": 44, "eo": [44, 46], "reshap": [44, 45], "____": 44, "drop": [44, 46], "faster": [44, 45, 46], "parallelis": [44, 46], "chop": 44, "privileg": 44, "earli": [44, 46], "cnn": [44, 46], "bos_token_id": 44, "swap": [44, 45], "runtim": [45, 46], "hardwar": [45, 46], "pane": [45, 46], "sidebar": [45, 46], "navig": [45, 46], "vscode": [45, 46], "outlin": 45, "tab": 45, "dropdown": [45, 46], "arrow": [45, 46], "page": [45, 46], "ctrl": [45, 46], "in_colab": [45, 46], "circuitsvi": [45, 46], "node": [45, 46], "curl": [45, 46], "fssl": [45, 46], "deb": [45, 46], "nodesourc": [45, 46], "setup_16": [45, 46], "sudo": [45, 46], "bash": [45, 46], "apt": [45, 46], "nodej": [45, 46], "noqa": [45, 46], "ipython": [45, 46], "get_ipython": [45, 46], "ip": [45, 46], "extension_manag": [45, 46], "autoreload": [45, 46], "functool": [45, 46], "plotli": [45, 46], "express": [45, 46], "px": [45, 46], "pio": [45, 46], "attention_head": 45, "fancy_einsum": [45, 46], "ifram": 45, "differenti": [45, 46], "simplic": 45, "imshow": [45, 46], "color_continuous_midpoint": [45, 46], "color_continuous_scal": [45, 46], "rdbu": [45, 46], "scatter": [45, 46], "xaxi": [45, 46], "yaxi": [45, 46], "caxi": [45, 46], "color": [45, 46], "principl": [45, 46, 48], "fun": [45, 46, 48], "gap": [45, 46, 48], "plai": [45, 46, 48], "flow": [45, 46, 48], "toolkit": [45, 46], "stylist": 45, "slowli": 45, "convei": 45, "tag": 45, "asid": 45, "flavour": 45, "weed": 45, "star": 45, "tagexampl": 45, "capabl": [45, 46], "interview": [45, 46], "kevin": [45, 46], "wang": 45, "twitter": 45, "thread": 45, "overview": 45, "bottl": [45, 46], "milk": [45, 46], "26": [45, 46], "Their": 45, "skimp": 45, "rigour": 45, "suggest": 45, "evid": 45, "80m": [45, 46], "simplif": 45, "nbval_ignore_output": [45, 46], "stabl": 45, "example_prompt": 45, "example_answ": 45, "39": [45, 46], "lt": [45, 46], "gt": [45, 46], "09": [45, 46], "70": 45, "07": [45, 46], "38": [45, 46], "67": 45, "35": [45, 46], "54": [45, 46], "11": [45, 46, 47], "84": [45, 46], "73": 45, "hi": [45, 46], "06": 45, "her": [45, 46], "74": 45, "52": [45, 46, 47], "49": [45, 46], "jesu": 45, "97": 45, "42": [45, 46], "him": 45, "subword": 45, "frequent": 45, "substr": [45, 46], "headach": 45, "annoi": [45, 46], "devot": 45, "sensibl": 45, "later": [45, 46], "wherev": 45, "flesh": 45, "prompt_format": 45, "jame": 45, "dan": 45, "sid": 45, "appl": 45, "martin": 45, "ami": 45, "drink": 45, "correct_token": 45, "insert": 45, "filler": 45, "newlin": 45, "intellig": 45, "complic": 45, "adjust": [45, 46], "aggreg": 45, "original_logit": 45, "upon": 45, "subject": [45, 46], "logits_to_ave_logit_diff": 45, "per_prompt": 45, "answer_logit": 45, "gather": 45, "answer_logit_diff": 45, "detach": [45, 46], "decim": [45, 46], "original_average_logit_diff": 45, "3370": 45, "2020": 45, "7090": 45, "7970": 45, "7200": 45, "2810": 45, "6010": 45, "7670": 45, "552": 45, "33": [45, 46], "dive": 45, "spend": [45, 46], "engag": 45, "decent": [45, 46], "hypothes": 45, "cheat": [45, 46], "hypothesi": 45, "scienc": 45, "belief": 45, "trap": 45, "flounder": 45, "dogmat": 45, "overconfid": 45, "unwil": 45, "contradict": 45, "flinch": 45, "disconfirm": 45, "focu": 45, "primit": 45, "nearbi": 45, "came": 45, "trigram": 45, "symmetri": 45, "cancel": 45, "inhibit": 45, "spoiler": 45, "simplist": 45, "central": 45, "importantli": [45, 46], "perfectli": [45, 46], "final_residual_stream": 45, "eleg": 45, "particularli": 45, "aspect": 45, "nicer": 45, "inde": 45, "log_prob": 45, "log_softmax": 45, "logsumexp": 45, "decid": 45, "pronoun": 45, "refin": 45, "friendlier": 45, "almost": 45, "answer_residual_direct": 45, "logit_diff_direct": 45, "account": 45, "w_u_fold": 45, "unigram": [45, 46], "statist": [45, 46], "opposit": 45, "hook_normalis": 45, "sub_layer_typ": 45, "final_token_residual_stream": 45, "scaled_final_token_residual_stream": 45, "average_logit_diff": 45, "residual_stack_to_logit_diff": 45, "scaled_residual_stack": 45, "fascinatingli": 45, "utterli": 45, "unabl": 45, "hover": [45, 46], "n_pre": 45, "n_mid": 45, "n_post": 45, "middl": [45, 46], "accumulated_residu": 45, "logit_lens_logit_diff": 45, "arang": 45, "hover_nam": [45, 46], "terminologi": 45, "overload": 45, "kth": 45, "per_layer_residu": 45, "per_layer_logit_diff": 45, "independ": [45, 46, 48], "l9h6": 45, "l9h9": 45, "l10h7": 45, "l11h10": 45, "harm": 45, "strongli": 45, "observ": [45, 46], "144": 45, "claim": 45, "surpris": 45, "7x": 45, "per_head_residu": 45, "per_head_logit_diff": 45, "rearrang": 45, "weren": 45, "alan": [45, 46], "coonei": [45, 46], "illustr": [45, 46], "mistak": 45, "mayb": [45, 46], "sai": [45, 46], "summari": 45, "sole": 45, "visualize_attention_pattern": 45, "local_cach": 45, "local_token": 45, "max_width": 45, "700": 45, "isinst": 45, "batch_index": 45, "combin": [45, 46], "attention_head_nam": 45, "show_cod": 45, "title_html": 45, "br": 45, "div": 45, "width": [45, 46], "top_positive_logit_attr_head": 45, "positive_html": 45, "top_negative_logit_attr_head": 45, "negative_html": 45, "conceptu": 45, "clearli": 45, "compos": [45, 46], "ideal": [45, 46], "david": [45, 46], "bau": [45, 46], "meng": [45, 46], "trace": [45, 46], "anim": 45, "lai": 45, "pro": 45, "con": 45, "Or": 45, "bake": 45, "claus": 45, "tack": 45, "gaussian": 45, "nois": 45, "beforehand": 45, "19": [45, 46], "corrupted_prompt": [45, 46], "corrupted_logit": [45, 46], "corrupted_cach": 45, "corrupted_average_logit_diff": 45, "temporarili": [45, 46], "patch_residual_compon": 45, "corrupted_residual_compon": 45, "normalize_patched_logit_diff": 45, "patched_logit_diff": [45, 46], "wors": [45, 46], "patched_residual_stream_diff": 45, "hook_fn": 45, "patched_logit": [45, 46], "abus": 45, "prompt_position_label": 45, "tok": 45, "_": [45, 46], "enumer": [45, 46], "reus": 45, "patched_attn_diff": 45, "patched_mlp_diff": 45, "patched_attn_logit": 45, "patched_attn_logit_diff": 45, "patched_mlp_logit": 45, "patched_mlp_logit_diff": 45, "late": [45, 46], "contrast": 45, "statement": 45, "mlp0": 45, "destroi": 45, "frame": 45, "unprincipl": 45, "invers": [45, 46], "plausibli": 45, "dedic": 45, "overcom": 45, "love": 45, "someon": 45, "patch_head_vector": 45, "corrupted_head_vector": 45, "patched_head_z_diff": 45, "l8h6": 45, "l8h10": 45, "l7h9": 45, "l5h5": 45, "l6h9": 45, "l3h0": 45, "semi": 45, "disentangl": 45, "familiar": 45, "28": [45, 46, 47], "patched_head_v_diff": 45, "heatmap": 45, "29": [45, 46], "lesson": 45, "head_label": 45, "range_x": 45, "range_i": 45, "31": [45, 46], "patch_head_pattern": 45, "corrupted_head_pattern": 45, "patched_head_attn_diff": 45, "32": [45, 46, 47], "reconsolid": 45, "extend": 45, "l7h3": 45, "specul": 45, "mysteri": [45, 46], "top_heads_by_output_patch": 45, "first_mid_lay": 45, "first_late_lay": 45, "early_head": 45, "mid_head": 45, "logical_and": 45, "late_head": 45, "diagram": 45, "l1h2": 45, "latest": 45, "definit": 45, "priori": 45, "stroke": 45, "didn": 45, "bracket": 45, "serv": [45, 46], "particip": 45, "behav": 45, "l5h0": 45, "wrote": [45, 46, 48], "overkil": 45, "simpler": 45, "repurpos": 45, "machineri": 45, "life": [45, 46], "built": 45, "34": [45, 46], "example_text": [45, 46], "seek": 45, "machin": [45, 46], "example_repeated_text": 45, "example_repeated_token": 45, "example_repeated_logit": 45, "example_repeated_cach": 45, "induction_head_label": 45, "81": 45, "65": 45, "800": 45, "accord": 45, "wildli": 45, "characteris": 45, "superfici": 45, "boost": [45, 46], "anti": 45, "suppress": [45, 46], "pick": [45, 46], "signal": 45, "hook_": 45, "hook_attn": 45, "token_po": 45, "metadata": 45, "36": [45, 46, 47], "prev_token_scor": 45, "prev_token_hook": 45, "dim1": [45, 46], "dim2": [45, 46], "duplicate_token_scor": 45, "duplicate_token_hook": 45, "induction_scor": [45, 46], "induction_hook": 45, "manual_se": [45, 46], "original_token": 45, "randint": [45, 46], "20000": [45, 46], "repeated_token": [45, 46], "pattern_filt": 45, "act_nam": [45, 46], "endswith": [45, 46], "hook_pattern": [45, 46], "0390": 45, "0310": 45, "1890": 45, "1720": 45, "0680": 45, "1570": 45, "0210": 45, "4820": 45, "0030": 45, "1320": 45, "0050": 45, "0020": 45, "0090": 45, "0040": 45, "0010": 45, "instantli": 45, "37": [45, 46], "seen": [45, 46], "mosaic": 45, "40": [45, 46, 47], "fascin": 45, "knock": 45, "naiv": [45, 46], "convers": 45, "flaw": 45, "knockout": 45, "send": 45, "redund": 45, "job": 45, "underestim": 45, "57": [45, 46], "99": [45, 46], "hook_z": [45, 46], "top_name_mov": 45, "top_name_mover_lay": 45, "top_name_mover_head": 45, "ablate_top_head_hook": 45, "ablated_logit": 45, "ablated_cach": 45, "2f": [45, 46], "l10h10": 45, "margin": 45, "obvious": 45, "per_head_ablated_residu": 45, "per_head_ablated_logit_diff": 45, "04": [45, 46], "uniformli": [45, 46], "042": 45, "5200": 45, "4700": 45, "8200": 45, "5100": 45, "2600": 45, "1800": 45, "4300": 45, "5700": 45, "3500": 45, "2900": 45, "6800": 45, "4900": 45, "8700": 45, "4200": 45, "reader": [45, 46], "gentler": 46, "tip": 46, "development_mod": 46, "in_github": 46, "getenv": 46, "github_act": 46, "render": 46, "argh": 46, "notebook_connect": 46, "cv": 46, "hello": 46, "auto": 46, "autograd": 46, "grad_mod": 46, "0x7ff15e63ce50": 46, "speak": [46, 48], "human": [46, 48], "palm": [46, 48], "nor": [46, 48], "offend": [46, 48], "anthrop": [46, 48], "team": [46, 48], "got": [46, 48], "frustrat": [46, 48], "deepspe": [46, 48], "industri": [46, 48], "heavili": [46, 48], "credit": [46, 48], "nelson": [46, 48], "elhag": [46, 48], "chri": [46, 48], "olah": [46, 48], "model_description_text": 46, "hyper": 46, "1758": 46, "box": 46, "On": 46, "insid": 46, "kinda": 46, "gpt2_cache_no_batch_dim": 46, "gpt2_cach": 46, "gpt2_text": 46, "summar": 46, "supervis": 46, "taskspecif": 46, "gpt2_token": 46, "gpt2_logit": 46, "lock": 46, "grid": 46, "gpt2_str_token": 46, "neural": 46, "system": 46, "surgic": 46, "surround": 46, "current_activation_valu": 46, "new_activation_valu": 46, "substitut": 46, "relationship": 46, "underr": 46, "janki": 46, "shamelessli": 46, "probepoint": 46, "qualiti": 46, "head_ablation_hook": 46, "layer_to_abl": 46, "head_index_to_abl": 46, "original_loss": 46, "ablated_loss": 46, "3f": 46, "999": 46, "453": 46, "stai": 46, "clean_prompt": 46, "clean_token": 46, "logits_to_logit_diff": 46, "correct_answ": 46, "incorrect_answ": 46, "correct_index": 46, "incorrect_index": 46, "clean_logit": 46, "clean_logit_diff": 46, "corrupted_logit_diff": 46, "276": 46, "738": 46, "residual_stream_patching_hook": 46, "clean_resid_pr": 46, "num_posit": 46, "ioi_patching_result": 46, "temp_hook_fn": 46, "ish": 46, "token_label": 46, "workflow": 46, "michael": 46, "jordan": 46, "surnam": 46, "terribl": 46, "halfwai": 46, "input_tensor": 46, "random_token": 46, "repeated_logit": 46, "correct_log_prob": 46, "loss_by_posit": 46, "manipul": 46, "hook_funct": 46, "induction_score_stor": 46, "induction_score_hook": 46, "induction_strip": 46, "pattern_hook_names_filt": 46, "highli": 46, "stripe": 46, "induction_head_lay": 46, "induction_head_index": 46, "single_random_sequ": 46, "repeated_random_sequ": 46, "visualize_pattern_hook": 46, "3d": 46, "four": 46, "300m": 46, "soon": 46, "distilgpt": 46, "distilgpt2_induction_score_stor": 46, "classic": 46, "openai": 46, "85m": [46, 47], "700m": 46, "22b": 46, "300b": 46, "180b": 46, "600": 46, "265": 46, "108m": 46, "bookscorpu": 46, "free": 46, "512": [46, 47], "tractabl": 46, "motif": 46, "80": [46, 47], "shuffl": 46, "scan": 46, "40m": 46, "100m": 46, "200m": 46, "340m": [46, 47], "15b": 46, "13m": [46, 47], "digress": 46, "usefulli": 46, "variengien": 46, "websit": 46, "cleantransformerdemo": 46, "new_activ": 46, "old_activ": 46, "remind": 46, "50267": 46, "named_paramet": 46, "startswith": 46, "fallback": 46, "spam": 46, "dest_posit": 46, "brown": 46, "fox": 46, "lazi": 46, "dog": 46, "num": 46, "print_name_shape_hook_funct": 46, "not_in_late_block_filt": 46, "hook_q": 46, "hook_v": 46, "hook_attn_scor": 46, "hook_attn_out": 46, "hook_resid_mid": 46, "hook_post": 46, "hook_mlp_out": 46, "hook_resid_post": 46, "preconcept": 46, "overhead": 46, "elementwis": 46, "consequ": 46, "rare": 46, "dramat": 46, "degre": 46, "punctuat": 46, "ass": 46, "randomredditor": 46, "unembed_bia": 46, "bias_valu": 46, "bias_indic": 46, "repr": 46, "03": 46, "98": 46, "68": 46, "48": [46, 47], "47": 46, "72": [46, 47], "44": [46, 47], "82": 46, "\u30b5\u30fc\u30c6\u30a3": 46, "83": 46, "x18": 46, "x14": 46, "\u9f8d": 46, "x1b": 46, "x05": 46, "x00": 46, "x06": 46, "x07": 46, "x0c": 46, "x02": 46, "oreandonlin": 46, "x11": 46, "x10": 46, "favour": 46, "6x": 46, "john_bia": 46, "mary_bia": 46, "4f": 46, "exp": 46, "8995": 46, "6034": 46, "6550x": 46, "finit": 46, "invert": 46, "de": 46, "uncommon": 46, "iz": 46, "charact": 46, "example_text_str_token": 46, "example_text_token": 46, "50256": 46, "464": 46, "717": 46, "1517": 46, "345": 46, "761": 46, "284": 46, "3785": 46, "503": 46, "318": 46, "1635": 46, "4919": 46, "1243": 46, "389": 46, "11241": 46, "1143": 46, "4600": 46, "19849": 46, "1462": 46, "62": 46, "2536": 46, "482": 46, "641": 46, "63": 46, "30778": 46, "257": 46, "4731": 46, "656": 46, "262": 46, "16326": 46, "292": 46, "1351": 46, "286": 46, "850": 46, "37336": 46, "25666": 46, "290": 46, "523": 46, "8781": 46, "7301": 46, "644": 46, "2420": 46, "3073": 46, "588": 46, "1675": 46, "10176": 46, "428": 46, "1309": 46, "338": 46, "779": 46, "340": 46, "319": 46, "7322": 46, "signifi": 46, "example_multi_text": 46, "cat": 46, "sat": 46, "mat": 46, "example_multi_text_token": 46, "3797": 46, "3332": 46, "2603": 46, "1107": 46, "1327": 46, "th": 46, "cat_text": 46, "cat_logit": 46, "cat_prob": 46, "capital_the_token_index": 46, "ascii": 46, "squeez": 46, "annoy": 46, "arithmet": 46, "impress": 46, "2342": 46, "2017": 46, "21445": 46, "1000000": 46, "999999": 46, "214": 46, "000000": 46, "9999": 46, "tim": 46, "ne": 46, "el": 46, "messier": 46, "takeawai": 46, "unexpect": 46, "notic": 46, "trip": 46, "confusingli": 46, "forth": 46, "ioi_logits_with_bo": 46, "clair": 46, "mary_logit_with_bo": 46, "claire_logit_with_bo": 46, "ioi_logits_without_bo": 46, "mary_logit_without_bo": 46, "claire_logit_without_bo": 46, "754": 46, "782": 46, "air": 46, "understood": 46, "requisit": 46, "attention_scor": 46, "ab_factor": 46, "9105": 46, "linalg": 46, "eig": 46, "2877e": 46, "00": 46, "8626e": 46, "3121e": 46, "9038e": 46, "08": 46, "1527e": 46, "2877": 46, "3121": 46, "3126e": 46, "3963e": 46, "2029e": 46, "7690e": 46, "2164e": 46, "3126": 46, "3963": 46, "300": 46, "abc_factor": 46, "unfactor": 46, "160": 46, "0830": 46, "43": 46, "ab_unfactor": 46, "isclos": 46, "subspac": 46, "coincid": 46, "assert": 46, "negat": 46, "proxi": 46, "lambda_i": 46, "ov_circuit_all_head": 46, "ov_circuit_all_heads_eigenvalu": 46, "complex64": 46, "ov_copying_scor": 46, "zmax": 46, "zmin": 46, "l11h11": 46, "imag": 46, "imaginari": 46, "full_ov_circuit": 46, "full_ov_circuit_eigenvalu": 46, "full_ov_copying_scor": 46, "interestingli": 46, "correl": 46, "outlier": 46, "ansh": 46, "radhakrishnan": 46, "establish": 46, "53": 46, "presid": 46, "barack": 46, "obama": 46, "caught": 46, "embarrass": 46, "scandal": 46, "nthe": 46, "financi": 46, "wife": 46, "chelsea": 46, "she": 46, "woman": 46, "lightweight": 46, "squarethenadd": 46, "hook_squar": 46, "twolayermodel": 46, "layer1": 46, "layer2": 46, "hook_in": 46, "hook_mid": 46, "hook_out": 46, "x_in": 46, "x_mid": 46, "x_out": 46, "model_out": 46, "cache_object": 46, "780": 46, "784": 46, "56": [46, 47], "set_to_zero_hook": 46, "num_checkpoint": 46, "piecewis": 46, "schedul": 46, "crash": 46, "11b": [46, 47], "centr": 46, "hoc": 46, "count": 46, "checkpoint_label": 46, "log_i": 46, "marker": 46, "brief": 46, "suddenli": 46, "500": 46, "visibl": 46, "curv": 46, "briefli": 46, "deliber": 46, "justic": 46, "chosen": 46, "60": [46, 47], "500m": 46, "58": 46, "arbitrarili": 46, "fast": 46, "checkpoint_indic": 46, "checkpointed_model": 46, "tokens_trained_on": 46, "model_for_this_checkpoint": 46, "tokens_seen_for_this_checkpoint": 46, "induction_loss_for_this_checkpoint": 46, "contextualis": 46, "strategi": 46, "95": 46, "log_x": 46, "302m": 47, "4096": 47, "708m": 47, "1280": 47, "5120": 47, "1600": 47, "6400": 47, "42m": 47, "2048": 47, "50272": 47, "8192": 47, "2560": 47, "10240": 47, "128": 47, "16384": 47, "20480": 47, "7168": 47, "28672": 47, "9216": 47, "36864": 47, "50400": 47, "6144": 47, "50432": 47, "96": 47, "24576": 47, "2m": 47, "50304": 47, "7m": 47, "805m": 47, "50688": 47, "50278": 47, "736": 47, "2944": 47, "101m": 47, "197m": 47, "1536": 47, "48262": 47, "4m": 47, "0m": 47, "50277": 47, "524k": 47, "50259": 47, "32000": 47, "11008": 47, "13824": 47, "32b": 47, "6656": 47, "17920": 47, "22016": 47, "78b": 47, "32016": 47, "128256": 47, "14336": 47, "25m": 47, "28996": 47, "393k": 47, "6m": 47, "47b": 47, "250880": 47, "679m": 47, "0b": 47, "49280": 47, "151936": 47, "5504": 47, "152064": 47, "13696": 47, "308m": 47, "2816": 47, "6912": 47, "51200": 47, "32064": 47, "256000": 47, "64000": 47, "39b": 47, "100000": 47, "formerli": 48, "transfer": 48}, "objects": {"transformer_lens": [[10, 0, 0, "-", "ActivationCache"], [11, 0, 0, "-", "FactoredMatrix"], [12, 0, 0, "-", "HookedEncoder"], [13, 0, 0, "-", "HookedTransformer"], [14, 0, 0, "-", "HookedTransformerConfig"], [15, 0, 0, "-", "SVDInterpreter"], [35, 0, 0, "-", "evals"], [36, 0, 0, "-", "head_detector"], [37, 0, 0, "-", "hook_points"], [38, 0, 0, "-", "loading_from_pretrained"], [39, 0, 0, "-", "past_key_value_caching"], [40, 0, 0, "-", "patching"], [41, 0, 0, "-", "train"], [44, 0, 0, "-", "utils"]], "transformer_lens.ActivationCache": [[10, 1, 1, "", "ActivationCache"]], "transformer_lens.ActivationCache.ActivationCache": [[10, 2, 1, "", "accumulated_resid"], [10, 2, 1, "", "apply_ln_to_stack"], [10, 2, 1, "", "apply_slice_to_batch_dim"], [10, 2, 1, "", "compute_head_results"], [10, 2, 1, "", "decompose_resid"], [10, 2, 1, "", "get_full_resid_decomposition"], [10, 2, 1, "", "get_neuron_results"], [10, 2, 1, "", "items"], [10, 2, 1, "", "keys"], [10, 2, 1, "", "logit_attrs"], [10, 2, 1, "", "remove_batch_dim"], [10, 2, 1, "", "stack_activation"], [10, 2, 1, "", "stack_head_results"], [10, 2, 1, "", "stack_neuron_results"], [10, 2, 1, "", "to"], [10, 2, 1, "", "toggle_autodiff"], [10, 2, 1, "", "values"]], "transformer_lens.FactoredMatrix": [[11, 1, 1, "", "FactoredMatrix"]], "transformer_lens.FactoredMatrix.FactoredMatrix": [[11, 3, 1, "", "AB"], [11, 3, 1, "", "BA"], [11, 3, 1, "", "S"], [11, 3, 1, "", "T"], [11, 3, 1, "", "U"], [11, 3, 1, "", "Vh"], [11, 2, 1, "", "collapse_l"], [11, 2, 1, "", "collapse_r"], [11, 3, 1, "", "eigenvalues"], [11, 2, 1, "", "get_corner"], [11, 2, 1, "", "make_even"], [11, 3, 1, "", "ndim"], [11, 2, 1, "", "norm"], [11, 3, 1, "", "pair"], [11, 2, 1, "", "svd"], [11, 2, 1, "", "unsqueeze"]], "transformer_lens.HookedEncoder": [[12, 1, 1, "", "HookedEncoder"]], "transformer_lens.HookedEncoder.HookedEncoder": [[12, 3, 1, "", "OV"], [12, 3, 1, "", "QK"], [12, 3, 1, "", "W_E"], [12, 3, 1, "", "W_E_pos"], [12, 3, 1, "", "W_K"], [12, 3, 1, "", "W_O"], [12, 3, 1, "", "W_Q"], [12, 3, 1, "", "W_U"], [12, 3, 1, "", "W_V"], [12, 3, 1, "", "W_in"], [12, 3, 1, "", "W_out"], [12, 3, 1, "", "W_pos"], [12, 2, 1, "", "all_head_labels"], [12, 3, 1, "", "b_K"], [12, 3, 1, "", "b_O"], [12, 3, 1, "", "b_Q"], [12, 3, 1, "", "b_U"], [12, 3, 1, "", "b_V"], [12, 3, 1, "", "b_in"], [12, 3, 1, "", "b_out"], [12, 2, 1, "", "cpu"], [12, 2, 1, "", "cuda"], [12, 2, 1, "", "forward"], [12, 2, 1, "", "from_pretrained"], [12, 2, 1, "", "mps"], [12, 2, 1, "", "run_with_cache"], [12, 2, 1, "", "to"]], "transformer_lens.HookedTransformer": [[13, 1, 1, "", "HookedTransformer"], [13, 1, 1, "", "Output"]], "transformer_lens.HookedTransformer.HookedTransformer": [[13, 3, 1, "", "OV"], [13, 3, 1, "", "QK"], [13, 3, 1, "", "W_E"], [13, 3, 1, "", "W_E_pos"], [13, 3, 1, "", "W_K"], [13, 3, 1, "", "W_O"], [13, 3, 1, "", "W_Q"], [13, 3, 1, "", "W_U"], [13, 3, 1, "", "W_V"], [13, 3, 1, "", "W_gate"], [13, 3, 1, "", "W_in"], [13, 3, 1, "", "W_out"], [13, 3, 1, "", "W_pos"], [13, 2, 1, "", "__init__"], [13, 2, 1, "", "accumulated_bias"], [13, 2, 1, "", "all_composition_scores"], [13, 2, 1, "", "all_head_labels"], [13, 3, 1, "", "b_K"], [13, 3, 1, "", "b_O"], [13, 3, 1, "", "b_Q"], [13, 3, 1, "", "b_U"], [13, 3, 1, "", "b_V"], [13, 3, 1, "", "b_in"], [13, 3, 1, "", "b_out"], [13, 2, 1, "", "center_unembed"], [13, 2, 1, "", "center_writing_weights"], [13, 2, 1, "", "check_hooks_to_add"], [13, 2, 1, "", "cpu"], [13, 2, 1, "", "cuda"], [13, 2, 1, "", "fold_layer_norm"], [13, 2, 1, "", "fold_value_biases"], [13, 2, 1, "", "forward"], [13, 2, 1, "", "from_pretrained"], [13, 2, 1, "", "from_pretrained_no_processing"], [13, 2, 1, "", "generate"], [13, 2, 1, "", "get_token_position"], [13, 2, 1, "", "init_weights"], [13, 2, 1, "", "input_to_embed"], [13, 4, 1, "", "ln_final"], [13, 2, 1, "", "load_and_process_state_dict"], [13, 2, 1, "", "load_sample_training_dataset"], [13, 2, 1, "", "loss_fn"], [13, 2, 1, "", "move_model_modules_to_device"], [13, 2, 1, "", "mps"], [13, 2, 1, "", "process_weights_"], [13, 2, 1, "", "refactor_factored_attn_matrices"], [13, 2, 1, "", "run_with_cache"], [13, 2, 1, "", "sample_datapoint"], [13, 2, 1, "", "set_tokenizer"], [13, 2, 1, "", "set_use_attn_in"], [13, 2, 1, "", "set_use_attn_result"], [13, 2, 1, "", "set_use_hook_mlp_in"], [13, 2, 1, "", "set_use_split_qkv_input"], [13, 2, 1, "", "to"], [13, 2, 1, "", "to_single_str_token"], [13, 2, 1, "", "to_single_token"], [13, 2, 1, "", "to_str_tokens"], [13, 2, 1, "", "to_string"], [13, 2, 1, "", "to_tokens"], [13, 2, 1, "", "tokens_to_residual_directions"]], "transformer_lens.HookedTransformer.Output": [[13, 4, 1, "", "logits"], [13, 4, 1, "", "loss"]], "transformer_lens.HookedTransformerConfig": [[14, 1, 1, "", "HookedTransformerConfig"]], "transformer_lens.HookedTransformerConfig.HookedTransformerConfig": [[14, 4, 1, "", "act_fn"], [14, 4, 1, "", "attention_dir"], [14, 4, 1, "", "attn_only"], [14, 4, 1, "", "attn_types"], [14, 4, 1, "", "checkpoint_index"], [14, 4, 1, "", "checkpoint_label_type"], [14, 4, 1, "", "checkpoint_value"], [14, 4, 1, "", "d_head"], [14, 4, 1, "", "d_mlp"], [14, 4, 1, "", "d_model"], [14, 4, 1, "", "d_vocab"], [14, 4, 1, "", "d_vocab_out"], [14, 4, 1, "", "default_prepend_bos"], [14, 4, 1, "", "device"], [14, 4, 1, "", "dtype"], [14, 4, 1, "", "eps"], [14, 4, 1, "", "experts_per_token"], [14, 4, 1, "", "final_rms"], [14, 4, 1, "", "from_checkpoint"], [14, 2, 1, "", "from_dict"], [14, 4, 1, "", "gated_mlp"], [14, 4, 1, "", "init_mode"], [14, 4, 1, "", "init_weights"], [14, 4, 1, "", "initializer_range"], [14, 4, 1, "", "load_in_4bit"], [14, 4, 1, "", "model_name"], [14, 4, 1, "", "n_ctx"], [14, 4, 1, "", "n_devices"], [14, 4, 1, "", "n_heads"], [14, 4, 1, "", "n_key_value_heads"], [14, 4, 1, "", "n_layers"], [14, 4, 1, "", "n_params"], [14, 4, 1, "", "normalization_type"], [14, 4, 1, "", "num_experts"], [14, 4, 1, "", "original_architecture"], [14, 4, 1, "", "parallel_attn_mlp"], [14, 4, 1, "", "positional_embedding_type"], [14, 4, 1, "", "post_embedding_ln"], [14, 4, 1, "", "rotary_adjacent_pairs"], [14, 4, 1, "", "rotary_base"], [14, 4, 1, "", "rotary_dim"], [14, 4, 1, "", "scale_attn_by_inverse_layer_idx"], [14, 4, 1, "", "seed"], [14, 2, 1, "", "set_seed_everywhere"], [14, 2, 1, "", "to_dict"], [14, 4, 1, "", "tokenizer_name"], [14, 4, 1, "", "tokenizer_prepends_bos"], [14, 4, 1, "", "trust_remote_code"], [14, 2, 1, "", "unwrap"], [14, 4, 1, "", "use_attn_in"], [14, 4, 1, "", "use_attn_result"], [14, 4, 1, "", "use_attn_scale"], [14, 4, 1, "", "use_hook_mlp_in"], [14, 4, 1, "", "use_hook_tokens"], [14, 4, 1, "", "use_local_attn"], [14, 4, 1, "", "use_split_qkv_input"], [14, 4, 1, "", "window_size"]], "transformer_lens.SVDInterpreter": [[15, 1, 1, "", "SVDInterpreter"]], "transformer_lens.SVDInterpreter.SVDInterpreter": [[15, 2, 1, "", "get_singular_vectors"]], "transformer_lens.components": [[17, 0, 0, "-", "abstract_attention"], [18, 0, 0, "-", "attention"], [19, 0, 0, "-", "bert_block"], [20, 0, 0, "-", "bert_embed"], [21, 0, 0, "-", "bert_mlm_head"], [22, 0, 0, "-", "embed"], [23, 0, 0, "-", "gated_mlp"], [24, 0, 0, "-", "grouped_query_attention"], [25, 0, 0, "-", "layer_norm"], [26, 0, 0, "-", "layer_norm_pre"], [27, 0, 0, "-", "mlp"], [28, 0, 0, "-", "moe"], [29, 0, 0, "-", "pos_embed"], [30, 0, 0, "-", "rms_norm"], [31, 0, 0, "-", "rms_norm_pre"], [32, 0, 0, "-", "token_typed_embed"], [33, 0, 0, "-", "transformer_block"], [34, 0, 0, "-", "unembed"]], "transformer_lens.components.abstract_attention": [[17, 1, 1, "", "AbstractAttention"]], "transformer_lens.components.abstract_attention.AbstractAttention": [[17, 3, 1, "", "OV"], [17, 3, 1, "", "QK"], [17, 2, 1, "", "__init__"], [17, 4, 1, "", "alibi"], [17, 2, 1, "", "apply_causal_mask"], [17, 2, 1, "", "apply_rotary"], [17, 2, 1, "", "calculate_attention_scores"], [17, 2, 1, "", "calculate_qkv_matrices"], [17, 2, 1, "", "calculate_sin_cos_rotary"], [17, 2, 1, "", "calculate_z_scores"], [17, 2, 1, "", "create_alibi_bias"], [17, 2, 1, "", "create_alibi_multipliers"], [17, 2, 1, "", "create_alibi_slope"], [17, 2, 1, "", "forward"], [17, 2, 1, "", "rotate_every_two"]], "transformer_lens.components.attention": [[18, 1, 1, "", "Attention"]], "transformer_lens.components.attention.Attention": [[18, 2, 1, "", "__init__"]], "transformer_lens.components.bert_block": [[19, 1, 1, "", "BertBlock"]], "transformer_lens.components.bert_block.BertBlock": [[19, 2, 1, "", "forward"]], "transformer_lens.components.bert_embed": [[20, 1, 1, "", "BertEmbed"]], "transformer_lens.components.bert_embed.BertEmbed": [[20, 2, 1, "", "forward"]], "transformer_lens.components.bert_mlm_head": [[21, 1, 1, "", "BertMLMHead"]], "transformer_lens.components.bert_mlm_head.BertMLMHead": [[21, 2, 1, "", "forward"]], "transformer_lens.components.embed": [[22, 1, 1, "", "Embed"]], "transformer_lens.components.embed.Embed": [[22, 2, 1, "", "forward"]], "transformer_lens.components.gated_mlp": [[23, 1, 1, "", "GatedMLP"]], "transformer_lens.components.gated_mlp.GatedMLP": [[23, 4, 1, "", "act_fn"], [23, 2, 1, "", "forward"], [23, 4, 1, "", "ln"]], "transformer_lens.components.grouped_query_attention": [[24, 1, 1, "", "GroupedQueryAttention"]], "transformer_lens.components.grouped_query_attention.GroupedQueryAttention": [[24, 3, 1, "", "W_K"], [24, 3, 1, "", "W_V"], [24, 2, 1, "", "__init__"], [24, 3, 1, "", "b_K"], [24, 3, 1, "", "b_V"], [24, 2, 1, "", "calculate_attention_scores"], [24, 2, 1, "", "calculate_qkv_matrices"], [24, 2, 1, "", "calculate_z_scores"]], "transformer_lens.components.layer_norm": [[25, 1, 1, "", "LayerNorm"]], "transformer_lens.components.layer_norm.LayerNorm": [[25, 2, 1, "", "__init__"], [25, 2, 1, "", "forward"]], "transformer_lens.components.layer_norm_pre": [[26, 1, 1, "", "LayerNormPre"]], "transformer_lens.components.layer_norm_pre.LayerNormPre": [[26, 2, 1, "", "__init__"], [26, 2, 1, "", "forward"]], "transformer_lens.components.mlp": [[27, 1, 1, "", "MLP"]], "transformer_lens.components.mlp.MLP": [[27, 4, 1, "", "act_fn"], [27, 2, 1, "", "forward"], [27, 4, 1, "", "ln"]], "transformer_lens.components.moe": [[28, 1, 1, "", "MoE"]], "transformer_lens.components.moe.MoE": [[28, 2, 1, "", "forward"]], "transformer_lens.components.pos_embed": [[29, 1, 1, "", "PosEmbed"]], "transformer_lens.components.pos_embed.PosEmbed": [[29, 2, 1, "", "forward"]], "transformer_lens.components.rms_norm": [[30, 1, 1, "", "RMSNorm"]], "transformer_lens.components.rms_norm.RMSNorm": [[30, 2, 1, "", "__init__"], [30, 2, 1, "", "forward"]], "transformer_lens.components.rms_norm_pre": [[31, 1, 1, "", "RMSNormPre"]], "transformer_lens.components.rms_norm_pre.RMSNormPre": [[31, 2, 1, "", "__init__"], [31, 2, 1, "", "forward"]], "transformer_lens.components.token_typed_embed": [[32, 1, 1, "", "TokenTypeEmbed"]], "transformer_lens.components.token_typed_embed.TokenTypeEmbed": [[32, 2, 1, "", "forward"]], "transformer_lens.components.transformer_block": [[33, 1, 1, "", "TransformerBlock"]], "transformer_lens.components.transformer_block.TransformerBlock": [[33, 2, 1, "", "forward"], [33, 4, 1, "", "ln1"], [33, 4, 1, "", "ln2"], [33, 4, 1, "", "mlp"]], "transformer_lens.components.unembed": [[34, 1, 1, "", "Unembed"]], "transformer_lens.components.unembed.Unembed": [[34, 2, 1, "", "forward"]], "transformer_lens.evals": [[35, 1, 1, "", "IOIDataset"], [35, 5, 1, "", "evaluate"], [35, 5, 1, "", "evaluate_on_dataset"], [35, 5, 1, "", "induction_loss"], [35, 5, 1, "", "ioi_eval"], [35, 5, 1, "", "make_code_data_loader"], [35, 5, 1, "", "make_owt_data_loader"], [35, 5, 1, "", "make_pile_data_loader"], [35, 5, 1, "", "make_wiki_data_loader"], [35, 5, 1, "", "sanity_check"]], "transformer_lens.evals.IOIDataset": [[35, 2, 1, "", "get_default_names"], [35, 2, 1, "", "get_default_nouns"], [35, 2, 1, "", "get_default_templates"], [35, 2, 1, "", "get_sample"]], "transformer_lens.head_detector": [[36, 5, 1, "", "compute_head_attention_similarity_score"], [36, 5, 1, "", "detect_head"], [36, 5, 1, "", "get_duplicate_token_head_detection_pattern"], [36, 5, 1, "", "get_induction_head_detection_pattern"], [36, 5, 1, "", "get_previous_token_head_detection_pattern"], [36, 5, 1, "", "get_supported_heads"]], "transformer_lens.hook_points": [[37, 4, 1, "", "HookFunction"], [37, 1, 1, "", "HookPoint"], [37, 1, 1, "", "HookedRootModule"], [37, 1, 1, "", "LensHandle"]], "transformer_lens.hook_points.HookPoint": [[37, 2, 1, "", "add_hook"], [37, 2, 1, "", "add_perma_hook"], [37, 2, 1, "", "clear_context"], [37, 2, 1, "", "forward"], [37, 2, 1, "", "layer"], [37, 2, 1, "", "remove_hooks"]], "transformer_lens.hook_points.HookedRootModule": [[37, 2, 1, "", "add_caching_hooks"], [37, 2, 1, "", "add_hook"], [37, 2, 1, "", "add_perma_hook"], [37, 2, 1, "", "cache_all"], [37, 2, 1, "", "cache_some"], [37, 2, 1, "", "check_and_add_hook"], [37, 2, 1, "", "check_hooks_to_add"], [37, 2, 1, "", "clear_contexts"], [37, 2, 1, "", "get_caching_hooks"], [37, 4, 1, "", "hook_dict"], [37, 2, 1, "", "hook_points"], [37, 2, 1, "", "hooks"], [37, 4, 1, "", "mod_dict"], [37, 4, 1, "", "name"], [37, 2, 1, "", "remove_all_hook_fns"], [37, 2, 1, "", "reset_hooks"], [37, 2, 1, "", "run_with_cache"], [37, 2, 1, "", "run_with_hooks"], [37, 2, 1, "", "setup"]], "transformer_lens.hook_points.LensHandle": [[37, 4, 1, "", "context_level"], [37, 4, 1, "", "hook"], [37, 4, 1, "", "is_permanent"]], "transformer_lens.loading_from_pretrained": [[38, 1, 1, "", "Config"], [38, 6, 1, "", "MODEL_ALIASES"], [38, 6, 1, "", "NON_HF_HOSTED_MODEL_NAMES"], [38, 6, 1, "", "OFFICIAL_MODEL_NAMES"], [38, 5, 1, "", "convert_bloom_weights"], [38, 5, 1, "", "convert_coder_weights"], [38, 5, 1, "", "convert_mistral_weights"], [38, 5, 1, "", "convert_mixtral_weights"], [38, 5, 1, "", "convert_phi3_weights"], [38, 5, 1, "", "convert_phi_weights"], [38, 5, 1, "", "convert_qwen2_weights"], [38, 5, 1, "", "convert_qwen_weights"], [38, 5, 1, "", "get_checkpoint_labels"], [38, 5, 1, "", "get_num_params_of_pretrained"], [38, 5, 1, "", "get_pretrained_model_config"]], "transformer_lens.loading_from_pretrained.Config": [[38, 4, 1, "", "d_head"], [38, 4, 1, "", "d_mlp"], [38, 4, 1, "", "d_model"], [38, 4, 1, "", "d_vocab"], [38, 4, 1, "", "debug"], [38, 4, 1, "", "init_range"], [38, 4, 1, "", "layer_norm_eps"], [38, 4, 1, "", "n_ctx"], [38, 4, 1, "", "n_heads"], [38, 4, 1, "", "n_layers"]], "transformer_lens.past_key_value_caching": [[39, 1, 1, "", "HookedTransformerKeyValueCache"], [39, 1, 1, "", "HookedTransformerKeyValueCacheEntry"]], "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache": [[39, 2, 1, "", "append_attention_mask"], [39, 4, 1, "", "entries"], [39, 2, 1, "", "freeze"], [39, 4, 1, "", "frozen"], [39, 2, 1, "", "init_cache"], [39, 4, 1, "", "previous_attention_mask"], [39, 2, 1, "", "unfreeze"]], "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry": [[39, 2, 1, "", "append"], [39, 4, 1, "", "frozen"], [39, 2, 1, "", "init_cache_entry"], [39, 4, 1, "", "past_keys"], [39, 4, 1, "", "past_values"]], "transformer_lens.patching": [[40, 5, 1, "", "generic_activation_patch"], [40, 5, 1, "", "get_act_patch_attn_head_all_pos_every"], [40, 5, 1, "", "get_act_patch_attn_head_by_pos_every"], [40, 5, 1, "", "get_act_patch_attn_head_k_all_pos"], [40, 5, 1, "", "get_act_patch_attn_head_k_by_pos"], [40, 5, 1, "", "get_act_patch_attn_head_out_all_pos"], [40, 5, 1, "", "get_act_patch_attn_head_out_by_pos"], [40, 5, 1, "", "get_act_patch_attn_head_pattern_all_pos"], [40, 5, 1, "", "get_act_patch_attn_head_pattern_by_pos"], [40, 5, 1, "", "get_act_patch_attn_head_pattern_dest_src_pos"], [40, 5, 1, "", "get_act_patch_attn_head_q_all_pos"], [40, 5, 1, "", "get_act_patch_attn_head_q_by_pos"], [40, 5, 1, "", "get_act_patch_attn_head_v_all_pos"], [40, 5, 1, "", "get_act_patch_attn_head_v_by_pos"], [40, 5, 1, "", "get_act_patch_attn_out"], [40, 5, 1, "", "get_act_patch_block_every"], [40, 5, 1, "", "get_act_patch_mlp_out"], [40, 5, 1, "", "get_act_patch_resid_mid"], [40, 5, 1, "", "get_act_patch_resid_pre"], [40, 5, 1, "", "layer_head_dest_src_pos_pattern_patch_setter"], [40, 5, 1, "", "layer_head_pattern_patch_setter"], [40, 5, 1, "", "layer_head_pos_pattern_patch_setter"], [40, 5, 1, "", "layer_head_vector_patch_setter"], [40, 5, 1, "", "layer_pos_head_vector_patch_setter"], [40, 5, 1, "", "layer_pos_patch_setter"]], "transformer_lens.train": [[41, 1, 1, "", "HookedTransformerTrainConfig"], [41, 5, 1, "", "train"]], "transformer_lens.train.HookedTransformerTrainConfig": [[41, 4, 1, "", "batch_size"], [41, 4, 1, "", "device"], [41, 4, 1, "", "lr"], [41, 4, 1, "", "max_grad_norm"], [41, 4, 1, "", "max_steps"], [41, 4, 1, "", "momentum"], [41, 4, 1, "", "num_epochs"], [41, 4, 1, "", "optimizer_name"], [41, 4, 1, "", "print_every"], [41, 4, 1, "", "save_dir"], [41, 4, 1, "", "save_every"], [41, 4, 1, "", "seed"], [41, 4, 1, "", "wandb"], [41, 4, 1, "", "wandb_project_name"], [41, 4, 1, "", "warmup_steps"], [41, 4, 1, "", "weight_decay"]], "transformer_lens.utilities": [[43, 0, 0, "-", "devices"]], "transformer_lens.utilities.devices": [[43, 5, 1, "", "get_device_for_block_index"], [43, 5, 1, "", "move_to_and_update_config"]], "transformer_lens.utils": [[44, 1, 1, "", "LocallyOverridenDefaults"], [44, 1, 1, "", "Slice"], [44, 6, 1, "", "SliceInput"], [44, 5, 1, "", "calc_fan_in_and_fan_out"], [44, 5, 1, "", "composition_scores"], [44, 5, 1, "", "download_file_from_hf"], [44, 5, 1, "", "gelu_fast"], [44, 5, 1, "", "gelu_new"], [44, 5, 1, "", "get_act_name"], [44, 5, 1, "", "get_attention_mask"], [44, 5, 1, "", "get_corner"], [44, 5, 1, "", "get_cumsum_along_dim"], [44, 5, 1, "", "get_dataset"], [44, 5, 1, "", "get_device"], [44, 5, 1, "", "get_input_with_manually_prepended_bos"], [44, 5, 1, "", "get_nested_attr"], [44, 5, 1, "", "get_offset_position_ids"], [44, 5, 1, "", "get_tokenizer_with_bos"], [44, 5, 1, "", "get_tokens_with_bos_removed"], [44, 5, 1, "", "init_kaiming_normal_"], [44, 5, 1, "", "init_kaiming_uniform_"], [44, 5, 1, "", "init_xavier_normal_"], [44, 5, 1, "", "init_xavier_uniform_"], [44, 5, 1, "", "is_lower_triangular"], [44, 5, 1, "", "is_square"], [44, 5, 1, "", "keep_single_column"], [44, 5, 1, "", "lm_accuracy"], [44, 5, 1, "", "lm_cross_entropy_loss"], [44, 5, 1, "", "override_or_use_default_value"], [44, 5, 1, "", "print_gpu_mem"], [44, 5, 1, "", "remove_batch_dim"], [44, 5, 1, "", "repeat_along_head_dimension"], [44, 5, 1, "", "sample_logits"], [44, 5, 1, "", "set_nested_attr"], [44, 5, 1, "", "solu"], [44, 5, 1, "", "test_prompt"], [44, 5, 1, "", "to_numpy"], [44, 5, 1, "", "tokenize_and_concatenate"], [44, 5, 1, "", "transpose"]], "transformer_lens.utils.LocallyOverridenDefaults": [[44, 2, 1, "", "__init__"]], "transformer_lens.utils.Slice": [[44, 2, 1, "", "__init__"], [44, 2, 1, "", "apply"], [44, 2, 1, "", "indices"], [44, 4, 1, "", "slice"], [44, 2, 1, "", "unwrap"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:attribute", "5": "py:function", "6": "py:data"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"], "6": ["py", "data", "Python data"]}, "titleterms": {"citat": 0, "contribut": 1, "setup": [1, 45, 46], "devcontain": 1, "manual": 1, "test": [1, 5], "run": [1, 46], "format": 1, "document": 1, "docstr": 1, "style": 1, "guid": 1, "section": 1, "order": 1, "support": 1, "sphinx": 1, "properti": [1, 47], "refer": 1, "other": [1, 46], "function": [1, 45], "class": [1, 46], "math": 1, "markup": 1, "galleri": 2, "get": [3, 4], "start": [3, 4, 7], "advic": 3, "read": [3, 45], "code": 3, "instal": 3, "huggingfac": 3, "gate": 3, "access": [3, 46], "mechanist": [4, 48], "interpret": [4, 46, 48], "transformerlen": [5, 48], "2": 5, "0": 5, "first": 5, "an": [5, 46], "introduct": [5, 45, 46], "adopt": 5, "semant": 5, "version": 5, "deprec": 5, "roadmap": 5, "immedi": 5, "within": 5, "next": 5, "month": 5, "mid": 5, "term": 5, "3": 5, "perform": 5, "streamlin": 5, "ad": 5, "new": 5, "model": [5, 46, 47, 48], "long": 5, "year": 5, "integr": 5, "contributor": 5, "dev": 5, "branch": 5, "coverag": 5, "compon": [5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "refactor": 5, "conclus": 5, "appendix": 5, "special": 6, "case": 6, "mixtur": 6, "expert": 6, "error": 6, "rate": 6, "tutori": 7, "where": 7, "To": 7, "demo": [7, 45, 46], "transform": [8, 46], "len": [8, 45, 46], "api": 8, "content": 8, "transformer_len": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "submodul": [9, 16, 42], "subpackag": 9, "activationcach": 10, "factoredmatrix": 11, "hookedencod": 12, "hookedtransform": 13, "hookedtransformerconfig": 14, "svdinterpret": 15, "abstract_attent": 17, "attent": [18, 45], "bert_block": 19, "bert_emb": 20, "bert_mlm_head": 21, "emb": 22, "gated_mlp": 23, "grouped_query_attent": 24, "layer_norm": 25, "layer_norm_pr": 26, "mlp": 27, "moe": 28, "pos_emb": 29, "rms_norm": 30, "rms_norm_pr": 31, "token_typed_emb": 32, "transformer_block": 33, "unemb": 34, "eval": 35, "head_detector": 36, "hook_point": 37, "loading_from_pretrain": 38, "past_key_value_cach": 39, "patch": [40, 45, 46], "train": [41, 46], "util": [42, 43, 44], "devic": 43, "exploratori": 45, "analysi": 45, "tip": 45, "thi": 45, "environ": 45, "ignor": 45, "import": [45, 46], "pytorch": 45, "plot": 45, "helper": 45, "indirect": [45, 46], "object": [45, 46], "identif": [45, 46], "brainstorm": 45, "what": 45, "": 45, "actual": 45, "go": 45, "On": 45, "option": 45, "direct": 45, "logit": 45, "attribut": 45, "layer": 45, "head": [45, 46], "activ": [45, 46], "residu": 45, "stream": 45, "decompos": 45, "consolid": 45, "understand": 45, "visual": 45, "pattern": 45, "compar": 45, "paper": 45, "bonu": 45, "explor": 45, "anomali": 45, "earli": 45, "ar": 45, "induct": [45, 46], "implic": 45, "backup": 45, "name": [45, 46], "mover": 45, "main": 46, "notebook": 46, "load": 46, "cach": 46, "all": 46, "hook": 46, "interven": 46, "task": 46, "avail": 46, "overview": 46, "open": 46, "sourc": 46, "librari": [46, 48], "some": 46, "friendli": 46, "i": 46, "ve": 46, "includ": 46, "resourc": 46, "architectur": 46, "paramet": 46, "fold": 46, "layernorm": 46, "For": 46, "curiou": 46, "featur": 46, "deal": 46, "token": 46, "gotcha": 46, "prepend_bo": 46, "factor": 46, "matrix": 46, "basic": 46, "exampl": 46, "medium": 46, "eigenvalu": 46, "copi": 46, "score": 46, "gener": [46, 48], "text": 46, "point": 46, "toi": 46, "pre": 46, "checkpoint": 46, "phase": 46, "transit": 46, "tabl": 47, "A": 48, "languag": 48}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx": 57}, "alltitles": {"Citation": [[0, "citation"]], "Contributing": [[1, "contributing"]], "Setup": [[1, "setup"], [45, "Setup"], [46, "Setup"]], "DevContainer": [[1, "devcontainer"]], "Manual Setup": [[1, "manual-setup"]], "Testing": [[1, "testing"]], "Running the tests": [[1, "running-the-tests"]], "Formatting": [[1, "formatting"]], "Documentation": [[1, "documentation"]], "Docstring Style Guide": [[1, "docstring-style-guide"]], "Sections and Order": [[1, "sections-and-order"]], "Supported Sphinx Properties": [[1, "supported-sphinx-properties"]], "References to Other Functions/Classes": [[1, "references-to-other-functions-classes"]], "Maths": [[1, "maths"]], "Markup": [[1, "markup"]], "Gallery": [[2, "gallery"]], "Getting Started": [[3, "getting-started"]], "Advice for Reading the Code": [[3, "advice-for-reading-the-code"]], "Installation": [[3, "installation"]], "Huggingface Gated Access": [[3, "huggingface-gated-access"]], "Getting Started in Mechanistic Interpretability": [[4, "getting-started-in-mechanistic-interpretability"]], "TransformerLens 2.0": [[5, "transformerlens-2-0"]], "First, an introduction": [[5, "first-an-introduction"]], "Adopting Semantic Versioning": [[5, "adopting-semantic-versioning"]], "Deprecations": [[5, "deprecations"]], "Roadmap": [[5, "roadmap"]], "Immediate - within the next month": [[5, "immediate-within-the-next-month"]], "Mid-term - within the next 3 months": [[5, "mid-term-within-the-next-3-months"]], "Performance": [[5, "performance"]], "Streamlining Adding New Models": [[5, "streamlining-adding-new-models"]], "Long-term - within the next year": [[5, "long-term-within-the-next-year"]], "Model Testing": [[5, "model-testing"]], "Model Integration": [[5, "model-integration"]], "Contributors": [[5, "contributors"]], "New Dev Branches": [[5, "new-dev-branches"]], "Integration Tests": [[5, "integration-tests"]], "Test Coverage": [[5, "test-coverage"]], "Components Refactor": [[5, "components-refactor"]], "Conclusion": [[5, "conclusion"]], "Appendix": [[5, "appendix"]], "Semantic Versioning": [[5, "semantic-versioning"]], "Special Cases": [[6, "special-cases"]], "Mixture of Experts error rates": [[6, "mixture-of-experts-error-rates"]], "Tutorials": [[7, "tutorials"]], "Where To Start": [[7, "where-to-start"]], "Demos": [[7, "demos"]], "Transformer Lens API": [[8, "transformer-lens-api"]], "Contents": [[8, "contents"]], "transformer_lens": [[9, "transformer-lens"]], "Submodules": [[9, "submodules"], [16, "submodules"], [42, "submodules"]], "Subpackages": [[9, "subpackages"]], "transformer_lens.ActivationCache": [[10, "module-transformer_lens.ActivationCache"]], "transformer_lens.FactoredMatrix": [[11, "module-transformer_lens.FactoredMatrix"]], "transformer_lens.HookedEncoder": [[12, "module-transformer_lens.HookedEncoder"]], "transformer_lens.HookedTransformer": [[13, "module-transformer_lens.HookedTransformer"]], "transformer_lens.HookedTransformerConfig": [[14, "module-transformer_lens.HookedTransformerConfig"]], "transformer_lens.SVDInterpreter": [[15, "module-transformer_lens.SVDInterpreter"]], "transformer_lens.components": [[16, "transformer-lens-components"]], "transformer_lens.components.abstract_attention": [[17, "module-transformer_lens.components.abstract_attention"]], "transformer_lens.components.attention": [[18, "module-transformer_lens.components.attention"]], "transformer_lens.components.bert_block": [[19, "module-transformer_lens.components.bert_block"]], "transformer_lens.components.bert_embed": [[20, "module-transformer_lens.components.bert_embed"]], "transformer_lens.components.bert_mlm_head": [[21, "module-transformer_lens.components.bert_mlm_head"]], "transformer_lens.components.embed": [[22, "module-transformer_lens.components.embed"]], "transformer_lens.components.gated_mlp": [[23, "module-transformer_lens.components.gated_mlp"]], "transformer_lens.components.grouped_query_attention": [[24, "module-transformer_lens.components.grouped_query_attention"]], "transformer_lens.components.layer_norm": [[25, "module-transformer_lens.components.layer_norm"]], "transformer_lens.components.layer_norm_pre": [[26, "module-transformer_lens.components.layer_norm_pre"]], "transformer_lens.components.mlp": [[27, "module-transformer_lens.components.mlp"]], "transformer_lens.components.moe": [[28, "module-transformer_lens.components.moe"]], "transformer_lens.components.pos_embed": [[29, "module-transformer_lens.components.pos_embed"]], "transformer_lens.components.rms_norm": [[30, "module-transformer_lens.components.rms_norm"]], "transformer_lens.components.rms_norm_pre": [[31, "module-transformer_lens.components.rms_norm_pre"]], "transformer_lens.components.token_typed_embed": [[32, "module-transformer_lens.components.token_typed_embed"]], "transformer_lens.components.transformer_block": [[33, "module-transformer_lens.components.transformer_block"]], "transformer_lens.components.unembed": [[34, "module-transformer_lens.components.unembed"]], "transformer_lens.evals": [[35, "module-transformer_lens.evals"]], "transformer_lens.head_detector": [[36, "module-transformer_lens.head_detector"]], "transformer_lens.hook_points": [[37, "module-transformer_lens.hook_points"]], "transformer_lens.loading_from_pretrained": [[38, "module-transformer_lens.loading_from_pretrained"]], "transformer_lens.past_key_value_caching": [[39, "module-transformer_lens.past_key_value_caching"]], "transformer_lens.patching": [[40, "module-transformer_lens.patching"]], "transformer_lens.train": [[41, "module-transformer_lens.train"]], "transformer_lens.utilities": [[42, "transformer-lens-utilities"]], "transformer_lens.utilities.devices": [[43, "module-transformer_lens.utilities.devices"]], "transformer_lens.utils": [[44, "module-transformer_lens.utils"]], "Exploratory Analysis Demo": [[45, "Exploratory-Analysis-Demo"]], "Tips for Reading This": [[45, "Tips-for-Reading-This"]], "Environment Setup (ignore)": [[45, "Environment-Setup-(ignore)"]], "Imports": [[45, "Imports"]], "PyTorch Setup": [[45, "PyTorch-Setup"]], "Plotting Helper Functions (ignore)": [[45, "Plotting-Helper-Functions-(ignore)"]], "Introduction": [[45, "Introduction"], [46, "Introduction"]], "Indirect Object Identification": [[45, "Indirect-Object-Identification"]], "Brainstorm What\u2019s Actually Going On (Optional)": [[45, "Brainstorm-What's-Actually-Going-On-(Optional)"]], "Direct Logit Attribution": [[45, "Direct-Logit-Attribution"]], "Logit Lens": [[45, "Logit-Lens"]], "Layer Attribution": [[45, "Layer-Attribution"]], "Head Attribution": [[45, "Head-Attribution"]], "Attention Analysis": [[45, "Attention-Analysis"]], "Activation Patching": [[45, "Activation-Patching"]], "Residual Stream": [[45, "Residual-Stream"]], "Layers": [[45, "Layers"]], "Heads": [[45, "Heads"]], "Decomposing Heads": [[45, "Decomposing-Heads"]], "Consolidating Understanding": [[45, "Consolidating-Understanding"]], "Visualizing Attention Patterns": [[45, "Visualizing-Attention-Patterns"]], "Comparing to the Paper": [[45, "Comparing-to-the-Paper"]], "Bonus: Exploring Anomalies": [[45, "Bonus:-Exploring-Anomalies"]], "Early Heads are Induction Heads(?!)": [[45, "Early-Heads-are-Induction-Heads(?!)"]], "Implications": [[45, "Implications"]], "Backup Name Mover Heads": [[45, "Backup-Name-Mover-Heads"]], "Transformer Lens Main Demo Notebook": [[46, "Transformer-Lens-Main-Demo-Notebook"]], "Loading and Running Models": [[46, "Loading-and-Running-Models"]], "Caching all Activations": [[46, "Caching-all-Activations"]], "Hooks: Intervening on Activations": [[46, "Hooks:-Intervening-on-Activations"]], "Activation Patching on the Indirect Object Identification Task": [[46, "Activation-Patching-on-the-Indirect-Object-Identification-Task"]], "Hooks: Accessing Activations": [[46, "Hooks:-Accessing-Activations"]], "Available Models": [[46, "Available-Models"]], "An overview of the important open source models in the library": [[46, "An-overview-of-the-important-open-source-models-in-the-library"]], "An overview of some interpretability-friendly models I\u2019ve trained and included": [[46, "An-overview-of-some-interpretability-friendly-models-I've-trained-and-included"]], "Other Resources:": [[46, "Other-Resources:"]], "Transformer architecture": [[46, "Transformer-architecture"]], "Parameter Names": [[46, "Parameter-Names"]], "Activation + Hook Names": [[46, "Activation-+-Hook-Names"]], "Folding LayerNorm (For the Curious)": [[46, "Folding-LayerNorm-(For-the-Curious)"]], "Features": [[46, "Features"]], "Dealing with tokens": [[46, "Dealing-with-tokens"]], "Gotcha: prepend_bos": [[46, "Gotcha:-prepend_bos"]], "Factored Matrix Class": [[46, "Factored-Matrix-Class"]], "Basic Examples": [[46, "Basic-Examples"]], "Medium Example: Eigenvalue Copying Scores": [[46, "Medium-Example:-Eigenvalue-Copying-Scores"]], "Generating Text": [[46, "Generating-Text"]], "Hook Points": [[46, "Hook-Points"]], "Toy Example": [[46, "Toy-Example"]], "Loading Pre-Trained Checkpoints": [[46, "Loading-Pre-Trained-Checkpoints"]], "Example: Induction Head Phase Transition": [[46, "Example:-Induction-Head-Phase-Transition"]], "Model Properties Table": [[47, "model-properties-table"]], "TransformerLens": [[48, "transformerlens"]], "A Library for Mechanistic Interpretability of Generative Language Models": [[48, "a-library-for-mechanistic-interpretability-of-generative-language-models"]]}, "indexentries": {"activationcache (class in transformer_lens.activationcache)": [[10, "transformer_lens.ActivationCache.ActivationCache"]], "accumulated_resid() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.accumulated_resid"]], "apply_ln_to_stack() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.apply_ln_to_stack"]], "apply_slice_to_batch_dim() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.apply_slice_to_batch_dim"]], "compute_head_results() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.compute_head_results"]], "decompose_resid() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.decompose_resid"]], "get_full_resid_decomposition() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.get_full_resid_decomposition"]], "get_neuron_results() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.get_neuron_results"]], "items() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.items"]], "keys() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.keys"]], "logit_attrs() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.logit_attrs"]], "module": [[10, "module-transformer_lens.ActivationCache"], [11, "module-transformer_lens.FactoredMatrix"], [12, "module-transformer_lens.HookedEncoder"], [13, "module-transformer_lens.HookedTransformer"], [14, "module-transformer_lens.HookedTransformerConfig"], [15, "module-transformer_lens.SVDInterpreter"], [17, "module-transformer_lens.components.abstract_attention"], [18, "module-transformer_lens.components.attention"], [19, "module-transformer_lens.components.bert_block"], [20, "module-transformer_lens.components.bert_embed"], [21, "module-transformer_lens.components.bert_mlm_head"], [22, "module-transformer_lens.components.embed"], [23, "module-transformer_lens.components.gated_mlp"], [24, "module-transformer_lens.components.grouped_query_attention"], [25, "module-transformer_lens.components.layer_norm"], [26, "module-transformer_lens.components.layer_norm_pre"], [27, "module-transformer_lens.components.mlp"], [28, "module-transformer_lens.components.moe"], [29, "module-transformer_lens.components.pos_embed"], [30, "module-transformer_lens.components.rms_norm"], [31, "module-transformer_lens.components.rms_norm_pre"], [32, "module-transformer_lens.components.token_typed_embed"], [33, "module-transformer_lens.components.transformer_block"], [34, "module-transformer_lens.components.unembed"], [35, "module-transformer_lens.evals"], [36, "module-transformer_lens.head_detector"], [37, "module-transformer_lens.hook_points"], [38, "module-transformer_lens.loading_from_pretrained"], [39, "module-transformer_lens.past_key_value_caching"], [40, "module-transformer_lens.patching"], [41, "module-transformer_lens.train"], [43, "module-transformer_lens.utilities.devices"], [44, "module-transformer_lens.utils"]], "remove_batch_dim() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.remove_batch_dim"]], "stack_activation() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.stack_activation"]], "stack_head_results() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.stack_head_results"]], "stack_neuron_results() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.stack_neuron_results"]], "to() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.to"]], "toggle_autodiff() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.toggle_autodiff"]], "transformer_lens.activationcache": [[10, "module-transformer_lens.ActivationCache"]], "values() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.values"]], "ab (transformer_lens.factoredmatrix.factoredmatrix property)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix.AB"]], "ba (transformer_lens.factoredmatrix.factoredmatrix property)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix.BA"]], "factoredmatrix (class in transformer_lens.factoredmatrix)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix"]], "s (transformer_lens.factoredmatrix.factoredmatrix property)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix.S"]], "t (transformer_lens.factoredmatrix.factoredmatrix property)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix.T"]], "u (transformer_lens.factoredmatrix.factoredmatrix property)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix.U"]], "vh (transformer_lens.factoredmatrix.factoredmatrix property)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix.Vh"]], "collapse_l() (transformer_lens.factoredmatrix.factoredmatrix method)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix.collapse_l"]], "collapse_r() (transformer_lens.factoredmatrix.factoredmatrix method)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix.collapse_r"]], "eigenvalues (transformer_lens.factoredmatrix.factoredmatrix property)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix.eigenvalues"]], "get_corner() (transformer_lens.factoredmatrix.factoredmatrix method)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix.get_corner"]], "make_even() (transformer_lens.factoredmatrix.factoredmatrix method)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix.make_even"]], "ndim (transformer_lens.factoredmatrix.factoredmatrix property)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix.ndim"]], "norm() (transformer_lens.factoredmatrix.factoredmatrix method)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix.norm"]], "pair (transformer_lens.factoredmatrix.factoredmatrix property)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix.pair"]], "svd() (transformer_lens.factoredmatrix.factoredmatrix method)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix.svd"]], "transformer_lens.factoredmatrix": [[11, "module-transformer_lens.FactoredMatrix"]], "unsqueeze() (transformer_lens.factoredmatrix.factoredmatrix method)": [[11, "transformer_lens.FactoredMatrix.FactoredMatrix.unsqueeze"]], "hookedencoder (class in transformer_lens.hookedencoder)": [[12, "transformer_lens.HookedEncoder.HookedEncoder"]], "ov (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.OV"]], "qk (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.QK"]], "w_e (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.W_E"]], "w_e_pos (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.W_E_pos"]], "w_k (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.W_K"]], "w_o (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.W_O"]], "w_q (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.W_Q"]], "w_u (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.W_U"]], "w_v (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.W_V"]], "w_in (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.W_in"]], "w_out (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.W_out"]], "w_pos (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.W_pos"]], "all_head_labels() (transformer_lens.hookedencoder.hookedencoder method)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.all_head_labels"]], "b_k (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.b_K"]], "b_o (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.b_O"]], "b_q (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.b_Q"]], "b_u (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.b_U"]], "b_v (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.b_V"]], "b_in (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.b_in"]], "b_out (transformer_lens.hookedencoder.hookedencoder property)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.b_out"]], "cpu() (transformer_lens.hookedencoder.hookedencoder method)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.cpu"]], "cuda() (transformer_lens.hookedencoder.hookedencoder method)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.cuda"]], "forward() (transformer_lens.hookedencoder.hookedencoder method)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.forward"]], "from_pretrained() (transformer_lens.hookedencoder.hookedencoder class method)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.from_pretrained"]], "mps() (transformer_lens.hookedencoder.hookedencoder method)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.mps"]], "run_with_cache() (transformer_lens.hookedencoder.hookedencoder method)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.run_with_cache"]], "to() (transformer_lens.hookedencoder.hookedencoder method)": [[12, "transformer_lens.HookedEncoder.HookedEncoder.to"]], "transformer_lens.hookedencoder": [[12, "module-transformer_lens.HookedEncoder"]], "hookedtransformer (class in transformer_lens.hookedtransformer)": [[13, "transformer_lens.HookedTransformer.HookedTransformer"]], "ov (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.OV"]], "output (class in transformer_lens.hookedtransformer)": [[13, "transformer_lens.HookedTransformer.Output"]], "qk (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.QK"]], "w_e (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.W_E"]], "w_e_pos (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.W_E_pos"]], "w_k (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.W_K"]], "w_o (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.W_O"]], "w_q (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.W_Q"]], "w_u (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.W_U"]], "w_v (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.W_V"]], "w_gate (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.W_gate"]], "w_in (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.W_in"]], "w_out (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.W_out"]], "w_pos (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.W_pos"]], "__init__() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.__init__"]], "accumulated_bias() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.accumulated_bias"]], "all_composition_scores() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.all_composition_scores"]], "all_head_labels() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.all_head_labels"]], "b_k (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.b_K"]], "b_o (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.b_O"]], "b_q (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.b_Q"]], "b_u (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.b_U"]], "b_v (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.b_V"]], "b_in (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.b_in"]], "b_out (transformer_lens.hookedtransformer.hookedtransformer property)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.b_out"]], "center_unembed() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.center_unembed"]], "center_writing_weights() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.center_writing_weights"]], "check_hooks_to_add() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.check_hooks_to_add"]], "cpu() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.cpu"]], "cuda() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.cuda"]], "fold_layer_norm() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.fold_layer_norm"]], "fold_value_biases() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.fold_value_biases"]], "forward() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.forward"]], "from_pretrained() (transformer_lens.hookedtransformer.hookedtransformer class method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.from_pretrained"]], "from_pretrained_no_processing() (transformer_lens.hookedtransformer.hookedtransformer class method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.from_pretrained_no_processing"]], "generate() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.generate"]], "get_token_position() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.get_token_position"]], "init_weights() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.init_weights"]], "input_to_embed() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.input_to_embed"]], "ln_final (transformer_lens.hookedtransformer.hookedtransformer attribute)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.ln_final"]], "load_and_process_state_dict() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.load_and_process_state_dict"]], "load_sample_training_dataset() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.load_sample_training_dataset"]], "logits (transformer_lens.hookedtransformer.output attribute)": [[13, "transformer_lens.HookedTransformer.Output.logits"]], "loss (transformer_lens.hookedtransformer.output attribute)": [[13, "transformer_lens.HookedTransformer.Output.loss"]], "loss_fn() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.loss_fn"]], "move_model_modules_to_device() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.move_model_modules_to_device"]], "mps() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.mps"]], "process_weights_() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.process_weights_"]], "refactor_factored_attn_matrices() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.refactor_factored_attn_matrices"]], "run_with_cache() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.run_with_cache"]], "sample_datapoint() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.sample_datapoint"]], "set_tokenizer() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.set_tokenizer"]], "set_use_attn_in() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.set_use_attn_in"]], "set_use_attn_result() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.set_use_attn_result"]], "set_use_hook_mlp_in() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.set_use_hook_mlp_in"]], "set_use_split_qkv_input() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.set_use_split_qkv_input"]], "to() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.to"]], "to_single_str_token() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.to_single_str_token"]], "to_single_token() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.to_single_token"]], "to_str_tokens() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.to_str_tokens"]], "to_string() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.to_string"]], "to_tokens() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.to_tokens"]], "tokens_to_residual_directions() (transformer_lens.hookedtransformer.hookedtransformer method)": [[13, "transformer_lens.HookedTransformer.HookedTransformer.tokens_to_residual_directions"]], "transformer_lens.hookedtransformer": [[13, "module-transformer_lens.HookedTransformer"]], "hookedtransformerconfig (class in transformer_lens.hookedtransformerconfig)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig"]], "act_fn (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.act_fn"]], "attention_dir (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attention_dir"]], "attn_only (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_only"]], "attn_types (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_types"]], "checkpoint_index (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_index"]], "checkpoint_label_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_label_type"]], "checkpoint_value (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_value"]], "d_head (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_head"]], "d_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_mlp"]], "d_model (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_model"]], "d_vocab (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_vocab"]], "d_vocab_out (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_vocab_out"]], "default_prepend_bos (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.default_prepend_bos"]], "device (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.device"]], "dtype (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.dtype"]], "eps (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.eps"]], "experts_per_token (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.experts_per_token"]], "final_rms (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.final_rms"]], "from_checkpoint (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.from_checkpoint"]], "from_dict() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig class method)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.from_dict"]], "gated_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.gated_mlp"]], "init_mode (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.init_mode"]], "init_weights (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.init_weights"]], "initializer_range (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.initializer_range"]], "load_in_4bit (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.load_in_4bit"]], "model_name (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.model_name"]], "n_ctx (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_ctx"]], "n_devices (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_devices"]], "n_heads (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_heads"]], "n_key_value_heads (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_key_value_heads"]], "n_layers (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_layers"]], "n_params (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_params"]], "normalization_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.normalization_type"]], "num_experts (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.num_experts"]], "original_architecture (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.original_architecture"]], "parallel_attn_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.parallel_attn_mlp"]], "positional_embedding_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.positional_embedding_type"]], "post_embedding_ln (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.post_embedding_ln"]], "rotary_adjacent_pairs (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_adjacent_pairs"]], "rotary_base (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_base"]], "rotary_dim (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_dim"]], "scale_attn_by_inverse_layer_idx (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.scale_attn_by_inverse_layer_idx"]], "seed (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.seed"]], "set_seed_everywhere() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.set_seed_everywhere"]], "to_dict() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.to_dict"]], "tokenizer_name (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.tokenizer_name"]], "tokenizer_prepends_bos (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.tokenizer_prepends_bos"]], "transformer_lens.hookedtransformerconfig": [[14, "module-transformer_lens.HookedTransformerConfig"]], "trust_remote_code (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.trust_remote_code"]], "unwrap() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig class method)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.unwrap"]], "use_attn_in (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_in"]], "use_attn_result (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_result"]], "use_attn_scale (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_scale"]], "use_hook_mlp_in (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_hook_mlp_in"]], "use_hook_tokens (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_hook_tokens"]], "use_local_attn (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_local_attn"]], "use_split_qkv_input (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_split_qkv_input"]], "window_size (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[14, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.window_size"]], "svdinterpreter (class in transformer_lens.svdinterpreter)": [[15, "transformer_lens.SVDInterpreter.SVDInterpreter"]], "get_singular_vectors() (transformer_lens.svdinterpreter.svdinterpreter method)": [[15, "transformer_lens.SVDInterpreter.SVDInterpreter.get_singular_vectors"]], "transformer_lens.svdinterpreter": [[15, "module-transformer_lens.SVDInterpreter"]], "abstractattention (class in transformer_lens.components.abstract_attention)": [[17, "transformer_lens.components.abstract_attention.AbstractAttention"]], "ov (transformer_lens.components.abstract_attention.abstractattention property)": [[17, "transformer_lens.components.abstract_attention.AbstractAttention.OV"]], "qk (transformer_lens.components.abstract_attention.abstractattention property)": [[17, "transformer_lens.components.abstract_attention.AbstractAttention.QK"]], "__init__() (transformer_lens.components.abstract_attention.abstractattention method)": [[17, "transformer_lens.components.abstract_attention.AbstractAttention.__init__"]], "alibi (transformer_lens.components.abstract_attention.abstractattention attribute)": [[17, "transformer_lens.components.abstract_attention.AbstractAttention.alibi"]], "apply_causal_mask() (transformer_lens.components.abstract_attention.abstractattention method)": [[17, "transformer_lens.components.abstract_attention.AbstractAttention.apply_causal_mask"]], "apply_rotary() (transformer_lens.components.abstract_attention.abstractattention method)": [[17, "transformer_lens.components.abstract_attention.AbstractAttention.apply_rotary"]], "calculate_attention_scores() (transformer_lens.components.abstract_attention.abstractattention method)": [[17, "transformer_lens.components.abstract_attention.AbstractAttention.calculate_attention_scores"]], "calculate_qkv_matrices() (transformer_lens.components.abstract_attention.abstractattention method)": [[17, "transformer_lens.components.abstract_attention.AbstractAttention.calculate_qkv_matrices"]], "calculate_sin_cos_rotary() (transformer_lens.components.abstract_attention.abstractattention method)": [[17, "transformer_lens.components.abstract_attention.AbstractAttention.calculate_sin_cos_rotary"]], "calculate_z_scores() (transformer_lens.components.abstract_attention.abstractattention method)": [[17, "transformer_lens.components.abstract_attention.AbstractAttention.calculate_z_scores"]], "create_alibi_bias() (transformer_lens.components.abstract_attention.abstractattention static method)": [[17, "transformer_lens.components.abstract_attention.AbstractAttention.create_alibi_bias"]], "create_alibi_multipliers() (transformer_lens.components.abstract_attention.abstractattention static method)": [[17, "transformer_lens.components.abstract_attention.AbstractAttention.create_alibi_multipliers"]], "create_alibi_slope() (transformer_lens.components.abstract_attention.abstractattention static method)": [[17, "transformer_lens.components.abstract_attention.AbstractAttention.create_alibi_slope"]], "forward() (transformer_lens.components.abstract_attention.abstractattention method)": [[17, "transformer_lens.components.abstract_attention.AbstractAttention.forward"]], "rotate_every_two() (transformer_lens.components.abstract_attention.abstractattention method)": [[17, "transformer_lens.components.abstract_attention.AbstractAttention.rotate_every_two"]], "transformer_lens.components.abstract_attention": [[17, "module-transformer_lens.components.abstract_attention"]], "attention (class in transformer_lens.components.attention)": [[18, "transformer_lens.components.attention.Attention"]], "__init__() (transformer_lens.components.attention.attention method)": [[18, "transformer_lens.components.attention.Attention.__init__"]], "transformer_lens.components.attention": [[18, "module-transformer_lens.components.attention"]], "bertblock (class in transformer_lens.components.bert_block)": [[19, "transformer_lens.components.bert_block.BertBlock"]], "forward() (transformer_lens.components.bert_block.bertblock method)": [[19, "transformer_lens.components.bert_block.BertBlock.forward"]], "transformer_lens.components.bert_block": [[19, "module-transformer_lens.components.bert_block"]], "bertembed (class in transformer_lens.components.bert_embed)": [[20, "transformer_lens.components.bert_embed.BertEmbed"]], "forward() (transformer_lens.components.bert_embed.bertembed method)": [[20, "transformer_lens.components.bert_embed.BertEmbed.forward"]], "transformer_lens.components.bert_embed": [[20, "module-transformer_lens.components.bert_embed"]], "bertmlmhead (class in transformer_lens.components.bert_mlm_head)": [[21, "transformer_lens.components.bert_mlm_head.BertMLMHead"]], "forward() (transformer_lens.components.bert_mlm_head.bertmlmhead method)": [[21, "transformer_lens.components.bert_mlm_head.BertMLMHead.forward"]], "transformer_lens.components.bert_mlm_head": [[21, "module-transformer_lens.components.bert_mlm_head"]], "embed (class in transformer_lens.components.embed)": [[22, "transformer_lens.components.embed.Embed"]], "forward() (transformer_lens.components.embed.embed method)": [[22, "transformer_lens.components.embed.Embed.forward"]], "transformer_lens.components.embed": [[22, "module-transformer_lens.components.embed"]], "gatedmlp (class in transformer_lens.components.gated_mlp)": [[23, "transformer_lens.components.gated_mlp.GatedMLP"]], "act_fn (transformer_lens.components.gated_mlp.gatedmlp attribute)": [[23, "transformer_lens.components.gated_mlp.GatedMLP.act_fn"]], "forward() (transformer_lens.components.gated_mlp.gatedmlp method)": [[23, "transformer_lens.components.gated_mlp.GatedMLP.forward"]], "ln (transformer_lens.components.gated_mlp.gatedmlp attribute)": [[23, "transformer_lens.components.gated_mlp.GatedMLP.ln"]], "transformer_lens.components.gated_mlp": [[23, "module-transformer_lens.components.gated_mlp"]], "groupedqueryattention (class in transformer_lens.components.grouped_query_attention)": [[24, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention"]], "w_k (transformer_lens.components.grouped_query_attention.groupedqueryattention property)": [[24, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention.W_K"]], "w_v (transformer_lens.components.grouped_query_attention.groupedqueryattention property)": [[24, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention.W_V"]], "__init__() (transformer_lens.components.grouped_query_attention.groupedqueryattention method)": [[24, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention.__init__"]], "b_k (transformer_lens.components.grouped_query_attention.groupedqueryattention property)": [[24, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention.b_K"]], "b_v (transformer_lens.components.grouped_query_attention.groupedqueryattention property)": [[24, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention.b_V"]], "calculate_attention_scores() (transformer_lens.components.grouped_query_attention.groupedqueryattention method)": [[24, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention.calculate_attention_scores"]], "calculate_qkv_matrices() (transformer_lens.components.grouped_query_attention.groupedqueryattention method)": [[24, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention.calculate_qkv_matrices"]], "calculate_z_scores() (transformer_lens.components.grouped_query_attention.groupedqueryattention method)": [[24, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention.calculate_z_scores"]], "transformer_lens.components.grouped_query_attention": [[24, "module-transformer_lens.components.grouped_query_attention"]], "layernorm (class in transformer_lens.components.layer_norm)": [[25, "transformer_lens.components.layer_norm.LayerNorm"]], "__init__() (transformer_lens.components.layer_norm.layernorm method)": [[25, "transformer_lens.components.layer_norm.LayerNorm.__init__"]], "forward() (transformer_lens.components.layer_norm.layernorm method)": [[25, "transformer_lens.components.layer_norm.LayerNorm.forward"]], "transformer_lens.components.layer_norm": [[25, "module-transformer_lens.components.layer_norm"]], "layernormpre (class in transformer_lens.components.layer_norm_pre)": [[26, "transformer_lens.components.layer_norm_pre.LayerNormPre"]], "__init__() (transformer_lens.components.layer_norm_pre.layernormpre method)": [[26, "transformer_lens.components.layer_norm_pre.LayerNormPre.__init__"]], "forward() (transformer_lens.components.layer_norm_pre.layernormpre method)": [[26, "transformer_lens.components.layer_norm_pre.LayerNormPre.forward"]], "transformer_lens.components.layer_norm_pre": [[26, "module-transformer_lens.components.layer_norm_pre"]], "mlp (class in transformer_lens.components.mlp)": [[27, "transformer_lens.components.mlp.MLP"]], "act_fn (transformer_lens.components.mlp.mlp attribute)": [[27, "transformer_lens.components.mlp.MLP.act_fn"]], "forward() (transformer_lens.components.mlp.mlp method)": [[27, "transformer_lens.components.mlp.MLP.forward"]], "ln (transformer_lens.components.mlp.mlp attribute)": [[27, "transformer_lens.components.mlp.MLP.ln"]], "transformer_lens.components.mlp": [[27, "module-transformer_lens.components.mlp"]], "moe (class in transformer_lens.components.moe)": [[28, "transformer_lens.components.moe.MoE"]], "forward() (transformer_lens.components.moe.moe method)": [[28, "transformer_lens.components.moe.MoE.forward"]], "transformer_lens.components.moe": [[28, "module-transformer_lens.components.moe"]], "posembed (class in transformer_lens.components.pos_embed)": [[29, "transformer_lens.components.pos_embed.PosEmbed"]], "forward() (transformer_lens.components.pos_embed.posembed method)": [[29, "transformer_lens.components.pos_embed.PosEmbed.forward"]], "transformer_lens.components.pos_embed": [[29, "module-transformer_lens.components.pos_embed"]], "rmsnorm (class in transformer_lens.components.rms_norm)": [[30, "transformer_lens.components.rms_norm.RMSNorm"]], "__init__() (transformer_lens.components.rms_norm.rmsnorm method)": [[30, "transformer_lens.components.rms_norm.RMSNorm.__init__"]], "forward() (transformer_lens.components.rms_norm.rmsnorm method)": [[30, "transformer_lens.components.rms_norm.RMSNorm.forward"]], "transformer_lens.components.rms_norm": [[30, "module-transformer_lens.components.rms_norm"]], "rmsnormpre (class in transformer_lens.components.rms_norm_pre)": [[31, "transformer_lens.components.rms_norm_pre.RMSNormPre"]], "__init__() (transformer_lens.components.rms_norm_pre.rmsnormpre method)": [[31, "transformer_lens.components.rms_norm_pre.RMSNormPre.__init__"]], "forward() (transformer_lens.components.rms_norm_pre.rmsnormpre method)": [[31, "transformer_lens.components.rms_norm_pre.RMSNormPre.forward"]], "transformer_lens.components.rms_norm_pre": [[31, "module-transformer_lens.components.rms_norm_pre"]], "tokentypeembed (class in transformer_lens.components.token_typed_embed)": [[32, "transformer_lens.components.token_typed_embed.TokenTypeEmbed"]], "forward() (transformer_lens.components.token_typed_embed.tokentypeembed method)": [[32, "transformer_lens.components.token_typed_embed.TokenTypeEmbed.forward"]], "transformer_lens.components.token_typed_embed": [[32, "module-transformer_lens.components.token_typed_embed"]], "transformerblock (class in transformer_lens.components.transformer_block)": [[33, "transformer_lens.components.transformer_block.TransformerBlock"]], "forward() (transformer_lens.components.transformer_block.transformerblock method)": [[33, "transformer_lens.components.transformer_block.TransformerBlock.forward"]], "ln1 (transformer_lens.components.transformer_block.transformerblock attribute)": [[33, "transformer_lens.components.transformer_block.TransformerBlock.ln1"]], "ln2 (transformer_lens.components.transformer_block.transformerblock attribute)": [[33, "transformer_lens.components.transformer_block.TransformerBlock.ln2"]], "mlp (transformer_lens.components.transformer_block.transformerblock attribute)": [[33, "transformer_lens.components.transformer_block.TransformerBlock.mlp"]], "transformer_lens.components.transformer_block": [[33, "module-transformer_lens.components.transformer_block"]], "unembed (class in transformer_lens.components.unembed)": [[34, "transformer_lens.components.unembed.Unembed"]], "forward() (transformer_lens.components.unembed.unembed method)": [[34, "transformer_lens.components.unembed.Unembed.forward"]], "transformer_lens.components.unembed": [[34, "module-transformer_lens.components.unembed"]], "ioidataset (class in transformer_lens.evals)": [[35, "transformer_lens.evals.IOIDataset"]], "evaluate() (in module transformer_lens.evals)": [[35, "transformer_lens.evals.evaluate"]], "evaluate_on_dataset() (in module transformer_lens.evals)": [[35, "transformer_lens.evals.evaluate_on_dataset"]], "get_default_names() (transformer_lens.evals.ioidataset static method)": [[35, "transformer_lens.evals.IOIDataset.get_default_names"]], "get_default_nouns() (transformer_lens.evals.ioidataset static method)": [[35, "transformer_lens.evals.IOIDataset.get_default_nouns"]], "get_default_templates() (transformer_lens.evals.ioidataset static method)": [[35, "transformer_lens.evals.IOIDataset.get_default_templates"]], "get_sample() (transformer_lens.evals.ioidataset method)": [[35, "transformer_lens.evals.IOIDataset.get_sample"]], "induction_loss() (in module transformer_lens.evals)": [[35, "transformer_lens.evals.induction_loss"]], "ioi_eval() (in module transformer_lens.evals)": [[35, "transformer_lens.evals.ioi_eval"]], "make_code_data_loader() (in module transformer_lens.evals)": [[35, "transformer_lens.evals.make_code_data_loader"]], "make_owt_data_loader() (in module transformer_lens.evals)": [[35, "transformer_lens.evals.make_owt_data_loader"]], "make_pile_data_loader() (in module transformer_lens.evals)": [[35, "transformer_lens.evals.make_pile_data_loader"]], "make_wiki_data_loader() (in module transformer_lens.evals)": [[35, "transformer_lens.evals.make_wiki_data_loader"]], "sanity_check() (in module transformer_lens.evals)": [[35, "transformer_lens.evals.sanity_check"]], "transformer_lens.evals": [[35, "module-transformer_lens.evals"]], "compute_head_attention_similarity_score() (in module transformer_lens.head_detector)": [[36, "transformer_lens.head_detector.compute_head_attention_similarity_score"]], "detect_head() (in module transformer_lens.head_detector)": [[36, "transformer_lens.head_detector.detect_head"]], "get_duplicate_token_head_detection_pattern() (in module transformer_lens.head_detector)": [[36, "transformer_lens.head_detector.get_duplicate_token_head_detection_pattern"]], "get_induction_head_detection_pattern() (in module transformer_lens.head_detector)": [[36, "transformer_lens.head_detector.get_induction_head_detection_pattern"]], "get_previous_token_head_detection_pattern() (in module transformer_lens.head_detector)": [[36, "transformer_lens.head_detector.get_previous_token_head_detection_pattern"]], "get_supported_heads() (in module transformer_lens.head_detector)": [[36, "transformer_lens.head_detector.get_supported_heads"]], "transformer_lens.head_detector": [[36, "module-transformer_lens.head_detector"]], "hookfunction (in module transformer_lens.hook_points)": [[37, "transformer_lens.hook_points.HookFunction"]], "hookpoint (class in transformer_lens.hook_points)": [[37, "transformer_lens.hook_points.HookPoint"]], "hookedrootmodule (class in transformer_lens.hook_points)": [[37, "transformer_lens.hook_points.HookedRootModule"]], "lenshandle (class in transformer_lens.hook_points)": [[37, "transformer_lens.hook_points.LensHandle"]], "add_caching_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[37, "transformer_lens.hook_points.HookedRootModule.add_caching_hooks"]], "add_hook() (transformer_lens.hook_points.hookpoint method)": [[37, "transformer_lens.hook_points.HookPoint.add_hook"]], "add_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[37, "transformer_lens.hook_points.HookedRootModule.add_hook"]], "add_perma_hook() (transformer_lens.hook_points.hookpoint method)": [[37, "transformer_lens.hook_points.HookPoint.add_perma_hook"]], "add_perma_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[37, "transformer_lens.hook_points.HookedRootModule.add_perma_hook"]], "cache_all() (transformer_lens.hook_points.hookedrootmodule method)": [[37, "transformer_lens.hook_points.HookedRootModule.cache_all"]], "cache_some() (transformer_lens.hook_points.hookedrootmodule method)": [[37, "transformer_lens.hook_points.HookedRootModule.cache_some"]], "check_and_add_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[37, "transformer_lens.hook_points.HookedRootModule.check_and_add_hook"]], "check_hooks_to_add() (transformer_lens.hook_points.hookedrootmodule method)": [[37, "transformer_lens.hook_points.HookedRootModule.check_hooks_to_add"]], "clear_context() (transformer_lens.hook_points.hookpoint method)": [[37, "transformer_lens.hook_points.HookPoint.clear_context"]], "clear_contexts() (transformer_lens.hook_points.hookedrootmodule method)": [[37, "transformer_lens.hook_points.HookedRootModule.clear_contexts"]], "context_level (transformer_lens.hook_points.lenshandle attribute)": [[37, "transformer_lens.hook_points.LensHandle.context_level"]], "forward() (transformer_lens.hook_points.hookpoint method)": [[37, "transformer_lens.hook_points.HookPoint.forward"]], "get_caching_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[37, "transformer_lens.hook_points.HookedRootModule.get_caching_hooks"]], "hook (transformer_lens.hook_points.lenshandle attribute)": [[37, "transformer_lens.hook_points.LensHandle.hook"]], "hook_dict (transformer_lens.hook_points.hookedrootmodule attribute)": [[37, "transformer_lens.hook_points.HookedRootModule.hook_dict"]], "hook_points() (transformer_lens.hook_points.hookedrootmodule method)": [[37, "transformer_lens.hook_points.HookedRootModule.hook_points"]], "hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[37, "transformer_lens.hook_points.HookedRootModule.hooks"]], "is_permanent (transformer_lens.hook_points.lenshandle attribute)": [[37, "transformer_lens.hook_points.LensHandle.is_permanent"]], "layer() (transformer_lens.hook_points.hookpoint method)": [[37, "transformer_lens.hook_points.HookPoint.layer"]], "mod_dict (transformer_lens.hook_points.hookedrootmodule attribute)": [[37, "transformer_lens.hook_points.HookedRootModule.mod_dict"]], "name (transformer_lens.hook_points.hookedrootmodule attribute)": [[37, "transformer_lens.hook_points.HookedRootModule.name"]], "remove_all_hook_fns() (transformer_lens.hook_points.hookedrootmodule method)": [[37, "transformer_lens.hook_points.HookedRootModule.remove_all_hook_fns"]], "remove_hooks() (transformer_lens.hook_points.hookpoint method)": [[37, "transformer_lens.hook_points.HookPoint.remove_hooks"]], "reset_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[37, "transformer_lens.hook_points.HookedRootModule.reset_hooks"]], "run_with_cache() (transformer_lens.hook_points.hookedrootmodule method)": [[37, "transformer_lens.hook_points.HookedRootModule.run_with_cache"]], "run_with_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[37, "transformer_lens.hook_points.HookedRootModule.run_with_hooks"]], "setup() (transformer_lens.hook_points.hookedrootmodule method)": [[37, "transformer_lens.hook_points.HookedRootModule.setup"]], "transformer_lens.hook_points": [[37, "module-transformer_lens.hook_points"]], "config (class in transformer_lens.loading_from_pretrained)": [[38, "transformer_lens.loading_from_pretrained.Config"]], "model_aliases (in module transformer_lens.loading_from_pretrained)": [[38, "transformer_lens.loading_from_pretrained.MODEL_ALIASES"]], "non_hf_hosted_model_names (in module transformer_lens.loading_from_pretrained)": [[38, "transformer_lens.loading_from_pretrained.NON_HF_HOSTED_MODEL_NAMES"]], "official_model_names (in module transformer_lens.loading_from_pretrained)": [[38, "transformer_lens.loading_from_pretrained.OFFICIAL_MODEL_NAMES"]], "convert_bloom_weights() (in module transformer_lens.loading_from_pretrained)": [[38, "transformer_lens.loading_from_pretrained.convert_bloom_weights"]], "convert_coder_weights() (in module transformer_lens.loading_from_pretrained)": [[38, "transformer_lens.loading_from_pretrained.convert_coder_weights"]], "convert_mistral_weights() (in module transformer_lens.loading_from_pretrained)": [[38, "transformer_lens.loading_from_pretrained.convert_mistral_weights"]], "convert_mixtral_weights() (in module transformer_lens.loading_from_pretrained)": [[38, "transformer_lens.loading_from_pretrained.convert_mixtral_weights"]], "convert_phi3_weights() (in module transformer_lens.loading_from_pretrained)": [[38, "transformer_lens.loading_from_pretrained.convert_phi3_weights"]], "convert_phi_weights() (in module transformer_lens.loading_from_pretrained)": [[38, "transformer_lens.loading_from_pretrained.convert_phi_weights"]], "convert_qwen2_weights() (in module transformer_lens.loading_from_pretrained)": [[38, "transformer_lens.loading_from_pretrained.convert_qwen2_weights"]], "convert_qwen_weights() (in module transformer_lens.loading_from_pretrained)": [[38, "transformer_lens.loading_from_pretrained.convert_qwen_weights"]], "d_head (transformer_lens.loading_from_pretrained.config attribute)": [[38, "transformer_lens.loading_from_pretrained.Config.d_head"]], "d_mlp (transformer_lens.loading_from_pretrained.config attribute)": [[38, "transformer_lens.loading_from_pretrained.Config.d_mlp"]], "d_model (transformer_lens.loading_from_pretrained.config attribute)": [[38, "transformer_lens.loading_from_pretrained.Config.d_model"]], "d_vocab (transformer_lens.loading_from_pretrained.config attribute)": [[38, "transformer_lens.loading_from_pretrained.Config.d_vocab"]], "debug (transformer_lens.loading_from_pretrained.config attribute)": [[38, "transformer_lens.loading_from_pretrained.Config.debug"]], "get_checkpoint_labels() (in module transformer_lens.loading_from_pretrained)": [[38, "transformer_lens.loading_from_pretrained.get_checkpoint_labels"]], "get_num_params_of_pretrained() (in module transformer_lens.loading_from_pretrained)": [[38, "transformer_lens.loading_from_pretrained.get_num_params_of_pretrained"]], "get_pretrained_model_config() (in module transformer_lens.loading_from_pretrained)": [[38, "transformer_lens.loading_from_pretrained.get_pretrained_model_config"]], "init_range (transformer_lens.loading_from_pretrained.config attribute)": [[38, "transformer_lens.loading_from_pretrained.Config.init_range"]], "layer_norm_eps (transformer_lens.loading_from_pretrained.config attribute)": [[38, "transformer_lens.loading_from_pretrained.Config.layer_norm_eps"]], "n_ctx (transformer_lens.loading_from_pretrained.config attribute)": [[38, "transformer_lens.loading_from_pretrained.Config.n_ctx"]], "n_heads (transformer_lens.loading_from_pretrained.config attribute)": [[38, "transformer_lens.loading_from_pretrained.Config.n_heads"]], "n_layers (transformer_lens.loading_from_pretrained.config attribute)": [[38, "transformer_lens.loading_from_pretrained.Config.n_layers"]], "transformer_lens.loading_from_pretrained": [[38, "module-transformer_lens.loading_from_pretrained"]], "hookedtransformerkeyvaluecache (class in transformer_lens.past_key_value_caching)": [[39, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache"]], "hookedtransformerkeyvaluecacheentry (class in transformer_lens.past_key_value_caching)": [[39, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry"]], "append() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry method)": [[39, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.append"]], "append_attention_mask() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[39, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.append_attention_mask"]], "entries (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[39, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.entries"]], "freeze() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[39, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.freeze"]], "frozen (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[39, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.frozen"]], "frozen (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[39, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.frozen"]], "init_cache() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache class method)": [[39, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.init_cache"]], "init_cache_entry() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry class method)": [[39, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.init_cache_entry"]], "past_keys (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[39, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.past_keys"]], "past_values (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[39, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.past_values"]], "previous_attention_mask (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[39, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.previous_attention_mask"]], "transformer_lens.past_key_value_caching": [[39, "module-transformer_lens.past_key_value_caching"]], "unfreeze() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[39, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.unfreeze"]], "generic_activation_patch() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.generic_activation_patch"]], "get_act_patch_attn_head_all_pos_every() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_attn_head_all_pos_every"]], "get_act_patch_attn_head_by_pos_every() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_attn_head_by_pos_every"]], "get_act_patch_attn_head_k_all_pos() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_attn_head_k_all_pos"]], "get_act_patch_attn_head_k_by_pos() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_attn_head_k_by_pos"]], "get_act_patch_attn_head_out_all_pos() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_attn_head_out_all_pos"]], "get_act_patch_attn_head_out_by_pos() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_attn_head_out_by_pos"]], "get_act_patch_attn_head_pattern_all_pos() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_attn_head_pattern_all_pos"]], "get_act_patch_attn_head_pattern_by_pos() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_attn_head_pattern_by_pos"]], "get_act_patch_attn_head_pattern_dest_src_pos() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_attn_head_pattern_dest_src_pos"]], "get_act_patch_attn_head_q_all_pos() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_attn_head_q_all_pos"]], "get_act_patch_attn_head_q_by_pos() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_attn_head_q_by_pos"]], "get_act_patch_attn_head_v_all_pos() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_attn_head_v_all_pos"]], "get_act_patch_attn_head_v_by_pos() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_attn_head_v_by_pos"]], "get_act_patch_attn_out() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_attn_out"]], "get_act_patch_block_every() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_block_every"]], "get_act_patch_mlp_out() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_mlp_out"]], "get_act_patch_resid_mid() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_resid_mid"]], "get_act_patch_resid_pre() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.get_act_patch_resid_pre"]], "layer_head_dest_src_pos_pattern_patch_setter() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.layer_head_dest_src_pos_pattern_patch_setter"]], "layer_head_pattern_patch_setter() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.layer_head_pattern_patch_setter"]], "layer_head_pos_pattern_patch_setter() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.layer_head_pos_pattern_patch_setter"]], "layer_head_vector_patch_setter() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.layer_head_vector_patch_setter"]], "layer_pos_head_vector_patch_setter() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.layer_pos_head_vector_patch_setter"]], "layer_pos_patch_setter() (in module transformer_lens.patching)": [[40, "transformer_lens.patching.layer_pos_patch_setter"]], "transformer_lens.patching": [[40, "module-transformer_lens.patching"]], "hookedtransformertrainconfig (class in transformer_lens.train)": [[41, "transformer_lens.train.HookedTransformerTrainConfig"]], "batch_size (transformer_lens.train.hookedtransformertrainconfig attribute)": [[41, "transformer_lens.train.HookedTransformerTrainConfig.batch_size"]], "device (transformer_lens.train.hookedtransformertrainconfig attribute)": [[41, "transformer_lens.train.HookedTransformerTrainConfig.device"]], "lr (transformer_lens.train.hookedtransformertrainconfig attribute)": [[41, "transformer_lens.train.HookedTransformerTrainConfig.lr"]], "max_grad_norm (transformer_lens.train.hookedtransformertrainconfig attribute)": [[41, "transformer_lens.train.HookedTransformerTrainConfig.max_grad_norm"]], "max_steps (transformer_lens.train.hookedtransformertrainconfig attribute)": [[41, "transformer_lens.train.HookedTransformerTrainConfig.max_steps"]], "momentum (transformer_lens.train.hookedtransformertrainconfig attribute)": [[41, "transformer_lens.train.HookedTransformerTrainConfig.momentum"]], "num_epochs (transformer_lens.train.hookedtransformertrainconfig attribute)": [[41, "transformer_lens.train.HookedTransformerTrainConfig.num_epochs"]], "optimizer_name (transformer_lens.train.hookedtransformertrainconfig attribute)": [[41, "transformer_lens.train.HookedTransformerTrainConfig.optimizer_name"]], "print_every (transformer_lens.train.hookedtransformertrainconfig attribute)": [[41, "transformer_lens.train.HookedTransformerTrainConfig.print_every"]], "save_dir (transformer_lens.train.hookedtransformertrainconfig attribute)": [[41, "transformer_lens.train.HookedTransformerTrainConfig.save_dir"]], "save_every (transformer_lens.train.hookedtransformertrainconfig attribute)": [[41, "transformer_lens.train.HookedTransformerTrainConfig.save_every"]], "seed (transformer_lens.train.hookedtransformertrainconfig attribute)": [[41, "transformer_lens.train.HookedTransformerTrainConfig.seed"]], "train() (in module transformer_lens.train)": [[41, "transformer_lens.train.train"]], "transformer_lens.train": [[41, "module-transformer_lens.train"]], "wandb (transformer_lens.train.hookedtransformertrainconfig attribute)": [[41, "transformer_lens.train.HookedTransformerTrainConfig.wandb"]], "wandb_project_name (transformer_lens.train.hookedtransformertrainconfig attribute)": [[41, "transformer_lens.train.HookedTransformerTrainConfig.wandb_project_name"]], "warmup_steps (transformer_lens.train.hookedtransformertrainconfig attribute)": [[41, "transformer_lens.train.HookedTransformerTrainConfig.warmup_steps"]], "weight_decay (transformer_lens.train.hookedtransformertrainconfig attribute)": [[41, "transformer_lens.train.HookedTransformerTrainConfig.weight_decay"]], "get_device_for_block_index() (in module transformer_lens.utilities.devices)": [[43, "transformer_lens.utilities.devices.get_device_for_block_index"]], "move_to_and_update_config() (in module transformer_lens.utilities.devices)": [[43, "transformer_lens.utilities.devices.move_to_and_update_config"]], "transformer_lens.utilities.devices": [[43, "module-transformer_lens.utilities.devices"]], "locallyoverridendefaults (class in transformer_lens.utils)": [[44, "transformer_lens.utils.LocallyOverridenDefaults"]], "slice (class in transformer_lens.utils)": [[44, "transformer_lens.utils.Slice"]], "sliceinput (in module transformer_lens.utils)": [[44, "transformer_lens.utils.SliceInput"]], "__init__() (transformer_lens.utils.locallyoverridendefaults method)": [[44, "transformer_lens.utils.LocallyOverridenDefaults.__init__"]], "__init__() (transformer_lens.utils.slice method)": [[44, "transformer_lens.utils.Slice.__init__"]], "apply() (transformer_lens.utils.slice method)": [[44, "transformer_lens.utils.Slice.apply"]], "calc_fan_in_and_fan_out() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.calc_fan_in_and_fan_out"]], "composition_scores() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.composition_scores"]], "download_file_from_hf() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.download_file_from_hf"]], "gelu_fast() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.gelu_fast"]], "gelu_new() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.gelu_new"]], "get_act_name() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.get_act_name"]], "get_attention_mask() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.get_attention_mask"]], "get_corner() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.get_corner"]], "get_cumsum_along_dim() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.get_cumsum_along_dim"]], "get_dataset() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.get_dataset"]], "get_device() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.get_device"]], "get_input_with_manually_prepended_bos() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.get_input_with_manually_prepended_bos"]], "get_nested_attr() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.get_nested_attr"]], "get_offset_position_ids() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.get_offset_position_ids"]], "get_tokenizer_with_bos() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.get_tokenizer_with_bos"]], "get_tokens_with_bos_removed() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.get_tokens_with_bos_removed"]], "indices() (transformer_lens.utils.slice method)": [[44, "transformer_lens.utils.Slice.indices"]], "init_kaiming_normal_() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.init_kaiming_normal_"]], "init_kaiming_uniform_() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.init_kaiming_uniform_"]], "init_xavier_normal_() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.init_xavier_normal_"]], "init_xavier_uniform_() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.init_xavier_uniform_"]], "is_lower_triangular() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.is_lower_triangular"]], "is_square() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.is_square"]], "keep_single_column() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.keep_single_column"]], "lm_accuracy() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.lm_accuracy"]], "lm_cross_entropy_loss() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.lm_cross_entropy_loss"]], "override_or_use_default_value() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.override_or_use_default_value"]], "print_gpu_mem() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.print_gpu_mem"]], "remove_batch_dim() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.remove_batch_dim"]], "repeat_along_head_dimension() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.repeat_along_head_dimension"]], "sample_logits() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.sample_logits"]], "set_nested_attr() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.set_nested_attr"]], "slice (transformer_lens.utils.slice attribute)": [[44, "transformer_lens.utils.Slice.slice"]], "solu() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.solu"]], "test_prompt() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.test_prompt"]], "to_numpy() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.to_numpy"]], "tokenize_and_concatenate() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.tokenize_and_concatenate"]], "transformer_lens.utils": [[44, "module-transformer_lens.utils"]], "transpose() (in module transformer_lens.utils)": [[44, "transformer_lens.utils.transpose"]], "unwrap() (transformer_lens.utils.slice class method)": [[44, "transformer_lens.utils.Slice.unwrap"]]}})